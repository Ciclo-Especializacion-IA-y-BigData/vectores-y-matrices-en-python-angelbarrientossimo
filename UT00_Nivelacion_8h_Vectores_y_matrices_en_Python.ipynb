{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "55f77e34",
      "metadata": {
        "id": "55f77e34"
      },
      "source": [
        "\n",
        "\n",
        "# Vectores y matrices en Python\n",
        "\n",
        "### Objetivos de aprendizaje\n",
        "\n",
        "* Comprender el concepto de vector y matriz como estructuras matemáticas y de datos.\n",
        "* Realizar operaciones básicas: suma, resta, producto escalar y multiplicación de matrices.\n",
        "* Resolver sistemas de ecuaciones lineales sencillos.\n",
        "* Aplicar todo esto con **NumPy**, la librería estándar de Python para cálculo numérico.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rNzoNVhrVI_e",
      "metadata": {
        "id": "rNzoNVhrVI_e"
      },
      "source": [
        "# 1. Vectores\n",
        "\n",
        "### ¿Qué es un vector?\n",
        "\n",
        "Un **vector** es un objeto matemático que nos da **dos informaciones a la vez**:\n",
        "\n",
        "1. **Módulo (o longitud)** → Cuánto mide. En el espacio euclidiano n-dimensional, el módulo (también conocido como norma euclidiana o 2-norma) de un vector x = (x₁, ..., xₙ) se calcula como √(x₁² + ... + xₙ²).\n",
        "2. **Dirección** → hacia dónde apunta.\n",
        "\n",
        "Aunque popularmente se define por tener magnitud y dirección, un vector es fundamentalmente una estructura matemática que permite operaciones como la adición y la multiplicación por escalares. Los conceptos de distancia y ortogonalidad también son parte de su estructura geométrica\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Vector_00.svg/2560px-Vector_00.svg.png\" alt=\"Elementos de un vector\" width=\"300\"/>\n",
        "\n",
        "\n",
        "La forma más sencilla de imaginar un vector es como una **flecha** dibujada desde un punto de partida (el **origen**) hasta un punto de llegada. En el contexto de un espacio vectorial (una estructura matemática más amplia), el origen es el vector nulo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplos cotidianos\n",
        "\n",
        "* **Dar una patada a un balón**: no basta con la fuerza (magnitud), también importa hacia dónde lo lanzas (dirección).\n",
        "* **El viento**: decimos “20 km/h al Este”. Esa es la magnitud (20) y la dirección (Este).\n",
        "* **Un mapa**: para ir de casa al instituto: “3 manzanas al Norte y 2 al Este” → vector $(3,2)$.\n",
        "\n",
        "---\n",
        "\n",
        "### Representación matemática\n",
        "\n",
        "Un vector se escribe como una colección ordenada de números, que pueden estar dispuestos en una fila o columna.\n",
        "\n",
        "$$\n",
        "\\vec{v} = (x_1, x_2, \\ldots, x_n)\n",
        "$$\n",
        "\n",
        "* Cada número $x_i$ es un **componente** del vector.\n",
        "* En el ejemplo del mapa:\n",
        "  $\\vec{v}=(3,2)$ significa *3 pasos al Norte y 2 al Este*.\n",
        "* En un espacio tridimensional, podemos tener:\n",
        "  $\\vec{v}=(2,3,5)$.\n",
        "\n",
        "Para realizar operaciones matemáticas, es común representar los vectores como vectores columna. Un vector n-dimensional se puede ver como una función que mapea un conjunto de índices {1, 2, ..., n} a números reales, donde cada índice corresponde a un componente  \n",
        "\n",
        "---\n",
        "\n",
        "### Diferencia con un escalar\n",
        "\n",
        "Un escalar es la entidad matemática más simple: es un único valor numérico que representa magnitud, pero carece de dirección.\n",
        "\n",
        "Ejemplo de escalar:* La temperatura es de 25 ºC.\n",
        "\n",
        "En IA, las tasas de aprendizaje o los términos de sesgo (bias) en una neurona son ejemplos de escalares\n",
        "\n",
        "A diferencia de los escalares, los vectores se usan para describir cantidades que existen en más de una dimensión\n",
        "\n",
        "---\n",
        "\n",
        "### Vectores en la vida real… y en la IA\n",
        "\n",
        "Los vectores y las matrices son fundamentales en la Inteligencia Artificial (IA) para la representación y manipulación de datos. En el aprendizaje automático, cada punto de datos se puede representar como un vector en un espacio de características, donde cada dimensión corresponde a una característica específica.\n",
        "\n",
        "* **Imágenes**: Una imagen puede representarse como una gran matriz de valores de píxeles, donde cada píxel corresponde a la intensidad de color. Por ejemplo, una imagen en blanco y negro de 100 píxeles puede representarse como un vector con 100 componentes. Las redes neuronales convolucionales (CNNs) utilizan estas representaciones matriciales para procesar datos visuales.\n",
        "* **Datos de una casa**: Características de una casa como la superficie, el número de habitaciones y el precio pueden agruparse en un vector de características, por ejemplo, (80, 3, 120000).\n",
        "* **NLP (Procesamiento de Lenguaje Natural)**: Las palabras o frases se transforman en vectores en un espacio de alta dimensión, conocidos como embeddings. Estos vectores permiten a los algoritmos de IA \"comprender\" el lenguaje de manera significativa, capturando relaciones semánticas entre las palabras en lugar de solo coincidencias de cadenas. Técnicas como Word2Vec y GloVe utilizan estas representaciones vectoriales.\n",
        "* **Redes Neuronales**: Una red neuronal se describe como una función multivariable que toma un vector como entrada (input) y produce otro vector como salida (output). La manipulación de vectores y espacios vectoriales es clave para diseñar arquitecturas de redes neuronales eficientes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k8oCQJFRVdlB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8oCQJFRVdlB",
        "outputId": "c27db847-0af7-437b-bed0-681ecd19a8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector: [2, 3]\n",
            "Vector con NumPy: [2 3]\n"
          ]
        }
      ],
      "source": [
        "# Vector como lista\n",
        "v = [2, 3]\n",
        "print(\"Vector:\", v)\n",
        "\n",
        "# Con NumPy (mejor para matemáticas e IA)\n",
        "import numpy as np\n",
        "v = np.array([2, 3])\n",
        "print(\"Vector con NumPy:\", v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OJiMSfzSV7cI",
      "metadata": {
        "id": "OJiMSfzSV7cI"
      },
      "source": [
        "Aquí el vector $(3,2)$ puede interpretarse como “3 pasos al Norte y 2 al Este”.\n",
        "\n",
        "---\n",
        "\n",
        "### Visualización en el plano\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Position_vector.svg\"  alt=\"vector en el plano\" width=\"300\"/>\n",
        "\n",
        "Podemos dibujar el vector en python para que sea más intuitivo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DqV-Z3xBV9HM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DqV-Z3xBV9HM",
        "outputId": "911c8f50-a480-4508-8cb2-f0ef6cef16a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "v = np.array([2,3])\n",
        "\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0, color='black')\n",
        "plt.quiver(0,0,v[0],v[1],angles='xy',scale_units='xy',scale=1,color='red')\n",
        "plt.xlim(-1,5); plt.ylim(-1,5)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.title(\"Vector (3,2)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y-2jXdNDWDGU",
      "metadata": {
        "id": "y-2jXdNDWDGU"
      },
      "source": [
        "Esto muestra la flecha desde el origen $(0,0)$ hasta el punto $(3,2)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dt7F_yw-WoCu",
      "metadata": {
        "id": "Dt7F_yw-WoCu"
      },
      "source": [
        "### 1.1 Características principales de los vectores\n",
        "\n",
        "Un vector se puede entender desde distintos puntos de vista:\n",
        "\n",
        "1. **Colección ordenada de números**\n",
        "   Un vector es una colección ordenada de números, es decir, una secuencia finita y ordenada de valores reales. Esta representación es una forma clara y concisa de almacenar información, ya que el formato de tupla sugiere que los componentes pertenecen juntos en un orden preciso.\n",
        "\n",
        "   Ejemplo: $ (1.297, -2.35, 32.3, 29.874) $ Cada número en la secuencia es un componente del vector. En el contexto de la inteligencia artificial (IA), estos valores podrían representar un conjunto de características para un punto de datos individual en un conjunto de datos, donde cada elemento corresponde a una característica diferente (por ejemplo, altura, peso, edad, ingresos). Para datos de una casa, un vector podría ser (superficie, nº de habitaciones, precio)\n",
        "\n",
        "  \n",
        "   En programación, puede representarse como:\n",
        "\n",
        "   ```python\n",
        "   v = [1.297, -2.35, 32.3, 29.874]   # lista en Python\n",
        "   ```\n",
        "\n",
        "   Aunque las listas de Python pueden representar vectores, los arrays de NumPy son una representación más eficiente para cálculos en álgebra linea\n",
        "  \n",
        "   ```python\n",
        "   import numpy as np\n",
        "\n",
        "    v = np.array([1.297, -2.35, 32.3, 29.874]) # lista en Numpy\n",
        "   ```\n",
        "---\n",
        "\n",
        "2. **Componentes**\n",
        "  Un vector $\\vec{v} = (v_1, v_2, \\ldots, v_n)$ está definido por sus **componentes** $v_i$. Estos componentes son los valores numéricos que conforman el vector. En un espacio de características, cada dimensión del vector corresponde a una característica específica del dato que se representa. Los vectores se utilizan para describir cantidades que existen en más de una dimensión, a diferencia de los escalares que solo tienen una magnitud.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Vector_09.svg/2560px-Vector_09.svg.png\"  alt=\"componentes vector\" width=\"300\"/>\n",
        "\n",
        "* Ejemplo en 2D: $\\vec{v} = (3, 4)$.\n",
        "\n",
        "  * El componente $v_x=3$ indica cuánto se mueve en el eje horizontal (x-axis).\n",
        "\n",
        "  * El componente $v_y=4$ indica cuánto se mueve en el eje vertical (y-axis). En matemáticas y IA, los vectores se suelen representar como vectores columna para una notación más compacta y para facilitar las operaciones matriciales.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. **Magnitud y dirección**\n",
        "\n",
        "Un vector es una cantidad que posee tanto magnitud (o módulo) como dirección. Esta dualidad es lo que los distingue de los escalares, que son un único valor numérico que solo representa magnitud, sin dirección asociada.\n",
        "\n",
        " <img src=\"https://soradavid.wordpress.com/wp-content/uploads/2014/08/imagen-1-muestra-las-principales-caracterc3adsticas-de-un-vector.png\"  alt=\"magnitud y dirección  vector\" width=\"300\"/>\n",
        "\n",
        "La **magnitud** (también conocida como **norma** o **longitud**) es el \"tamaño\" del vector. En el espacio euclidiano n-dimensional ($\\mathbb{R}^n$), la magnitud (o norma euclidiana, también conocida como 2-norma) de un vector $\\vec{x} = (x_1, \\ldots, x_n)$ se calcula como: $$ |\\vec{x}| = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2} $$ Esta fórmula proviene directamente del Teorema de Pitágoras, extendido a dimensiones superiores. Las normas son funciones que miden el tamaño de un vector y deben satisfacer tres propiedades clave: positividad definida (ser mayor o igual a cero y cero solo si el vector es nulo), homogeneidad positiva (escalar el vector escala su norma) y la desigualdad triangular. Esta es una de las \"p-normas\".\n",
        "\n",
        "  * Ejemplo: si $\\vec{x}=(3,4)$, entonces $|\\vec{x}| = \\sqrt{3^2+4^2} = 5$.\n",
        "\n",
        "La **dirección** indica hacia dónde apunta el vector. En un espacio bidimensional (2D), puede calcularse con un ángulo: $$ \\theta = \\arctan\\left(\\frac{y}{x}\\right) $$ Para $(3,4)$, el ángulo es $\\arctan(4/3) \\approx 53^\\circ$. De manera más general, la dirección de un vector está intrínsecamente relacionada con el concepto de producto interno (o producto escalar). El **producto interno** permite definir el ángulo $\\alpha$ entre dos vectores $\\vec{x}$ e $\\vec{y}$ mediante la relación $\\langle\\vec{x}, \\vec{y}\\rangle = |\\vec{x}||\\vec{y}| \\cos\\alpha$. Esta relación es tan fundamental que, en espacios vectoriales abstractos donde la intuición geométrica del ángulo no es evidente, se utiliza para definir el ángulo entre vectores. En el aprendizaje automático, los **gradientes** de una función son vectores que indican la dirección de máximo crecimiento de la función en un punto dado.\n",
        "\n",
        "\n",
        "   **Ejemplo en Python**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "krl_InUbWtI-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krl_InUbWtI-",
        "outputId": "5b2e8ea9-b8ef-4729-8aa0-a73d74aaaa6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magnitud: 5.0\n",
            "Dirección: 53.13010235415598\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "v = np.array([3,4])\n",
        "magnitud = np.linalg.norm(v)\n",
        "direccion = np.degrees(np.arctan2(v[1], v[0]))\n",
        "print(\"Magnitud:\", magnitud)       # 5.0\n",
        "print(\"Dirección:\", direccion)     # 53.13 grados\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78Q_hB4Xa3w3",
      "metadata": {
        "id": "78Q_hB4Xa3w3"
      },
      "source": [
        "**ACTIVIDAD 1 – Representar y calcular magnitud**\n",
        "**Objetivo**: comprender la representación y longitud de un vector.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Define el vector `v = (3,4)` como lista en Python y como `np.array`.\n",
        "  2. Calcula su magnitud usando la fórmula de Pitágoras (`math.sqrt`).\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Repite el cálculo con `np.linalg.norm`.\n",
        "  4\\. Representa el vector en el plano con Matplotlib.\n",
        "\n",
        "* **Reto**\n",
        "  5\\. Crea una función `magnitud(v)` que calcule la longitud de cualquier vector en 2D o 3D.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZJ8smOrTa3-f",
      "metadata": {
        "id": "ZJ8smOrTa3-f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.0\n",
            "5.0\n",
            "[2, 2, 2]\n",
            "3.4641016151377544\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "#Nivel basico\n",
        "a = np.array([3,4])\n",
        "b = [3,4]\n",
        "magnitud = math.sqrt(b[0]** 2 + b[1]** 2)\n",
        "print(magnitud)\n",
        "#Nivel intermedio\n",
        "magnitud_2 = np.linalg.norm(a)\n",
        "print(magnitud_2)\n",
        "\n",
        "#Reto\n",
        "def magnitud1():\n",
        "    longitud = 0\n",
        "    if dimension == 2:\n",
        "        longitud += math.sqrt(vector[0] ** 2 + vector[1] ** 2)\n",
        "    else:\n",
        "        longitud += math.sqrt(vector[0] ** 2 + vector[1] ** 2 + vector[2] ** 2)\n",
        "    print(longitud)\n",
        "\n",
        "dimension = int(input(\"Dimension 2/3¿?\"))\n",
        "if dimension == 2:\n",
        "    x = int(input(\"Valor para vector[0]\"))\n",
        "    y = int(input(\"Valor para vector[1]\"))\n",
        "    vector  =[x,y]\n",
        "elif dimension == 3:\n",
        "    x = int(input(\"Valor para vector[0]\"))\n",
        "    y = int(input(\"Valor para vector[1]\"))\n",
        "    z = int(input(\"Valor para vector[2]\"))\n",
        "    vector  = [x,y,z]\n",
        "else:\n",
        "    print(\"Valor no valido\")\n",
        "print(vector)\n",
        "magnitud1()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-zQ6qWJfW4Rm",
      "metadata": {
        "id": "-zQ6qWJfW4Rm"
      },
      "source": [
        "\n",
        "4. **Interpretación geométrica**\n",
        "\n",
        "Las operaciones básicas con vectores tienen interpretaciones geométricas claras que son fundamentales para entender cómo los algoritmos de IA manipulan los datos. Un espacio vectorial es una estructura matemática que define cómo los vectores pueden ser sumados y multiplicados por escalares, y estas operaciones deben satisfacer ciertas propiedades para asegurar la coherencia del espacio\n",
        "\n",
        "* **Suma de vectores**: Equivale a **colocar una flecha tras otra**, con el resultado siendo una **traslación**. La suma de dos vectores, **x + y**, produce un nuevo vector donde cada componente es la suma de los componentes correspondientes de **x** e **y**. Esta operación debe cumplir propiedades como la conmutatividad y la asociatividad, y el resultado debe permanecer dentro del mismo espacio vectorial (propiedad de aditividad)\n",
        "\n",
        "  * **Ejemplo**: Si sumamos el vector $(2,1)$ con el vector $(1,3)$, obtenemos $(2+1, 1+3) = (3,4)$. Geométricamente, esto es como mover el origen del segundo vector al final del primero y el resultado es el vector que va desde el origen del primero hasta el final del segundo.\n",
        "\n",
        "\n",
        "     <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Vector_addition.svg/2560px-Vector_addition.svg.png\"  alt=\"Suma de vectores\" width=\"300\"/>\n",
        "\n",
        "   \n",
        "* **Multiplicación por un escalar**:  Esta operación **estira o encoge el vector en la misma dirección**, o invierte su dirección si el escalar es negativo. Cuando un vector v se multiplica por un escalar c, el nuevo vector $c\\cdot\\vec{v}$ tiene una magnitud que es $|c|$ veces la magnitud de v, y su dirección es la misma si c > 0 o la opuesta si c < 0. Esta propiedad se conoce como homogeneidad positiva y es una de las características clave de las normas vectoriales\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Scalar_multiplication_by_r%3D3.svg/2560px-Scalar_multiplication_by_r%3D3.svg.png\"  alt=\"Multiplicación por un escalar\" width=\"250\"/>\n",
        "   \n",
        "  * **Ejemplo**: Si multiplicamos el vector $(2,1)$ por el escalar $3$, obtenemos $(3 \\cdot 2, 3 \\cdot 1) = (6,3)$. El vector resultante es tres veces más largo y apunta en la misma dirección que el original.\n",
        "\n",
        "---\n",
        "\n",
        "5. **Conexión con IA**\n",
        "\n",
        "Los vectores y las matrices son la **base fundamental para la representación y manipulación de datos en la Inteligencia Artificial (IA)**, especialmente en el aprendizaje automático y las redes neuronales.\n",
        "\n",
        "* **Componentes**: En IA, los componentes de un vector suelen representar las **características (features) de un dato**. Cada dimensión del vector corresponde a una característica específica.\n",
        "    * **Ejemplo**: En un conjunto de datos de estudiantes, un vector podría contener la nota de un alumno en cada asignatura, donde cada componente es la calificación de una materia diferente. De manera similar, para una casa, un vector podría ser (superficie, nº de habitaciones, precio).\n",
        "* **Magnitud**: La magnitud (o norma) de un vector en IA puede indicar el **“nivel general” o la intensidad de un dato**. Las normas son cruciales para determinar la similitud entre puntos de datos, así como para medir y controlar la complejidad de los modelos de redes neuronales.\n",
        "  * **Ejemplo**: En el contexto de un alumno, la magnitud del vector de sus notas podría representar su rendimiento global. En algoritmos de aprendizaje no supervisado, la distancia entre puntos (derivada de la magnitud) se utiliza para agrupar datos en clusters.\n",
        "* **Dirección**: La dirección de un vector es vital porque representa el **patrón intrínseco del dato**. Es particularmente importante al **comparar similitudes con otros datos**. El **producto interno (o producto escalar)** de dos vectores es una herramienta fundamental que permite cuantificar esta similitud y definir el ángulo entre ellos.\n",
        "  * La **similitud del coseno**, por ejemplo, mide cuánto se mueven las características de dos muestras de datos juntas, sin tener en cuenta su magnitud.\n",
        "* En el entrenamiento de modelos de IA, la dirección también es fundamental en los algoritmos de optimización. Por ejemplo, los **gradientes** son vectores que indican la dirección de máximo crecimiento de una función. El **método del gradiente descendente** se basa en mover los parámetros del modelo en la dirección opuesta al gradiente para minimizar una función de pérdida, lo cual es esencial para el entrenamiento de redes neuronales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TyJti_d7fPWj",
      "metadata": {
        "id": "TyJti_d7fPWj"
      },
      "source": [
        "### 1.2 Vectores en Machine Learning e Inteligencia Artificial\n",
        "\n",
        "Los **vectore** son la **forma estándar y fundamental de representar la información en la Inteligencia Artificial (IA)**. Cada dato, por muy complejo que sea, acaba representado como una **colección ordenada de números**. Las matemáticas de la IA se basan en un marco matemático que dicta cómo se representan, procesan y analizan los datos. El álgebra lineal, en particular, se encarga de los espacios vectoriales y las transformaciones, siendo el núcleo de las computaciones de la IA.\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.1 Representación de datos simples\n",
        "\n",
        "Cada vector es un conjunto de **características** (o features) de un ejemplo. En el aprendizaje automático (Machine Learning), cada punto de datos se puede representar como un vector en un **espacio de características**, donde cada dimensión del vector corresponde a una característica específica. La representación de datos en espacios multi-dimensionales es fundamental para tareas como la clasificación, el clustering y la regresión.\n",
        "Ejemplo: Las notas de un alumno en tres asignaturas, como (8.5, 7.0, 9.0), donde cada componente es la calificación en una materia diferente.\n",
        "\n",
        "  * **Ejemplo**: Las notas de un alumno en tres asignaturas, como (8.5, 7.0, 9.0), donde cada componente es la calificación en una materia diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F1f71U5sfTTf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1f71U5sfTTf",
        "outputId": "06f8bb35-e472-4374-c1d4-e4d0098f3e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6 7 8]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "notas = np.array([8.5, 7.0, 9.0])\n",
        "print(notas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gWiOgOvQflvK",
      "metadata": {
        "id": "gWiOgOvQflvK"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.2.2 Coordenadas en espacios geométricos\n",
        "\n",
        "Un vector puede representar un punto en el plano (2D) o en el espacio (3D), y de manera más general, en espacios multidimensionales. Los espacios vectoriales proporcionan la base para representar datos en **espacios de alta dimensión**.\n",
        "\n",
        "* **Ejemplo**: Un $ \\text{punto} = (10, 13, 5) $ Este tipo de representación es muy útil para **visualizar** cómo se agrupan los datos, utilizando técnicas de reducción de dimensionalidad para proyectar datos de alta dimensión en 2D o 3D y observar patrones, clusters y outliers.\n",
        "\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/3D_Cartesian.svg/330px-3D_Cartesian.svg.png\"  alt=\"punto 3d\" width=\"300\"/>\n",
        "\n",
        "\n",
        "Este tipo de representación es muy útil para **visualizar** cómo se agrupan los datos.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.3 Características de objetos\n",
        "\n",
        "Un objeto real se describe mediante varias medidas, que se agrupan en un vector de características. Un ejemplo clásico es el **conjunto de datos Iris**.\n",
        "\n",
        "* Ejemplo clásico (dataset Iris): $ \\text{flor} = (5.1,\\ 3.5,\\ 1.4,\\ 0.2) $ Esta representación describe una flor con medidas de longitud y ancho de sépalos y pétalos. Cada una de estas cuatro medidas es una característica, y juntas forman un vector en $\\mathbb{R}^4$. Para trabajar con estos vectores en programación, se utilizan eficientemente arrays de NumPy.\n",
        "\n",
        "  <img src=\"https://miro.medium.com/1*H2UmG5L1I5bzFCW006N5Ag.png\"  alt=\"dataset Iris\" width=\"600\"/>\n",
        "\n",
        "\n",
        "```python\n",
        "flor = np.array([5.1, 3.5, 1.4, 0.2])\n",
        "print(flor)\n",
        "# Esto sería un array de NumPy que representa la flor, útil para cálculos eficientes.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.4 Procesamiento del lenguaje natural (NLP)\n",
        "\n",
        "En NLP, las palabras o frases se transforman en **vectores en un espacio de alta dimensión**, conocidos como word embeddings.\n",
        "\n",
        "Palabras con significados parecidos tienen vectores cercanos en este espacio. Los word embeddings, como Word2Vec y GloVe, representan palabras en un espacio de menor dimensión mientras preservan las relaciones semánticas entre ellas.\n",
        "\n",
        "* Ejemplo: “rey” y “reina” están más próximos entre sí que “rey” y “mesa”, debido a que los modelos matemáticos capturan las relaciones semánticas entre palabras. Las técnicas de reducción de dimensionalidad como PCA pueden aplicarse a estos embeddings para simplificar tareas como la similitud semántica o el agrupamiento de textos.\n",
        "\n",
        "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Word_embedding_illustration.svg/1920px-Word_embedding_illustration.svg.png\"  alt=\"word embeddings\" width=\"300\"/>\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.5 Imágenes y señales\n",
        "\n",
        "Una imagen o una señal se puede ver como un vector o una matriz, lo que permite su procesamiento mediante algoritmos de IA\n",
        "\n",
        "* **Imágenes**: Una imagen puede representarse como una gran matriz de valores de píxeles, donde cada píxel corresponde a la intensidad de color. Por ejemplo, una imagen de 256x256 píxeles puede representarse como una matriz de 256x256 (para escala de grises) o 256x256x3 (para imágenes RGB). Las **Redes Neuronales Convolucionales (CNNs)**, por ejemplo, aplican operaciones matemáticas para identificar características clave como bordes y texturas en imágenes, lo que es crucial para la clasificación de objetos o el reconocimiento facial.\n",
        "\n",
        "* **Señales** (audio o sensores): Las señales, como las de audio o las captadas por sensores, se transforman en vectores para su análisis y clasificación [Fuente original del usuario]. Las **Transformadas de Fourier** y las **Transformadas Wavelet** son herramientas matemáticas utilizadas para procesar señales y extraer características importantes, permitiendo a los modelos de IA operar en el dominio de la frecuencia para identificar patrones o reducir la dimensionalidad de los datos.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.6 Espacios de características\n",
        "\n",
        "En Machine Learning (ML), un vector es un punto en un espacio de características.\n",
        "\n",
        "* Cada dimensión corresponde a un atributo o característica.\n",
        "* Los algoritmos, como el K-Nearest Neighbors (KNN) o los métodos de clustering, trabajan **midiendo distancias** entre estos puntos para encontrar patrones, similitudes o agrupaciones en los datos. La elección de una base para este espacio de características es crucial para transformar los datos de entrada en una representación más útil para el modelo. Las técnicas de reducción de dimensionalidad como PCA también operan en estos espacios, proyectando los datos en nuevas direcciones para capturar la mayor varianza y simplificar el análisis\n",
        "\n",
        "📌 Ejemplo visual:\n",
        "\n",
        "* Alumnos representados por $(\\text{horas de estudio}, \\text{nota en examen})$.\n",
        "* Cada alumno es un **punto en 2D**.\n",
        "* El agrupamiento de puntos muestra **patrones de aprendizaje**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ww6UloWwo04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7ww6UloWwo04",
        "outputId": "df255ed5-a454-471e-bbd2-f4d7f6395ce2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Datos ficticios: horas de estudio y notas\n",
        "horas = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "notas = [40, 45, 50, 60, 65, 70, 80, 85]\n",
        "\n",
        "plt.scatter(horas, notas, color='blue')\n",
        "plt.xlabel(\"Horas de estudio\")\n",
        "plt.ylabel(\"Nota en examen\")\n",
        "plt.title(\"Alumnos representados como vectores (horas, nota)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2qX72Sijhj5C",
      "metadata": {
        "id": "2qX72Sijhj5C"
      },
      "source": [
        "### 1.3. Operaciones con vectores\n",
        "\n",
        "En Machine Learning, los vectores se manipulan con operaciones matemáticas fundamentales que son cruciales para **comparar datos, medir similitudes** y construir algoritmos. El álgebra lineal, que estudia los espacios vectoriales y sus transformaciones, constituye el núcleo de los cálculos de la IA.\n",
        "\n",
        "\n",
        "---\n",
        "#### 1.3.1 Suma de vectores\n",
        "\n",
        "La suma de vectores se realiza elemento a elemento. Si tenemos dos vectores $\\mathbf{x} = (x_1, \\ldots, x_n)$ e $\\mathbf{y} = (y_1, \\ldots, y_n)$, su suma es $\\mathbf{x} + \\mathbf{y} = (x_1+y_1, \\ldots, x_n+y_n)$.\n",
        "\n",
        "$$\n",
        "(2,3)+(1,4)=(3,7)\n",
        "$$\n",
        "\n",
        "👉 **Interpretación**: Geométricamente, la suma de vectores es una traslación, donde se coloca un vector a continuación del otro.\n",
        "\n",
        "📌 En geometría, esta operación se representa comúnmente con la **regla del paralelogramo**. La propiedad de aditividad de un espacio vectorial establece que la suma de dos vectores cualesquiera sigue siendo un vector dentro del mismo espacio.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Vector_addition.svg/2560px-Vector_addition.svg.png\"  alt=\"Suma de vectores\" width=\"300\"/>\n",
        "\n",
        "En el aprendizaje automático, la suma de vectores es útil en muchos algoritmos, especialmente en la optimización, donde los pesos de un modelo se ajustan sumando o restando valores de gradiente. En Python, las arrays de NumPy soportan esta operación de forma predeterminada con el operador +.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YwUm_uxqbr3d",
      "metadata": {
        "id": "YwUm_uxqbr3d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "x = np.array([2, 3])\n",
        "y = np.array([1, 4])\n",
        "\n",
        "# Suma de vectores\n",
        "suma = x + y\n",
        "\n",
        "print(\"x + y =\", suma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yZ2pDNJtbsHF",
      "metadata": {
        "id": "yZ2pDNJtbsHF"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.12 Multiplicación por un escalar\n",
        "\n",
        "En esta operación, cada componente del vector se multiplica por un número real (escalar). Si un vector $\\mathbf{x} = (x_1, \\ldots, x_n)$ se multiplica por un escalar $c \\in \\mathbb{R}$, el resultado es $c\\mathbf{x} = (cx_1, \\ldots, cx_n)$.\n",
        "\n",
        "$$\n",
        "2\\cdot(2,3)=(4,6)\n",
        "$$\n",
        "\n",
        "👉 Interpretación: Geométricamente, la multiplicación por un escalar **estira o encoge el vector**, manteniendo la misma dirección si el escalar es positivo, o invirtiendo su dirección si es negativo. Esta es la propiedad de homogeneidad positiva de una norma.\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Scalar_multiplication_by_r%3D3.svg/2560px-Scalar_multiplication_by_r%3D3.svg.png\"  alt=\"Multiplicación por un escalar\" width=\"250\"/>\n",
        "\n",
        "En Machine Learning, la multiplicación por un escalar se utiliza al ajustar los pesos y parámetros de un modelo, por ejemplo, escalando el gradiente durante procesos de optimización como el descenso de gradiente. La tasa de aprendizaje en el descenso de gradiente es un escalar que determina el tamaño del paso para actualizar los parámetros del modelo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qrR0uH57bv_c",
      "metadata": {
        "id": "qrR0uH57bv_c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos el vector\n",
        "x = np.array([2, 3])\n",
        "\n",
        "# Definimos el escalar\n",
        "c = 2\n",
        "\n",
        "# Multiplicación por escalar\n",
        "resultado = c * x\n",
        "\n",
        "print(f\"{c} * {x} = {resultado}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yNsk-SaobQGk",
      "metadata": {
        "id": "yNsk-SaobQGk"
      },
      "source": [
        "**ACTIVIDAD 2 – Suma, resta y producto escalar**\n",
        "**Objetivo**: practicar operaciones básicas con vectores.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Declara `a = (2,1)` y `b = (1,3)`. Calcula su suma y resta con NumPy.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Calcula el producto escalar con un bucle `for`.\n",
        "  3\\. Calcula el producto escalar con `np.dot(a, b)`.\n",
        "\n",
        "* **Reto**\n",
        "  4\\. Implementa una función `similitud_coseno(a, b)` que devuelva el coseno del ángulo entre dos vectores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ugNblW1ZbQTQ",
      "metadata": {
        "id": "ugNblW1ZbQTQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 4]\n",
            "[ 1 -2]\n",
            "5\n",
            "5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(0.7071067811865475)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "#Nivel basico\n",
        "a = np.array([2,1])\n",
        "b = np.array([1,3])\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "#Nivel intermedio\n",
        "for i in a:\n",
        "    if i ==  a[0]:\n",
        "        resultado1 = a[0] * b[0]\n",
        "    else:\n",
        "        resultado2 = a[1] * b[1]\n",
        "print(resultado1 + resultado2)\n",
        "\n",
        "f = np.dot(a,b)\n",
        "print(f)\n",
        "#Reto\n",
        "def similitud_coseno(a, b):\n",
        "    producto_punto = np.dot(a, b)\n",
        "    norma_a = np.linalg.norm(a)\n",
        "    norma_b = np.linalg.norm(b)\n",
        "    \n",
        "    if norma_a == 0 or norma_b == 0:\n",
        "        return 0 \n",
        "    \n",
        "    return producto_punto / (norma_a * norma_b)\n",
        "similitud_coseno(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0yuMre9qbwI1",
      "metadata": {
        "id": "0yuMre9qbwI1"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.3 Norma (longitud del vector)\n",
        "\n",
        "La norma de un vector, a menudo referida como su magnitud o longitud, mide el \"tamaño\" del vector.\n",
        "La norma euclidiana (también conocida como 2-norma) de un vector $\\vec{v}=(x_1,x_2,\\ldots,x_n)$ se calcula como: $$ |\\vec{v}|=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2} $$\n",
        "\n",
        "\n",
        "* Ejemplo: $$ |(2,3,5)|=\\sqrt{2^2+3^2+5^2}=\\sqrt{4+9+25}=\\sqrt{38}\\approx6.16 $$ Esta fórmula se deriva directamente del Teorema de Pitágoras, generalizado a dimensiones superiores. Una función para medir la magnitud de un vector se define como norma si satisface tres propiedades clave: positividad definida, homogeneidad positiva y la desigualdad triangular\n",
        "\n",
        "Existen otras p-normas, como la 1-norma (distancia de Manhattan), que es la suma de los valores absolutos de los componentes, y la $\\infty$-norma, que es el valor absoluto máximo de los componentes.\n",
        "\n",
        "En Machine Learning, las nociones de magnitud y distancia son críticas para determinar la similitud entre puntos de datos, así como para medir y controlar la complejidad de los modelos de redes neuronales. Por ejemplo, el error cuadrático medio (MSE) es esencialmente la distancia euclidiana escalada entre la predicción y la verdad fundamental. Las normas se utilizan para controlar la complejidad de los modelos durante el entrenamiento, penalizando coeficientes grandes para fomentar la simplicidad y mejorar la generalización.\n",
        "\n",
        "En Python, la magnitud euclidiana de un vector puede calcularse eficientemente usando ``np.linalg.norm``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSvzdzA0asUo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSvzdzA0asUo",
        "outputId": "b3c415a3-af4f-4467-b65c-da0b3e9c525e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norma Euclidiana (2-norma): 6.164414002968976\n",
            "Norma 1: 10.0\n",
            "Norma infinito: 5.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos el vector\n",
        "v = np.array([2, 3, 5])\n",
        "\n",
        "# Norma Euclidiana (2-norma)\n",
        "norm_2 = np.linalg.norm(v)\n",
        "\n",
        "# Norma 1 (suma de valores absolutos)\n",
        "norm_1 = np.linalg.norm(v, ord=1)\n",
        "\n",
        "# Norma infinito (máximo valor absoluto)\n",
        "norm_inf = np.linalg.norm(v, ord=np.inf)\n",
        "\n",
        "print(\"Norma Euclidiana (2-norma):\", norm_2)\n",
        "print(\"Norma 1:\", norm_1)\n",
        "print(\"Norma infinito:\", norm_inf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ucKhg7bashE",
      "metadata": {
        "id": "3ucKhg7bashE"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.4 Normalización\n",
        "\n",
        "La **normalización** de un vector consiste en **dividir el vector por su norma**, de forma que el vector resultante tenga una longitud de 1. $$ \\hat{v}=\\frac{\\vec{v}}{|\\vec{v}|} $$\n",
        "\n",
        "\n",
        "\n",
        "👉 **Muy útil para comparar vectores en la misma escala**. Esta técnica es fundamental en IA, ya que permite estandarizar conjuntos de datos para asegurar que las diferentes características tengan el mismo rango e influencia en el modelo, mejorando la precisión de las predicciones. En el entrenamiento de modelos de redes neuronales, a menudo se estandarizan los datos restando la media y dividiendo por la desviación estándar, lo que asegura que todas las características tengan una media de 0 y una varianza de 1\n",
        "\n",
        " <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Vector_normalization.svg/800px-Vector_normalization.svg.png\" width=\"100\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rpezHClicAvY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpezHClicAvY",
        "outputId": "7e7dcec4-ef0e-4ccf-95bd-0317baf40d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Producto escalar SIN normalizar: 30\n",
            "Producto escalar CON normalización: 0.6\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos dos vectores\n",
        "a = np.array([10, 0])\n",
        "b = np.array([3, 4])\n",
        "\n",
        "# Producto escalar sin normalizar\n",
        "dot_no_norm = np.dot(a, b)\n",
        "\n",
        "# Normalizamos los vectores\n",
        "a_norm = a / np.linalg.norm(a)\n",
        "b_norm = b / np.linalg.norm(b)\n",
        "\n",
        "# Producto escalar con vectores normalizados (similitud coseno)\n",
        "dot_norm = np.dot(a_norm, b_norm)\n",
        "\n",
        "print(\"Producto escalar SIN normalizar:\", dot_no_norm)\n",
        "print(\"Producto escalar CON normalización:\", dot_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MZD-y8vFcA64",
      "metadata": {
        "id": "MZD-y8vFcA64"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.5 Producto escalar (dot product)\n",
        "\n",
        "El **producto escalar** (o producto interno) de dos vectores $\\vec{u}=(u_1, u_2, \\ldots, u_n)$ y $\\vec{v}=(v_1, v_2, \\ldots, v_n)$ se calcula multiplicando cada componente correspondiente y luego sumando los resultados. $$ \\vec{u}\\cdot\\vec{v}=\\sum_i u_i v_i $$\n",
        "Ejemplo: $$ (2,3,5)\\cdot(1,0,4)=2\\cdot1+3\\cdot0+5\\cdot4=2+0+20=22 $$\n",
        "\n",
        "👉**Interpretación**: El producto escalar **mide qué tan alineados están los vectores**. Es una forma de cuantificar la similitud entre dos vectores\n",
        "\n",
        "* Si el resultado es grande y positivo (cuando los vectores se normalizan), significa que los vectores apuntan en direcciones parecidas o tienen una alta similitud. La similitud coseno es precisamente el producto interno de dos vectores normalizados y se usa para medir cuán similares son las características de dos muestras de datos sin considerar su magnitud.\n",
        "\n",
        "* Si el resultado es cero, los vectores son perpendiculares (ortogonales), lo que significa que no tienen una relación lineal o \"no contienen información\" el uno del otro.\n",
        "\n",
        "En Machine Learning, los productos escalares son una herramienta fundamental para definir la ortogonalidad y el ángulo entre vectores, lo que es esencial para algoritmos que miden la similitud o la distancia. En Python, se puede calcular con la función ```np.dot```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_u-9gS4CaoOV",
      "metadata": {
        "id": "_u-9gS4CaoOV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "\n",
        "# Producto escalar\n",
        "dot_product = np.dot(u, v)\n",
        "\n",
        "print(\"Producto escalar:\", dot_product)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BNXlCYZ_aok0",
      "metadata": {
        "id": "BNXlCYZ_aok0"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.6 Distancia entre vectores\n",
        "\n",
        "La **distancia euclidiana** entre dos vectores $\\vec{u}$ y $\\vec{v}$ mide lo distintos que son. Se calcula como la norma euclidiana de la diferencia entre los vectores: $$ d(\\vec{u},\\vec{v})=|\\vec{u}-\\vec{v}| = \\sqrt{(u_1-v_1)^2 + (u_2-v_2)^2 + \\cdots + (u_n-v_n)^2} $$\n",
        "\n",
        "* Ejemplo: $$ d((2,3,5),(1,0,4))=|(2-1, 3-0, 5-4)|=|(1,3,1)|=\\sqrt{(1)^2+(3)^2+(1)^2}=\\sqrt{1+9+1}=\\sqrt{11}\\approx3.316 $$\n",
        "\n",
        "👉 En Machine Learning, las nociones de distancia son **críticas para determinar la similitud entre puntos de datos**. Se usa ampliamente en algoritmos de **clustering** (agrupamiento de datos en función de su cercanía), **K-Nearest Neighbors (KNN)** (para clasificar puntos de datos basándose en la mayoría de votos de sus vecinos más cercanos) y **detección de anomalías** (identificando puntos de datos que se desvían significativamente de los patrones esperados).\n",
        "\n",
        "En Python, la distancia euclidiana se puede calcular usando ``np.linalg.norm(x - y, ord=2)``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xkZ-0cpxbPC3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkZ-0cpxbPC3",
        "outputId": "df6fe00e-cfdb-4a02-a60b-3b562fe5de9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 3.3166247903554\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "\n",
        "# Distancia euclidiana\n",
        "dist_euclidiana = np.linalg.norm(u - v)\n",
        "\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XcCIvMFqblZN",
      "metadata": {
        "id": "XcCIvMFqblZN"
      },
      "source": [
        "**ACTIVIDAD 3 – Comparar vectores**\n",
        "**Objetivo**: entender diferencias entre magnitud y distancia.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Calcula la norma de `u = (2,3,5)` y `v = (1,0,4)` con `np.linalg.norm`.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Calcula la distancia euclidiana entre `u` y `v` con la fórmula y con `np.linalg.norm(u-v)`.\n",
        "\n",
        "* **Reto**\n",
        "  3\\. Genera 5 vectores aleatorios en 3D con `np.random.randint` y calcula cuál es el par más cercano entre ellos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21ssutz8blk3",
      "metadata": {
        "id": "21ssutz8blk3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 3.3166247903554\n",
            "[[5 8 7]\n",
            " [4 4 4]\n",
            " [1 9 7]\n",
            " [9 6 5]\n",
            " [9 3 8]]\n",
            "\n",
            "El par más cercano de vectores es:\n",
            "[5 8 7] y [1 9 7] con una distancia de 4.123105625617661\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "dist_euclidiana = np.linalg.norm(u - v)\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n",
        "\n",
        "#Reto\n",
        "vectores = 5\n",
        "array_aux = []\n",
        "\n",
        "for i in range(vectores):\n",
        "    x = np.random.randint(1, 10)\n",
        "    y = np.random.randint(1, 10)\n",
        "    z = np.random.randint(1, 10)\n",
        "    array_aux.append([x, y, z])\n",
        "\n",
        "array_aux = np.array(array_aux)\n",
        "print(array_aux) \n",
        "\n",
        "distancias = np.linalg.norm(array_aux[:, np.newaxis] - array_aux, axis=2)\n",
        "\n",
        "np.fill_diagonal(distancias, np.inf)\n",
        "indice_min = np.unravel_index(np.argmin(distancias), distancias.shape)\n",
        "\n",
        "vector1 = array_aux[indice_min[0]]\n",
        "vector2 = array_aux[indice_min[1]]\n",
        "distancia_min = distancias[indice_min]\n",
        "\n",
        "print(f\"\\nEl par más cercano de vectores es:\\n{vector1} y {vector2} con una distancia de {distancia_min}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lMUIHuttbPQG",
      "metadata": {
        "id": "lMUIHuttbPQG"
      },
      "source": [
        "---\n",
        "#### 1.3.7 Distancia vs. Similitud coseno\n",
        "\n",
        "La elección entre usar la **distancia** o la **similitud coseno** para comparar vectores en Machine Learning depende fundamentalmente de si la magnitud absoluta o la dirección (patrón) de los vectores es más relevante para el problema en cuestión. Ambas son medidas de la relación entre vectores y son críticas en la IA para determinar la similitud entre puntos de datos.\n",
        "\n",
        "* **Distancia (generalmente Distancia Euclidiana)**:\n",
        "\n",
        "  * La distancia euclidiana mide el \"tamaño\" de la diferencia entre dos vectores. Es una medida de cuán \"lejos\" están dos puntos en el espacio.\n",
        "  * **Importa la magnitud absoluta**: La distancia es sensible a la longitud o magnitud de los vectores. Un vector más largo tendrá una mayor distancia de otro vector si su magnitud es muy diferente, incluso si apuntan en la misma dirección. Esto se ilustra con la fórmula de la norma euclidiana, que considera la suma de los cuadrados de los componentes.\n",
        "  * **Ejemplo**: Si un vector de datos de una casa (superficie, precio) es (80, 100000) y otro es (160, 200000), la distancia entre ellos será grande, reflejando las grandes diferencias en sus valores absolutos.\n",
        "\n",
        "**En Machine Learning**: Las nociones de magnitud y distancia son críticas para determinar la similitud entre puntos de datos. Algoritmos de aprendizaje no supervisado, como el clustering, separan los puntos de datos en grupos basándose en sus distancias mutuas. Sin embargo, en espacios de alta dimensión, las métricas de distancia tradicionales pueden perder su efectividad, un fenómeno conocido como la \"maldición de la dimensionalidad\".\n",
        "\n",
        "* **Similitud Coseno**:\n",
        "  * El producto interno (o escalar) de dos vectores normalizados es una medida de similitud frecuentemente utilizada.\n",
        "  * **Importa solo la dirección (patrón)**: La similitud coseno mide el coseno del ángulo entre dos vectores. Al normalizar los vectores (dividiéndolos por su norma para que tengan longitud 1), esta métrica se vuelve **independiente de su magnitud**, enfocándose exclusivamente en su orientación relativa.\n",
        "  * **Ejemplo**: Volviendo al ejemplo de la casa, si la casa (160, 200000) se normaliza a (0.64, 0.77) y la (80, 100000) a (0.64, 0.77), su similitud coseno sería máxima (1), indicando el mismo \"patrón\" o proporción, a pesar de que sus valores absolutos son muy diferentes.\n",
        "\n",
        "**En Machine Learning**: La similitud coseno es una herramienta fundamental en IA, especialmente cuando la dirección (el \"patrón\") es más informativa que la magnitud. Se utiliza para saber \"cuánto se mueven las características de dos muestras de datos juntas\".\n",
        "\n",
        "* **Muy relevante en embeddings de texto e imágenes**:\n",
        "  * **Procesamiento de Lenguaje Natural (NLP)**: Las palabras se transforman en vectores de alta dimensión llamados word embeddings. En estos espacios, palabras con significados parecidos tienen vectores cercanos, y la similitud coseno permite cuantificar esta cercanía semántica, ya que las longitudes de los vectores de palabras individuales no suelen ser tan importantes como su orientación mutua.\n",
        "  * **Imágenes**: En computer vision y reconocimiento de imágenes, los vectores representan patrones visuales. La similitud coseno ayuda a comparar estos patrones sin que el brillo general o el tamaño de un objeto dominen la comparación.\n",
        "  * **Redes Neuronales**: Se describe una red neuronal como una función multivariable que toma un vector como entrada y produce otro vector como salida. La manipulación de vectores y espacios vectoriales es clave para diseñar arquitecturas de redes neuronales eficientes. La similitud coseno puede usarse para evaluar la relación entre estas representaciones vectoriales internas.\n",
        "\n",
        "En resumen, mientras que la **distancia** proporciona una medida del espacio absoluto que separa dos puntos, la **similitud coseno** ofrece una perspectiva de su alineación direccional. Comprender cuándo aplicar cada una es vital para el desarrollo efectivo de modelos de IA, ya que permite a los algoritmos interpretar mejor las relaciones subyacentes en los datos.\n",
        "\n",
        "---\n",
        "### Código ejemplo en Python (NumPy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dRrfUvNFhzn9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRrfUvNFhzn9",
        "outputId": "43b63b9f-dc76-41f5-a22d-b10aefb3609e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 100000.03199999488\n",
            "Similitud coseno: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dos vectores: mismo patrón pero distinta magnitud\n",
        "a = np.array([80, 100000])\n",
        "b = np.array([160, 200000])\n",
        "\n",
        "# --- Distancia Euclidiana ---\n",
        "dist_euclidiana = np.linalg.norm(a - b)\n",
        "\n",
        "# --- Similitud Coseno ---\n",
        "# Normalizamos ambos vectores\n",
        "a_norm = a / np.linalg.norm(a)\n",
        "b_norm = b / np.linalg.norm(b)\n",
        "\n",
        "# Producto escalar entre los vectores normalizados\n",
        "sim_coseno = np.dot(a_norm, b_norm)\n",
        "\n",
        "# La distancia euclidiana es enorme porque los valores absolutos de los vectores son muy distintos.\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n",
        "\n",
        "# La similitud coseno es 1.0, lo que indica que los vectores están perfectamente alineados (mismo patrón de proporciones).\n",
        "print(\"Similitud coseno:\", sim_coseno)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wRKGc6RBhYbL",
      "metadata": {
        "id": "wRKGc6RBhYbL"
      },
      "source": [
        "### Ejercicio resuleto en Python con NumPy\n",
        "\n",
        "Imagina que tienes los resultados de dos estudiantes en tres asignaturas:\n",
        "\n",
        "* Alumno A: Matemáticas = 7, Lengua = 8, Inglés = 6\n",
        "\n",
        "* Alumno B: Matemáticas = 5, Lengua = 9, Inglés = 7\n",
        "\n",
        "Representa las notas de cada alumno como vectores en Python.\n",
        "\n",
        "Calcula:\n",
        "\n",
        "* La suma de los vectores (notas combinadas de ambos alumnos).\n",
        "\n",
        "* La diferencia de los vectores (comparación alumno A – alumno B).\n",
        "\n",
        "* La norma de cada vector (magnitud de las notas de cada alumno).\n",
        "\n",
        "* El producto escalar entre ambos vectores (medida de similitud en su rendimiento).\n",
        "\n",
        "* La distancia entre los vectores (qué tan diferentes son en sus resultados).\n",
        "\n",
        "* Normaliza los vectores de cada alumno para que la comparación sea independiente de la escala.\n",
        "\n",
        "Interpreta los resultados:\n",
        "* ¿qué alumno es más regular?\n",
        "* ¿qué tan parecidos son en sus notas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z5bmFsXShbbO",
      "metadata": {
        "id": "z5bmFsXShbbO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Representación de los vectores (notas de alumnos)\n",
        "alumno_A = np.array([7, 8, 6])\n",
        "alumno_B = np.array([5, 9, 7])\n",
        "\n",
        "print(\"Alumno A:\", alumno_A)\n",
        "print(\"Alumno B:\", alumno_B)\n",
        "\n",
        "# 2. Operaciones con vectores\n",
        "suma = alumno_A + alumno_B\n",
        "resta = alumno_A - alumno_B\n",
        "norma_A = np.linalg.norm(alumno_A)\n",
        "norma_B = np.linalg.norm(alumno_B)\n",
        "producto_escalar = np.dot(alumno_A, alumno_B)\n",
        "distancia = np.linalg.norm(alumno_A - alumno_B)\n",
        "\n",
        "# 3. Normalización\n",
        "alumno_A_norm = alumno_A / norma_A\n",
        "alumno_B_norm = alumno_B / norma_B\n",
        "\n",
        "# 4. Resultados\n",
        "print(\"\\nSuma de notas:\", suma)\n",
        "print(\"Diferencia de notas (A - B):\", resta)\n",
        "\n",
        "# Comparamos las normas para comparar su rendimiento en las tres asignaturas\n",
        "print(\"Norma de A:\", norma_A)\n",
        "print(\"Norma de B:\", norma_B)\n",
        "# Cuanto más alto el producto escalar, más siguen un patrón similar\n",
        "print(\"Producto escalar (similitud):\", producto_escalar)\n",
        "# Cuanto menor la distancia, rendimientros más cercanos\n",
        "print(\"Distancia entre A y B:\", distancia)\n",
        "print(\"Alumno A normalizado:\", alumno_A_norm)\n",
        "print(\"Alumno B normalizado:\", alumno_B_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00606f85",
      "metadata": {
        "id": "00606f85"
      },
      "source": [
        "### Resumen rápido\n",
        "\n",
        "| Operación              | Descripción                              | Fórmula                                          | Uso en Machine Learning                          |\n",
        "|------------------------|------------------------------------------|-------------------------------------------------|-------------------------------------------------|\n",
        "| **Suma**               | Suma elemento a elemento                 | $$ (v_1 + v_2)_i = v_{1,i} + v_{2,i} $$         | Combinar características o vectores             |\n",
        "| **Resta**              | Resta elemento a elemento                | $$ (v_1 - v_2)_i = v_{1,i} - v_{2,i} $$         | Calcular errores o diferencias (pred vs real)   |\n",
        "| **Multiplicación escalar** | Escalar cada componente del vector     | $$ (c \\cdot v)_i = c \\cdot v_i $$               | Ajustar magnitud de datos o pesos               |\n",
        "| **Producto escalar**   | Multiplicación elemento a elemento y suma | $$ \\sum_i v_{1,i} \\cdot v_{2,i} $$              | Medir similitud o correlación                   |\n",
        "| **Similitud coseno**   | Medida de ángulo entre vectores          | $$ \\cos(\\theta)=\\tfrac{v_1\\cdot v_2}{||v_1||\\,||v_2||} $$ | Comparar embeddings en NLP e imágenes |\n",
        "| **Producto vectorial** | Vector perpendicular en 3D               | $$ v_1 \\times v_2 $$                            | Geometría 3D, visión por ordenador avanzada     |\n",
        "| **Norma (longitud)**   | Tamaño o magnitud del vector              | $$ \\sqrt{\\sum_i v_i^2} $$                       | Medir magnitud o energía de un dato             |\n",
        "| **Normalización (L2)** | Vector con longitud 1                     | $$ \\hat{v} = \\tfrac{v}{||v||} $$                | Comparar vectores en la misma escala            |\n",
        "| **Distancia euclídea** | Separación entre dos vectores             | $$ d(v_1, v_2) = || v_1 - v_2 || $$             | KNN, clustering, detección de anomalías         |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xOdTftgIRgS_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOdTftgIRgS_",
        "outputId": "3ec918c1-5495-4b8e-bf22-4b098e861602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector v1: [2 3 5]\n",
            "Vector v2: [1 4 2]\n",
            "\n",
            "1) Suma: [3 7 7]\n",
            "2) Resta: [ 1 -1  3]\n",
            "3) Multiplicación escalar (2 * v1): [ 4  6 10]\n",
            "4) Producto escalar: 24\n",
            "5) Producto vectorial: [-14   1   5]\n",
            "6) Norma de v1: 6.164414002968976\n",
            "7) v1 normalizado: [0.32444284 0.48666426 0.81110711]\n",
            "8) Distancia entre v1 y v2: 3.3166247903554\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos dos vectores en R^3 (tres dimensiones)\n",
        "v1 = np.array([2, 3, 5])\n",
        "v2 = np.array([1, 4, 2])\n",
        "c = 2  # escalar\n",
        "\n",
        "print(\"Vector v1:\", v1)\n",
        "print(\"Vector v2:\", v2)\n",
        "\n",
        "# 1. Suma de vectores -> juntar datos\n",
        "# Ejemplo: sumar las notas de dos alumnos en cada asignatura\n",
        "suma = v1 + v2\n",
        "print(\"\\n1) Suma:\", suma)  # [3 7 7]\n",
        "\n",
        "# 2. Resta de vectores -> diferencia entre datos\n",
        "# Ejemplo: ver en qué asignaturas un alumno saca más puntos que otro\n",
        "resta = v1 - v2\n",
        "print(\"2) Resta:\", resta)  # [1 -1 3]\n",
        "\n",
        "# 3. Multiplicación por un escalar -> estirar o encoger un vector\n",
        "# Ejemplo: duplicar todas las características de un objeto\n",
        "mult_escalar = c * v1\n",
        "print(\"3) Multiplicación escalar (2 * v1):\", mult_escalar)  # [4 6 10]\n",
        "\n",
        "# 4. Producto escalar (dot product) -> mide qué tan parecidos son dos vectores\n",
        "# Ejemplo: comparar si dos alumnos tienen notas similares\n",
        "producto_escalar = np.dot(v1, v2)\n",
        "print(\"4) Producto escalar:\", producto_escalar)  # 24\n",
        "\n",
        "# 5. Producto vectorial -> genera un vector perpendicular en 3D\n",
        "# Ejemplo: se usa en geometría, gráficos y visión por ordenador\n",
        "producto_vectorial = np.cross(v1, v2)\n",
        "print(\"5) Producto vectorial:\", producto_vectorial)  # [-14  1  5]\n",
        "\n",
        "# 6. Norma (longitud del vector) -> mide el tamaño del vector\n",
        "# Ejemplo: mide el “nivel” o magnitud de un dato\n",
        "norma_v1 = np.linalg.norm(v1)\n",
        "print(\"6) Norma de v1:\", norma_v1)  # 6.164...\n",
        "\n",
        "# 7. Normalización -> vector con tamaño 1\n",
        "# Ejemplo: permite comparar datos aunque estén en escalas distintas\n",
        "v1_normalizado = v1 / norma_v1\n",
        "print(\"7) v1 normalizado:\", v1_normalizado)\n",
        "\n",
        "# 8. Distancia entre dos vectores -> mide lo diferentes que son\n",
        "# Ejemplo: se usa en Machine Learning (KNN, clustering, detección de anomalías)\n",
        "distancia = np.linalg.norm(v1 - v2)\n",
        "print(\"8) Distancia entre v1 y v2:\", distancia)  # 3.162...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kCt0qEYsn7Mr",
      "metadata": {
        "id": "kCt0qEYsn7Mr"
      },
      "source": [
        "### 📝 Actividad 1 – Vectores\n",
        "\n",
        "1. Definir dos vectores a=(3,4) y b=(1,2): En la Inteligencia Artificial y el Machine Learning, los vectores se representan de forma estándar como una colección ordenada de números. La manera más eficiente y común de trabajar con ellos en Python es a través de NumPy arrays.\n",
        "\n",
        "2. Calcular: Las operaciones con vectores son fundamentales para comparar datos, medir similitudes y construir algoritmos en Machine Learning\n",
        "\n",
        "  * Su suma y resta: La suma y resta de vectores se realiza elemento a elemento. NumPy soporta estas operaciones directamente con los operadores + y -.\n",
        "  * Su producto escalar (dot product): El producto escalar de dos vectores se calcula multiplicando cada componente correspondiente y luego sumando los resultados. Este valor mide qué tan alineados están los vectores [conversación anterior]. En NumPy, se utiliza la función np.dot() o el operador @.\n",
        "  * Sus normas (longitudes): La norma euclidiana (también conocida como 2-norma) mide la longitud o magnitud del vector. Se calcula como la raíz cuadrada de la suma de los cuadrados de sus componentes. En NumPy, se utiliza np.linalg.norm().\n",
        "  \n",
        "3. Representar ambos en el plano con Matplotlib: La visualización de vectores en el plano ayuda a comprender su interpretación geométrica. Matplotlib es una herramienta común para esta tarea, utilizando funciones como plt.arrow() para dibujar las flechas de los vectores.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187fcae1",
      "metadata": {
        "id": "187fcae1"
      },
      "source": [
        "# 2. Matrices\n",
        "\n",
        "En matemáticas, una **matriz** es una **tabla rectangular u ordenada de números organizada en filas y columnas**. Es como una hoja de cálculo o una tabla de Excel, donde cada casilla contiene un número. Las matrices son una de las estructuras de datos más importantes que pueden representar sistemas de ecuaciones, gráficos, mapeos entre espacios vectoriales y mucho más. Son los bloques de construcción fundamentales del *Machine Learning*.\n",
        "\n",
        "Las matrices son una generalización bidimensional de los vectores y, a su vez, son un caso especial de los tensores de orden superior, que son las estructuras de datos fundamentales en el *deep learning*.\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo sencillo\n",
        "\n",
        "Una matriz con 2 filas y 3 columnas puede escribirse así:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Tiene **2 filas** (horizontal).\n",
        "* Tiene **3 columnas** (vertical).\n",
        "* El **elemento** en la primera fila y segunda columna es $a_{1,2} = 2$.\n",
        "\n",
        "👉 Notación general: Una matriz $A$ de tamaño $m \\times n$ tiene $m$ filas y $n$ columnas. Se denota como $A = (a_{i,j})_{i=1,j=1}^{n,m} \\in \\mathbb{R}^{n \\times m}$, donde $\\mathbb{R}^{n \\times m}$ es el conjunto de todas las matrices reales con $n$ filas y $m$ columnas.\n",
        "\n",
        "---\n",
        "\n",
        "### Diferencia con un vector\n",
        "\n",
        "* Un **vector** es una colección ordenada de números dispuestos en una fila o columna, y representa una cantidad que tiene tanto magnitud como dirección. En esencia, un vector puede considerarse un caso especial de matriz con **una sola fila o una sola columna**. Por ejemplo, un vector columna de 3 elementos: $$ \\vec{v} = \\begin{bmatrix} 3 \\ 7 \\ 5 \\end{bmatrix} $$\n",
        "\n",
        "* Una **matriz** puede tener muchas filas y muchas columnas. Los vectores son fundamentales para comprender muchos aspectos de la IA, especialmente al tratar con conjuntos de datos, transformaciones y espacios multidimensionales. En contraste, las matrices son esenciales para la representación y manipulación eficiente de datos, especialmente con conjuntos de datos de alta dimensión\n",
        "\n",
        "---\n",
        "\n",
        "### Intuición\n",
        "\n",
        "Piensa en una matriz como en un **almacén de información estructurada**:\n",
        "\n",
        "* Cada **fila** = un ejemplo (un alumno, una flor, una imagen).\n",
        "* Cada **columna** = una característica (nota, tamaño, color).\n",
        "\n",
        "👉  Esta visión es la que usaremos en **Machine Learning**, donde un dataset entero se guarda en forma de matriz. En el machine learning, los conjuntos de datos a menudo se almacenan en matrices, con cada fila representando un punto de datos individual y cada columna representando una característica específica del dato. Los modelos de IA, especialmente las redes neuronales profundas, dependen en gran medida de las operaciones matriciales para realizar cálculos en grandes conjuntos de datos. Las matrices son cruciales para el cómo muchos modelos de IA aprenden y hacen predicciones.\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo cotidiano\n",
        "\n",
        "Supongamos que guardamos las notas de 3 alumnos en 3 asignaturas:\n",
        "\n",
        "$$\n",
        "\\text{Notas} =\n",
        "\\begin{bmatrix}\n",
        "6 & 7 & 8 \\\\\n",
        "5 & 9 & 7 \\\\\n",
        "8 & 6 & 9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Fila 1 → Alumno A con notas (6,7,8).\n",
        "* Fila 2 → Alumno B con notas (5,9,7).\n",
        "* Fila 3 → Alumno C con notas (8,6,9).\n",
        "* Columnas → Asignaturas (Matemáticas, Lengua, Inglés).\n",
        "\n",
        "Este ejemplo ilustra cómo una matriz puede representar un sistema de puntos de datos, donde las filas corresponden a diferentes muestras (alumnos) y las columnas a diferentes características (asignaturas/notas). Esta representación es fundamental en el Machine Learning, donde, por ejemplo, los datos de entrada de un dataset para regresión lineal pueden representarse como una matriz, y las etiquetas objetivo correspondientes como otro vector o matriz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kfQuZOy7S6-P",
      "metadata": {
        "id": "kfQuZOy7S6-P"
      },
      "source": [
        "\n",
        "## 2.1 Características de una matriz\n",
        "\n",
        "Ahora que ya sabemos qué es una matriz y su papel fundamental en la inteligencia artificial (IA) como el lenguaje de los datos, veamos sus **características principales**. Las matrices son estructuras matemáticas esenciales que permiten la representación y manipulación eficiente de grandes conjuntos de datos\n",
        "\n",
        "---\n",
        "\n",
        "### Tamaño o forma de una matriz\n",
        "\n",
        "El **tamaño o la forma** de una matriz es una de sus características más importantes y se define por el número de **filas** (disposición horizontal) y **columnas** (disposición vertical) que posee. Una matriz es, en esencia, una tabla de números.\n",
        "\n",
        "👉 Si una matriz tiene $m$ filas y $n$ columnas, decimos que es de **tamaño $m \\times n$ (“m por n”)**. El conjunto de todas las matrices reales con $m$ filas y $n$ columnas se denota como $\\mathbb{R}^{m \\times n}$.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Tiene **2 filas** (horizontales).\n",
        "* Tiene **3 columnas** (verticales).\n",
        "* Es una matriz de **2 × 3**.\n",
        "\n",
        "📌 **Idea clave**: Si una matriz tiene $m$ filas y $n$ columnas, decimos que es de tamaño $m \\times n$ (“m por n”). El conjunto de todas las matrices reales con $m$ filas y $n$ columnas se denota como $\\mathbb{R}^{m \\times n}$.\n",
        "\n",
        "\n",
        "**Importancia del tamaño en las operaciones y la representación de datos en IA**:\n",
        "\n",
        "* **Representación de datos**: En machine learning, los conjuntos de datos se suelen almacenar en matrices, donde cada fila puede representar un punto de datos individual y cada columna una característica específica de esos datos. Por ejemplo, una imagen de 256x256 píxeles puede representarse como una matriz de ese tamaño (para escala de grises) o como un tensor de 256x256x3 (para imágenes RGB), donde las dimensiones definen la estructura de la imagen. En Procesamiento de Lenguaje Natural (PLN), palabras o frases se representan como vectores de alta dimensión, que luego se procesan como matrices.\n",
        "\n",
        "* **Suma y resta de matrices**: Para poder sumar o restar dos matrices, estas deben tener **exactamente las mismas dimensiones** (el mismo número de filas y columnas).\n",
        "\n",
        "* **Multiplicación de matrices**: Esta es una operación fundamental en IA. Para multiplicar dos matrices $A$ y $B$, **el número de columnas de la primera matriz ($A$) debe ser igual al número de filas de la segunda matriz ($B$)**. Si $A$ es de tamaño $n \\times m$ y $B$ es de tamaño $m \\times l$, su producto $AB$ resultará en una matriz de tamaño $n \\times l$. Esta compatibilidad dimensional es vital en algoritmos como la regresión lineal y en las capas de las redes neuronales para propagar la información.\n",
        "\n",
        "* **Transposición de una matriz**: La transposición de una matriz implica intercambiar sus filas por sus columnas. Si una matriz original tiene un tamaño de $m \\times n$, su transpuesta tendrá un tamaño de $n \\times m$.\n",
        "* **Inversa de una matriz**: No todas las matrices tienen inversa. Solo las matrices cuadradas (aquellas con el mismo número de filas y columnas, es decir, de tamaño $n \\times n$) y no singulares (con determinante distinto de cero) pueden tener una inversa.\n",
        "\n",
        "* **Redimensionamiento (Reshaping)**: Es posible cambiar la forma de una matriz sin alterar el número total de sus elementos, lo que implica reorganizar cómo se distribuyen las filas y columnas. Por ejemplo, una matriz de $3 \\times 4$ puede ser redimensionada a $6 \\times 2$ o $4 \\times 3$, entre otras, manteniendo los 12 elementos.\n",
        "\n",
        "* **Errores de forma (Shape Mismatches)**: En la práctica de machine learning, los errores debidos a la falta de coincidencia en las formas o dimensiones de las matrices son muy comunes y pueden causar problemas significativos en el desarrollo de modelos.\n",
        "\n",
        "Comprender el tamaño y la forma de las matrices es un pilar fundamental para trabajar eficazmente con los algoritmos y modelos de IA\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "roTfgV6I428p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roTfgV6I428p",
        "outputId": "68fc4e92-7edd-49f7-d3d0-755fbd80bde6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz A:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Forma: (2, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "print(\"Matriz A:\\n\", A)\n",
        "print(\"Forma:\", A.shape)  # (2, 3) → 2 filas, 3 columnas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eqrw2uez43aN",
      "metadata": {
        "id": "Eqrw2uez43aN"
      },
      "source": [
        "## 2.2. Elementos de una matriz\n",
        "\n",
        "Cada número dentro de la matriz se llama **elemento**.\n",
        "Se identifica por la **fila** y la **columna** en la que se encuentra.\n",
        "\n",
        "Ejemplo: en la matriz anterior, el número que está en la **fila 2, columna 3** es:\n",
        "\n",
        "$$\n",
        "a_{2,3} = 6\n",
        "$$\n",
        "\n",
        "👉 Se suele escribir con la letra de la matriz en minúscula y los subíndices de fila y columna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YtCaqYrn5Bt9",
      "metadata": {
        "id": "YtCaqYrn5Bt9"
      },
      "outputs": [],
      "source": [
        "print(\"Elemento fila 2, columna 3:\", A[1, 2])  # índice empieza en 0 → a_{2,3} = 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dMCupk35Est",
      "metadata": {
        "id": "2dMCupk35Est"
      },
      "source": [
        "\n",
        "### 2.3 Tipos de matrices\n",
        "\n",
        "En el estudio de las matemáticas aplicadas a la Inteligencia Artificial, las matrices son estructuras fundamentales para representar y procesar datos. Dentro de este contexto, existen algunas matrices especiales que, debido a sus propiedades únicas, son de particular importancia para la optimización de cálculos, la resolución de sistemas de ecuaciones lineales y el diseño de modelos eficientes. Conocer sus características nos permite comprender mejor cómo funcionan los algoritmos y modelos de IA.\n",
        "\n",
        "\n",
        "* **Matriz cuadrada**:  Una matriz es cuadrada si tiene el mismo número de filas ($n$) y columnas ($n$) [ref: user provided definition, 84]. Se denota su tamaño como $n \\times n$.\n",
        "\n",
        "  Ejemplo: Una matriz de $2 \\times 2$ o $3 \\times 3$\n",
        "\n",
        "  * **Relevancia en IA**: Las matrices cuadradas son esenciales en muchos algoritmos, ya que solo ellas pueden tener una **inversa** (siempre que sean no singulares, es decir, con determinante distinto de cero). Además, los conceptos de **autovalores y autovectores**, fundamentales para entender el comportamiento de transformaciones lineales y la reducción de dimensionalidad (como en PCA), están definidos para matrices cuadradas. La **descomposición espectral** y la **descomposición de autovalores (EVD)** son técnicas que se aplican a matrices cuadradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sW8bvrcGicAu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8bvrcGicAu",
        "outputId": "43d7c141-19c5-4ddf-f95b-8c15075da0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz Cuadrada\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "\n",
        "print(\"Matriz Cuadrada\")\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zBV52y1ricLV",
      "metadata": {
        "id": "zBV52y1ricLV"
      },
      "source": [
        "\n",
        "\n",
        "* **Matriz identidad**: La matriz identidad, denotada por $I$, es una matriz cuadrada que posee unos en la diagonal principal (desde la esquina superior izquierda hasta la inferior derecha) y ceros en todas las demás posiciones.\n",
        "\n",
        "  $$\n",
        "  I =\n",
        "  \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  *   **Propiedad**: Se comporta como el número 1 en la multiplicación escalar o matricial; es decir, multiplicar cualquier matriz por la matriz identidad deja la matriz original sin cambios ($A \\times I = A$ y $I \\times A = A$)  Esto la convierte en el \"elemento neutro\" de la multiplicación matricial.\n",
        "\n",
        "  * **Relevancia en IA**:\n",
        "      *  **Inicialización**: Se utiliza frecuentemente para inicializar ciertos algoritmos, como las matrices de pesos iniciales en modelos de aprendizaje profundo, garantizando que los pesos no estén sesgados al principio.\n",
        "\n",
        "      *  **Sistemas de ecuaciones lineales**: Es clave para resolver sistemas de ecuaciones lineales, particularmente en la eliminación gaussiana y la inversión de matrices, ya que la inversa de una matriz $A$ es aquella que, al multiplicarse por $A$, da como resultado la matriz identidad ($A \\times A^{-1} = I$).\n",
        "\n",
        "      *  **Matrices ortogonales**: Define la condición para que una matriz sea ortogonal: $Q^T \\times Q = I$, donde $Q^T$ es la transpuesta de $Q$.\n",
        "\n",
        "      *  **Autovalores**: Juega un papel en el cálculo de autovalores, donde se busca $\\lambda$ tal que $\\det(A - \\lambda I) = 0$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qel-no8rijG5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qel-no8rijG5",
        "outputId": "658412d1-3058-4ead-a1e8-813dc7e18c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Matriz identidad de 3x3\n",
        "I = np.eye(3)\n",
        "print(\"Identidad:\\n\", I)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RmaU4YZcijTl",
      "metadata": {
        "id": "RmaU4YZcijTl"
      },
      "source": [
        "* **Matriz nula**: Una matriz nula es aquella en la que todos sus elementos son 0.\n",
        "\n",
        "  $$\n",
        "  0 =\n",
        "  \\begin{bmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 0\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  * **Relevancia en IA**: El concepto de elementos cero es fundamental. Por ejemplo, en el contexto de los espacios vectoriales, existe un \"vector nulo\" (todos sus elementos son cero) que actúa como identidad aditiva. Una transformación lineal que mapea todos los vectores al vector cero no puede tener una inversa. Una matriz con una columna o fila de ceros tiene un determinante de cero, lo que implica que no es invertible. En la práctica, se utilizan funciones como ``np.zeros`` en NumPy para crear matrices con todos sus elementos inicializados a cero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jj_BZitFin-t",
      "metadata": {
        "id": "jj_BZitFin-t"
      },
      "outputs": [],
      "source": [
        "# Matriz nula de 2x2\n",
        "Z = np.zeros((2, 2))\n",
        "print(\"Nula:\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oC6vjZ3zioKE",
      "metadata": {
        "id": "oC6vjZ3zioKE"
      },
      "source": [
        "* **Matriz diagonal**: Una matriz diagonal es una matriz cuadrada que tiene números únicamente en su diagonal principal, y ceros en todos los elementos fuera de ella.\n",
        "\n",
        "  $$\n",
        "  D =\n",
        "  \\begin{bmatrix}\n",
        "  3 & 0 & 0 \\\\\n",
        "  0 & 5 & 0 \\\\\n",
        "  0 & 0 & 7\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  * **Relevancia en IA**:\n",
        "      *  **Eficiencia computacional**: Las matrices diagonales son altamente valoradas en la práctica de la IA debido a su **eficiencia computacional**. Multiplicar por una matriz diagonal es significativamente más rápido, requiriendo $O(n)$ operaciones en lugar de $O(n^2)$. El determinante de una matriz triangular (y por ende, de una diagonal) se calcula simplemente multiplicando sus elementos de la diagonal.\n",
        "      *  **Simplificación de transformaciones lineales (Diagonalización)**: El objetivo de muchos algoritmos en IA es diagonalizar matrices. Esto implica encontrar una base (compuesta por autovectores) en la que la matriz de una transformación lineal se convierte en diagonal. Esta diagonalización simplifica enormemente el análisis y la aplicación de la transformación, revelando la \"estructura interna\" de la misma.\n",
        "      *  **Descomposiciones matriciales:** Son componentes clave en descomposiciones importantes como la **descomposición espectral** (donde la matriz diagonal contiene los autovalores) y la **descomposición en valores singulares (SVD)** (donde una matriz diagonal contiene los valores singulares, que representan los factores de estiramiento de la transformación).\n",
        "\n",
        "  Estas matrices especiales no solo son conceptos teóricos, sino herramientas poderosas que subyacen a la eficacia y eficiencia de muchos de los algoritmos y modelos complejos utilizados en el campo de la Inteligencia Artificial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2MXdj-Sc5WA4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MXdj-Sc5WA4",
        "outputId": "08485a88-b139-4619-e9a8-eb5eb772600a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Nula:\n",
            " [[0. 0.]\n",
            " [0. 0.]]\n",
            "Diagonal:\n",
            " [[3 0 0]\n",
            " [0 5 0]\n",
            " [0 0 7]]\n"
          ]
        }
      ],
      "source": [
        "# Matriz diagonal con 3, 5, 7 en la diagonal\n",
        "D = np.diag([3, 5, 7])\n",
        "print(\"Diagonal:\\n\", D)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zgs1kDiuGxGe",
      "metadata": {
        "id": "Zgs1kDiuGxGe"
      },
      "source": [
        "### 2.4 Operaciones con matrices\n",
        "\n",
        "En álgebra lineal, las **operaciones con matrices** son la piedra angular para la manipulación y el procesamiento de datos. En el ámbito del Machine Learning (ML) y la Inteligencia Artificial (IA), estas operaciones son realizadas con **frecuencia** y de manera intensiva, constituyendo el corazón de los cálculos y algoritmos. Herramientas como **NumPy** en Python facilitan enormemente su implementación, permitiendo realizar estas operaciones de forma eficiente en grandes conjuntos de datos.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2.4.1 Suma y resta de matrices\n",
        "\n",
        "La **suma y resta de matrices** son operaciones fundamentales que permiten combinar o comparar matrices\n",
        "\n",
        "👉  La regla principal es que solo se pueden sumar o restar matrices si tienen **exactamente el mismo tamaño** (es decir, el mismo número de filas y columnas). La operación se realiza **elemento a elemento** (element-wise), lo que significa que los elementos correspondientes de cada matriz se suman o se restan\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "5 & 6 \\\\\n",
        "7 & 8\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "6 & 8 \\\\\n",
        "10 & 12\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Relevancia en IA/ML**: Estas operaciones son útiles en muchos algoritmos de machine learning, particularmente en la **optimización**, donde los **pesos (weights)** de un modelo se ajustan al añadir o restar valores de gradiente durante el proceso de entrenamiento. Por ejemplo, en el método del **gradiente descendente**, los parámetros del modelo se actualizan en cada iteración sumando o restando un valor proporcional al gradiente de la función de pérdida. Además, la **adición de matrices es conmutativa** ($A + B = B + A$) y **asociativa** ($A + (B + C) = (A + B) + C$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SngTC8afGztu",
      "metadata": {
        "id": "SngTC8afGztu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "B = np.array([[5, 6],\n",
        "              [7, 8]])\n",
        "print(\"Suma:\\n\", A + B)\n",
        "print(\"Resta:\\n\", A - B)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T6sMFQZOG4HO",
      "metadata": {
        "id": "T6sMFQZOG4HO"
      },
      "source": [
        "#### 2.4.2 Multiplicación por un escalar\n",
        "\n",
        "👉 Cada elemento de la matriz se multiplica por un número real.\n",
        "\n",
        "$$\n",
        "2 \\cdot\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "2 & 4 \\\\\n",
        "6 & 8\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ucNoylHzHAYt",
      "metadata": {
        "id": "ucNoylHzHAYt"
      },
      "outputs": [],
      "source": [
        "print(\"A * 2:\\n\", 2 * A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PkMt4t2yHDU-",
      "metadata": {
        "id": "PkMt4t2yHDU-"
      },
      "source": [
        "#### 2.4.3 Multiplicación de matrices\n",
        "\n",
        "La **multiplicación de matrices** es una operación central y una de las más cruciales en IA, ya que permite la **transformación de datos**. A diferencia de la suma y resta, la multiplicación de matrices no se realiza elemento a elemento.\n",
        "\n",
        "\n",
        "👉 La regla fundamental en álgebra lineal es que para multiplicar dos matrices $A$ y $B$ ($C = A \\cdot B$), **el número de columnas de la primera matriz ($A$) debe ser igual al número de filas de la segunda matriz ($B$)**. Si $A$ tiene dimensiones $n \\times m$ y $B$ tiene dimensiones $m \\times l$, la matriz resultante $C$ tendrá dimensiones $n \\times l$\n",
        "\n",
        "La multiplicación combina las filas de la primera matriz con las columnas de la segunda a través de un proceso de producto escalar (dot product). El elemento en la $i$-ésima fila y $j$-ésima columna de la matriz resultante $C$ se calcula como el producto escalar de la $i$-ésima fila de $A$ y la $j$-ésima columna de $B$.\n",
        "\n",
        "Fórmula:  \n",
        "$$\n",
        "C = A \\cdot B \\quad \\Rightarrow \\quad c_{ij} = \\sum_{k=1}^{m} a_{ik} \\cdot b_{kj}\n",
        "$$\n",
        "\n",
        "Ejemplo:  \n",
        "Si $A$ es una matriz de $2 \\times 3$ y $B$ es una matriz de $3 \\times 2$, el resultado $C$ será una matriz de $2 \\times 2$:  \n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "B =\n",
        "\\begin{bmatrix}\n",
        "7 & 8 \\\\\n",
        "9 & 10 \\\\\n",
        "11 & 12\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "El producto $C = A \\times B$ sería:  \n",
        "\n",
        "$$\n",
        "C =\n",
        "\\begin{bmatrix}\n",
        "(1\\cdot7 + 2\\cdot9 + 3\\cdot11) & (1\\cdot8 + 2\\cdot10 + 3\\cdot12) \\\\\n",
        "(4\\cdot7 + 5\\cdot9 + 6\\cdot11) & (4\\cdot8 + 5\\cdot10 + 6\\cdot12)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "(7+18+33) & (8+20+36) \\\\\n",
        "(28+45+66) & (32+50+72)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "58 & 64 \\\\\n",
        "139 & 154\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "📌 **Relevancia en IA/ML**: La multiplicación de matrices es una operación fundamental en la mayoría de los algoritmos de IA.\n",
        "\n",
        "  * **Redes neuronales**: En las redes neuronales profundas, la multiplicación de matrices se utiliza para **computar las salidas de cada capa** multiplicando los datos de entrada por las** matrices de peso**s aprendidos. Este proceso es crucial para propagar la información a través de la red.\n",
        "  * **Regresión lineal**: Es un componente clave en la **regresión lineal**, donde los vectores de características de entrada se multiplican por una matriz de pesos para generar predicciones.\n",
        "  * **Optimización**: Se usa en muchos **algoritmos de optimización**.\n",
        "  * Eficiencia computacional: Las bibliotecas como NumPy están altamente optimizadas para realizar multiplicaciones de matrices de manera muy rápida, a menudo aprovechando hardware especializado (como GPUs) y bibliotecas de bajo nivel (como BLAS y LAPACK) para operaciones paralelas.\n",
        "  * **Composición de transformaciones**: Desde la perspectiva de las transformaciones lineales, la multiplicación de matrices representa la **composición de dos transformaciones lineales**.\n",
        "  * **Notación en Python**: NumPy permite usar el operador ``@`` para la multiplicación de matrices, lo que simplifica el código.\n",
        "  * Propiedades: Es importante notar que, a diferencia de la suma, **la multiplicación de matrices generalmente no es conmutativa** ($A \\times B \\neq B \\times A$). Sin embargo, sí es asociativa ($A \\times (B \\times C) = (A \\times B) \\times C$) y distributiva sobre la suma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GXdh8UCiHGmZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXdh8UCiHGmZ",
        "outputId": "c2e6a6e0-400f-4630-85f1-1ed8bf465b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multiplicación C @ D:\n",
            " [[ 58  64]\n",
            " [139 154]]\n"
          ]
        }
      ],
      "source": [
        "C = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])   # (2x3)\n",
        "D = np.array([[7, 8],\n",
        "              [9, 10],\n",
        "              [11, 12]])    # (3x2)\n",
        "\n",
        "print(\"Multiplicación C @ D:\\n\", C @ D)  # producto matricial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xS-nNmaA5cQM",
      "metadata": {
        "id": "xS-nNmaA5cQM"
      },
      "source": [
        "---\n",
        "\n",
        "#### 2.4.4 Transposición\n",
        "\n",
        "La transpuesta de una matriz, denotada por $A^T$ (o $A'$), es una nueva matriz que se obtiene al intercambiar sus filas por sus columnas [ref: user provided text, 100, 316]. Si una matriz original tiene $m$ filas y $n$ columnas (tamaño $m \\times n$), su transpuesta tendrá $n$ filas y $m$ columnas (tamaño $n \\times m$)\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\quad \\longrightarrow \\quad\n",
        "A^T =\n",
        "\\begin{bmatrix}\n",
        "1 & 4 \\\\\n",
        "2 & 5 \\\\\n",
        "3 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "👉 Es como “voltear” la matriz sobre su diagonal principal\n",
        "\n",
        "📌 **Relevancia en IA/ML**:  La transposición es una operación fundamental y crítica para que las dimensiones coincidan en los cálculos de Machine Learning  Se utiliza en diversos contextos:\n",
        "  * **Productos escalares (similitud)**: Se emplea en operaciones que involucran productos escalares, por ejemplo, para calcular la **similitud entre vectores** (como la similitud del coseno).\n",
        "\n",
        "  * **Cálculo de gradientes**: Es esencial en el **cálculo de gradientes** en algoritmos de optimización, como el de **retropropagación (backpropagation)** en redes neuronales. La transpuesta juega un papel clave en la regla de la cadena para propagar los errores hacia atrás a través de las capas de la red.\n",
        "\n",
        "  * **Ecuaciones de modelos lineales**: Aparece en la formulación y resolución de ecuaciones de modelos lineales, por ejemplo, en la solución de mínimos cuadrados.\n",
        "\n",
        "  * **Redes neuronales**: Se usa en diversas **operaciones dentro de las redes neuronales**.\n",
        "\n",
        "  * **Matrices ortogonales**: Una matriz $Q$ es ortogonal si su transpuesta es igual a su inversa ($Q^T = Q^{-1}$), lo que significa que $Q^T \\times Q = I$ (la matriz identidad). Las matrices ortogonales son importantes porque preservan la longitud y los ángulos de los vectores, siendo útiles en transformaciones geométricas y en técnicas como el **Análisis de Componentes Principales (PCA)**.\n",
        "\n",
        "  * **Propiedades**: La transposición de una suma de matrices es la suma de sus transpuestas ($(A+B)^T = A^T + B^T$) y la transpuesta de un producto es el producto de las transpuestas en orden inverso ($(AB)^T = B^T A^T$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t841XV615cew",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t841XV615cew",
        "outputId": "2288f837-d3a0-4721-9330-421276bbadc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de datos_alumnos: (3, 2)\n",
            "Forma de pesos: (1, 2)\n",
            "Error: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)\n",
            "Forma de pesos.T: (2, 1)\n",
            "Predicciones (3 alumnos):\n",
            " [[5. ]\n",
            " [5.2]\n",
            " [7.4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset: 3 alumnos (filas), con 2 características cada uno (columnas)\n",
        "# Características: [horas de estudio, nota en prácticas]\n",
        "datos_alumnos = np.array([[2, 7],   # Alumno 1\n",
        "                          [4, 6],   # Alumno 2\n",
        "                          [5, 9]])  # Alumno 3\n",
        "print(\"Forma de datos_alumnos:\", datos_alumnos.shape)  # (3, 2)\n",
        "\n",
        "# Pesos del modelo: importancia que damos a cada característica\n",
        "# [peso_horas, peso_practicas]\n",
        "pesos = np.array([[0.4, 0.6]])  # (1, 2) → vector fila\n",
        "print(\"Forma de pesos:\", pesos.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# Intento de multiplicación\n",
        "# -----------------------------\n",
        "# Regla: columnas de la primera (2) = filas de la segunda (¿?)\n",
        "# Aquí tenemos (3x2) @ (1x2) → ERROR, porque 2 ≠ 1\n",
        "try:\n",
        "    print(datos_alumnos @ pesos)\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# -----------------------------\n",
        "# Solución: usar la transpuesta\n",
        "# -----------------------------\n",
        "# pesos.T convierte (1,2) → (2,1)\n",
        "print(\"Forma de pesos.T:\", pesos.T.shape)\n",
        "\n",
        "# Ahora sí: (3x2) @ (2x1) → (3x1)\n",
        "predicciones = datos_alumnos @ pesos.T\n",
        "print(\"Predicciones (3 alumnos):\\n\", predicciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHNq6BnSHQpR",
      "metadata": {
        "id": "KHNq6BnSHQpR"
      },
      "source": [
        "\n",
        "#### 2.4.5 Inversa de una matriz\n",
        "\n",
        "La inversa de una matriz $A$, denotada como $A^{-1}$, es otra matriz que, al multiplicarse por $A$, produce la matriz identidad ($I$). Es decir, la inversa \"deshace\" el efecto de la matriz original.\n",
        "La inversa $A^{-1}$ cumple la siguiente propiedad fundamental:\n",
        "\n",
        "$$\n",
        "A \\cdot A^{-1} = I\n",
        "$$\n",
        "\n",
        "Solo existe para matrices cuadradas (aquellas con el mismo número de filas y columnas) y que sean no singulares (es decir, su determinante es distinto de 0). Las matrices con un determinante de cero se denominan matrices singulares y no tienen inversa. Si una matriz no es cuadrada, no es invertible en el sentido clásico.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}2&1\\\\5&3\\end{bmatrix}\n",
        "\\begin{bmatrix}3&-1\\\\-5&2\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}1&0\\\\0&1\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "📌 **Relevancia en IA/ML**: La inversión de matrices es una operación crucial en muchas áreas de la IA y el Machine Learning:\n",
        "\n",
        "* **Resolución de sistemas de ecuaciones lineales**: La inversa de una matriz es indispensable para resolver sistemas de ecuaciones lineales, que son frecuentes en ML al calcular las **actualizaciones de parámetros** en algoritmos o en problemas de optimización. Por ejemplo, en la **regresión linea**l, la solución a los mínimos cuadrados a menudo implica encontrar la inversa de una matriz.\n",
        "* **Optimización**: En algoritmos de optimización como el **gradiente descendente**, la inversión de matrices se utiliza para ajustar los pesos y minimizar la función de error en los modelos de aprendizaje automático.\n",
        "* **Transformaciones invertibles**: En el contexto de las transformaciones lineales, una transformación es invertible si existe otra transformación que la \"deshace\". Esto es crítico en algoritmos como los **autoencoders y modelos generativos**, donde los datos se codifican y luego se decodifican a su forma original.\n",
        "* **Matrices ortogonales**: La inversa de una matriz ortogonal es igual a su transpuesta ($Q^{-1} = Q^T$), lo que es fundamental en transformaciones que preservan la geometría de los datos, como rotaciones y reducciones de dimensionalidad en PCA.\n",
        "* **Algoritmos computacionales**: Métodos como la **eliminación gaussiana** y la **descomposición LU** proporcionan formas computacionales para obtener la inversa de una matriz, siendo pasos clave en la implementación de algoritmos esenciales.\n",
        "* **Propiedades**: La transpuesta de una inversa es la inversa de la transpuesta ($(A^{-1})^T = (A^T)^{-1}$), y el determinante de la inversa es el recíproco del determinante original ($\\det(A^{-1}) = (\\det A)^{-1}$).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "UPCJybtPHRS-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPCJybtPHRS-",
        "outputId": "b94daaaf-7296-4a96-d3ab-b0cd3283d864"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sympy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Definimos la matriz en SymPy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m E \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mMatrix([[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      5\u001b[0m                [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m]])\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
          ]
        }
      ],
      "source": [
        "import sympy as sp\n",
        "\n",
        "# Definimos la matriz en SymPy\n",
        "E = sp.Matrix([[2, 1],\n",
        "               [5, 3]])\n",
        "\n",
        "E_inv = E.inv()  # inversa exacta\n",
        "print(\"Inversa simbólica:\\n\", E_inv)\n",
        "\n",
        "# Comprobación\n",
        "print(\"Comprobación E * E_inv:\\n\", E * E_inv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mAndXJQl5e8w",
      "metadata": {
        "id": "mAndXJQl5e8w"
      },
      "source": [
        "\n",
        "#### 2.4.6 Determinante\n",
        "\n",
        "El **determinante** es un **número escalar único asociado a una matriz cuadrada**. En álgebra lineal, su valor nos ofrece información crucial sobre las propiedades de la matriz y la transformación lineal que representa. Geométricamente, el determinante describe cuánto distorsiona el volumen una transformación lineal y cómo cambia la orientación del espacio.\n",
        "\n",
        "En **álgebra lineal**, **el determinante nos dice si una matriz tiene inversa** (y si se puede \"deshacer\" una transformación) o no\n",
        "\n",
        "**En Machine Learning, esto se interpreta de manera muy práctica**:\n",
        "\n",
        "  * Si **determinante ≠ 0**:\n",
        "    * La matriz contiene **información independiente** .\n",
        "    * Las columnas de la matriz son **linealmente independientes**. Esto significa que **cada característica (columna) aporta información distinta y no redundante** al conjunto de datos o al modelo .\n",
        "    * La transformación lineal que representa la matriz no \"colapsa\" el espacio, es decir, preserva la dimensionalidad y no reduce el volumen a cero.\n",
        "  * Si d**eterminante = 0** :\n",
        "    * Indica que hay **columnas o filas redundantes**. Esto significa que una columna (o fila) es una copia o una combinación lineal de otras columnas (o filas).\n",
        "    * En el contexto de los datos, esto significa que **los datos no aportan información nueva y el modelo no puede aprender correctamente** si necesita invertir la matriz. La presencia de columnas linealmente dependientes puede causar problemas de **multicolinealidad**, afectando la estabilidad y la interpretabilidad de los modelos.\n",
        "    * La transformación lineal asociada a la matriz colapsa el espacio, reduciendo su dimensionalidad a cero o a una dimensión menor. Por ejemplo, en un espacio 2D, un determinante de 0 significa que los vectores columna son colineales (están sobre la misma línea), \"aplastando\" el área a cero.\n",
        "    * **Los modelos que necesitan invertir matrices** (por ejemplo, la regresión lineal utilizando la fórmula de mínimos cuadrados en forma normal) no pueden entrenar bien en este caso, ya que la inversa no existe .\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo 1:** Determinante distinto de 0\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "2 & 1 \\\\\n",
        "5 & 3\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Cálculo en matriz de 2X2:\n",
        "\n",
        "$$\n",
        "\\det(A) = 2\\cdot 3 - 1\\cdot 5 = 6 - 5 = 1\n",
        "$$\n",
        "\n",
        "✅ Como $\\det(A) = 1 \\neq 0$, las columnas son **independientes**.\n",
        "👉 Cada característica (representada por una columna) aporta información distinta. En un modelo, esto es deseable para un aprendizaje robusto.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo 2:** Determinante igual a 0 (redundancia)\n",
        "\n",
        "$$\n",
        "B =\n",
        "\\begin{bmatrix}\n",
        "2 & 4 \\\\\n",
        "1 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Cálculo:\n",
        "\n",
        "$$\n",
        "\\det(B) = 2\\cdot 2 - 4\\cdot 1 = 4 - 4 = 0\n",
        "$$\n",
        "\n",
        "❌ Aquí $\\det(B) = 0$.\n",
        "👉 La segunda columna es el **doble de la primera**. No aporta información nueva, lo que indica redundancia en los datos\n",
        "\n",
        "**Consideraciones adicionales en IA/ML sobre el determinante**:\n",
        "\n",
        "* **Valores singulares y Autovalores**: El determinante está relacionado con los autovalores y valores singulares de una matriz. Por ejemplo, para una matriz cuadrada, el determinante es el producto de sus autovalores.\n",
        "* **Matrices triangulares**: El determinante de una matriz triangular (superior o inferior) es simplemente el producto de los elementos de su diagonal principal. Esta propiedad es clave para algoritmos de descomposición.\n",
        "* **Costo computacional**: El cálculo directo del determinante mediante la fórmula de permutaciones es computacionalmente muy costoso (complejidad factorial $O(n!)$). Sin embargo, existen métodos mucho más eficientes, como el uso de la descomposición LU, que reducen la complejidad a $O(n^3)$. Las bibliotecas como NumPy utilizan estas implementaciones optimizadas.\n",
        "* **Estabilidad numérica**: En la práctica, con matrices grandes y números de punto flotante, calcular el determinante puede ser sensible a errores numéricos.\n",
        "Comprender el determinante no es solo una cuestión teórica, sino una herramienta diagnóstica fundamental para la calidad y la manejabilidad de los datos en el desarrollo de algoritmos de Machine Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OnK8AdcQ5fFc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnK8AdcQ5fFc",
        "outputId": "77073063-5388-4175-a002-cb5b3c30ba08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determinante ventas: 0.0\n",
            "Rango ventas: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Columnas: [precio_base, IVA, total_con_IVA]\n",
        "# Aquí IVA = 0.21 * base y total = base + IVA  → col3 = col1 + col2 (lineal)\n",
        "ventas = np.array([\n",
        "    [100, 21, 121],\n",
        "    [200, 42, 242],\n",
        "    [300, 63, 363]\n",
        "], dtype=float)\n",
        "\n",
        "print(\"Determinante ventas:\", np.linalg.det(ventas))        # → 0.0 exacto (o ~0 por redondeo)\n",
        "print(\"Rango ventas:\", np.linalg.matrix_rank(ventas))       # → 2 < 3  (hay redundancia)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DLOOPbVM5i4v",
      "metadata": {
        "id": "DLOOPbVM5i4v"
      },
      "source": [
        "\n",
        "## Recuerda\n",
        "\n",
        "Las operaciones con matrices son el **fundamento matemático** para manejar datos y algoritmos en IA y ML:\n",
        "* La **suma y resta** de matrices se realizan **elemento a elemento **y solo son posibles si las matrices tienen el **mismo tamaño**. Son esenciales en la optimización, como en el ajuste de pesos durante el **gradiente descendente**.\n",
        "* La **multiplicación por escalar** ajusta la magnitud de todos los elementos de una matriz (la \"estira o encoge\"), sin alterar sus dimensiones. Se usa para modificar parámetros y pesos de un modelo.\n",
        "* La **multiplicación de matrices** es una operación central que **combina información y transforma datos**. Es **clave en redes neuronales** para calcular las salidas de las capas, requiriendo que el número de columnas de la primera matriz sea igual al número de filas de la segunda.\n",
        "* La **transpuesta** de una matriz ($A^T$) **intercambia filas por columnas**. Es vital para **ajustar dimensiones** en cálculos de ML, utilizándose en productos escalares, cálculo de gradientes y modelos lineales.\n",
        "* La **inversa** de una matriz ($A^{-1}$) \"deshace\" su efecto, y se cumple que $A \\cdot A^{-1} = I$ (la matriz identidad). Solo existe para **matrices cuadradas y no singulares** (con determinante distinto de 0). Es crucial para la resolución de sistemas de** ecuaciones lineales** y en algoritmos de **optimización**.\n",
        "* El **determinante** es un número asociado a una **matriz cuadrada** que indica si esta tiene inversa. Un **determinante distinto de 0** significa que la matriz contiene información independiente (datos no redundantes); **un determinante igual a 0** señala **redundancia** en las columnas, lo que puede impedir el correcto aprendizaje de un modelo que necesite invertir la matriz."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HizVdvTVFBLi",
      "metadata": {
        "id": "HizVdvTVFBLi"
      },
      "source": [
        "## 2.5 Matrices en Python con NumPy\n",
        "\n",
        "En Python, las matrices no existen como tipo de dato básico. Para trabajar con ellas usamos **NumPy**, una librería fundamental en cálculo numérico y Machine Learning.\n",
        "\n",
        "👉 En NumPy, una **matriz** se representa con un objeto llamado `ndarray`.\n",
        "\n",
        "* Un **vector** es un array 1D (una lista de números).\n",
        "* Una **matriz** es un array 2D (tabla de números con filas y columnas).\n",
        "* Un **tensor** es un array con más dimensiones (3D, 4D, …).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.1 Crear matrices\n",
        "\n",
        "Con NumPy podemos crear matrices de varias formas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0QKY6UqMFZHx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QKY6UqMFZHx",
        "outputId": "cb62bcd6-3088-4311-fd18-2b8a439e62b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz A:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crear una matriz a partir de una lista de listas\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "print(\"Matriz A:\\n\", A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MiJIuMXOFb4d",
      "metadata": {
        "id": "MiJIuMXOFb4d"
      },
      "source": [
        "👉 Aquí creamos una matriz **2x3** (2 filas, 3 columnas) con números que nosotros mismos escribimos.\n",
        "\n",
        "---\n",
        "\n",
        "También podemos crear matrices especiales automáticamente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J5AtOsmnFdrx",
      "metadata": {
        "id": "J5AtOsmnFdrx"
      },
      "outputs": [],
      "source": [
        "# Crear una matriz de ceros\n",
        "Z = np.zeros((3, 3))\n",
        "print(\"\\nMatriz de ceros:\\n\", Z)\n",
        "\n",
        "# Crear una matriz de unos\n",
        "U = np.ones((2, 4))\n",
        "print(\"\\nMatriz de unos:\\n\", U)\n",
        "\n",
        "# Crear la matriz identidad (I)\n",
        "I = np.eye(3)\n",
        "print(\"\\nMatriz identidad:\\n\", I)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3uuqNZ5Fh21",
      "metadata": {
        "id": "b3uuqNZ5Fh21"
      },
      "source": [
        "👉 Muy útil en ML:\n",
        "\n",
        "* Las de ceros o unos se usan para **inicializar** datos.\n",
        "* La identidad juega el papel del “1” en las matrices: $A \\cdot I = A$.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.2 Acceso a elementos\n",
        "\n",
        "Una vez creada la matriz, podemos consultar sus elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4MRKFTQqFicB",
      "metadata": {
        "id": "4MRKFTQqFicB"
      },
      "outputs": [],
      "source": [
        "print(\"Elemento fila 1, col 2:\", A[0, 1])   # fila 1, columna 2 (recuerda que Python empieza en 0)\n",
        "print(\"Primera fila:\", A[0, :])             # todos los elementos de la fila 1\n",
        "print(\"Segunda columna:\", A[:, 1])          # todos los elementos de la columna 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nEYKIE8QFmD1",
      "metadata": {
        "id": "nEYKIE8QFmD1"
      },
      "source": [
        "\n",
        "👉 Aquí aprendemos:\n",
        "\n",
        "* `A[i, j]` → un elemento concreto.\n",
        "* `A[i, :]` → toda la fila *i*.\n",
        "* `A[:, j]` → toda la columna *j*.\n",
        "\n",
        "Esto se usa muchísimo para trabajar con datos: por ejemplo, seleccionar todas las notas de Matemáticas (columna) o todas las características de un alumno (fila).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.3 Operaciones básicas con matrices\n",
        "\n",
        "Las matrices permiten operaciones como suma, resta o multiplicación.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eX-pxalrFn1B",
      "metadata": {
        "id": "eX-pxalrFn1B"
      },
      "outputs": [],
      "source": [
        "B = np.array([[7, 8, 9],\n",
        "              [10, 11, 12]])\n",
        "\n",
        "print(\"Suma A + B:\\n\", A + B)     # suma elemento a elemento\n",
        "print(\"Resta A - B:\\n\", A - B)\n",
        "print(\"Multiplicación escalar (2*A):\\n\", 2 * A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlvEN7dPFqmx",
      "metadata": {
        "id": "GlvEN7dPFqmx"
      },
      "source": [
        "\n",
        "👉 Estas operaciones son **elemento a elemento** (cada casilla se suma, resta o multiplica con su correspondiente).\n",
        "\n",
        "Para hacer el **producto matricial clásico del álgebra lineal** usamos `@`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EPG0R80lFsSN",
      "metadata": {
        "id": "EPG0R80lFsSN"
      },
      "outputs": [],
      "source": [
        "print(\"Producto A @ B.T:\\n\", A @ B.T)  # trasponemos B para que encajen dimensiones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fNuUwt8NFuJQ",
      "metadata": {
        "id": "fNuUwt8NFuJQ"
      },
      "source": [
        "\n",
        "👉 Aquí, `A` es de tamaño (2x3) y `B.T` de (3x2), por lo que el resultado es (2x2).\n",
        "Esto se usa en ML para combinar datos con pesos o aplicar transformaciones.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.4 Propiedades de matrices\n",
        "\n",
        "NumPy nos permite calcular propiedades muy útiles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vj5rMYMaFv7I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj5rMYMaFv7I",
        "outputId": "7a3f5704-675c-43ec-e1db-02af31fbb8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transpuesta de A:\n",
            " [[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n",
            "Determinante de A.T @ A: 0.0\n",
            "Inversa de la identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Transpuesta de A:\\n\", A.T)                  # Cambia filas por columnas\n",
        "print(\"Determinante de A.T @ A:\", np.linalg.det(A.T @ A))  # Determinante\n",
        "print(\"Inversa de la identidad:\\n\", np.linalg.inv(I))      # Matriz inversa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VNtc5INvFyok",
      "metadata": {
        "id": "VNtc5INvFyok"
      },
      "source": [
        "\n",
        "👉 Estas operaciones aparecen mucho en Machine Learning:\n",
        "\n",
        "* La **transpuesta** alinea las dimensiones para cálculos.\n",
        "* El **determinante** indica si hay redundancia en los datos.\n",
        "* La **inversa** se usa en fórmulas como la regresión lineal.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hTHlTmhldth8",
      "metadata": {
        "id": "hTHlTmhldth8"
      },
      "source": [
        "**ACTIVIDAD 4 – Operaciones básicas con matrices**\n",
        "**Objetivo**: aplicar suma, resta y multiplicación.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Declara dos matrices `A` y `B` de tamaño 2×2.\n",
        "  2. Calcula su suma, resta y multiplicación por un escalar.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Calcula el producto matricial `A @ B`.\n",
        "  4\\. Obtén la transpuesta de `A`.\n",
        "\n",
        "* **Reto**\n",
        "  5\\. Calcula el determinante y la inversa de una matriz cuadrada 2×2. Comprueba que `A @ A⁻¹ = I`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "srT82c3ldtuT",
      "metadata": {
        "id": "srT82c3ldtuT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 7  8]\n",
            " [10 11]]\n",
            "[[1 2]\n",
            " [2 4]]\n",
            "[[14 16]\n",
            " [20 22]]\n",
            "[[2 4]\n",
            " [4 8]]\n",
            "[[ 8 10]\n",
            " [12 15]]\n",
            "[[6 6]\n",
            " [8 7]]\n",
            "[[23 46]\n",
            " [32 64]]\n",
            "[[ 7 10]\n",
            " [ 8 11]]\n",
            "-2.9999999999999902 0.0\n",
            "[[-3.66666667  2.66666667]\n",
            " [ 3.33333333 -2.33333333]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.array([[7, 8],\n",
        "              [10, 11]])\n",
        "print(a)\n",
        "b = np.array([[1, 2],\n",
        "              [2, 4]])\n",
        "print(b)\n",
        "#Multiplicacion por un escalar\n",
        "c = 2\n",
        "print(c * a)\n",
        "print(c * b)\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a @ b)\n",
        "print(a.T)\n",
        "determinante = np.linalg.det(a)\n",
        "determinanteb = np.linalg.det(b)\n",
        "print(determinante, determinanteb)\n",
        "#Si el determinante es cero no tiene inversa, como no es cero tiene inversa\n",
        "a_inv = np.linalg.inv(a)\n",
        "print(a_inv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3JtCZ5uWdxFl",
      "metadata": {
        "id": "3JtCZ5uWdxFl"
      },
      "source": [
        "### 2.5.5 Ejemplo aplicado a Machine Learning\n",
        "\n",
        "Supongamos que tenemos un dataset con alumnos:\n",
        "\n",
        "* Características → \\[horas de estudio, nota en prácticas].\n",
        "* Queremos calcular una predicción de su nota final a partir de unos pesos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kBFyMFebF0-J",
      "metadata": {
        "id": "kBFyMFebF0-J"
      },
      "outputs": [],
      "source": [
        "# Matriz de datos: filas = alumnos, columnas = características\n",
        "datos = np.array([[2, 7],   # Alumno 1\n",
        "                  [4, 6],   # Alumno 2\n",
        "                  [5, 9]])  # Alumno 3\n",
        "\n",
        "# Pesos del modelo: importancia de cada característica\n",
        "pesos = np.array([[0.4],\n",
        "                  [0.6]])\n",
        "\n",
        "# Predicciones: datos (3x2) @ pesos (2x1) = (3x1)\n",
        "predicciones = datos @ pesos\n",
        "print(\"Predicciones:\\n\", predicciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BSblOZk1F3WU",
      "metadata": {
        "id": "BSblOZk1F3WU"
      },
      "source": [
        "👉 Esto es exactamente lo que ocurre en un modelo lineal:\n",
        "\n",
        "* `datos` = matriz con las características de cada ejemplo.\n",
        "* `pesos` = parámetros que aprende el modelo.\n",
        "* `predicciones` = resultado para cada alumno."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0sOc8DUDF5kU",
      "metadata": {
        "id": "0sOc8DUDF5kU"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "* NumPy hace que trabajar con **matrices sea muy sencillo**.\n",
        "* Todo lo que aprendemos en matemáticas (sumar, multiplicar, trasponer…) lo podemos probar en Python con pocas líneas.\n",
        "* En Machine Learning, las **matrices son la forma estándar de guardar y manipular datos**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LnwzKdOeL9Ee",
      "metadata": {
        "id": "LnwzKdOeL9Ee"
      },
      "source": [
        "## Actividades prácticas\n",
        "\n",
        "### 📝 Actividad 2 – Matrices\n",
        "\n",
        "1. Crea dos matrices 2x2:\n",
        "\n",
        "   $\n",
        "   A = \\begin{bmatrix}1 & 3 \\\\ 2 & 4\\end{bmatrix}, \\quad\n",
        "   B = \\begin{bmatrix}2 & 0 \\\\ 1 & 2\\end{bmatrix}\n",
        "   $\n",
        "2. Calcula: suma, resta, transpuesta y producto $A \\times B$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "20fe841a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 3]\n",
            " [2 4]] \n",
            " [[2 0]\n",
            " [1 2]]\n",
            "[[3 3]\n",
            " [3 6]] [[-1  3]\n",
            " [ 1  2]] [[2 0]\n",
            " [2 8]] \n",
            " [[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "A = np.array([[1,3],\n",
        "             [2,4]])\n",
        "B = np.array([[2,0],\n",
        "             [1,2]])\n",
        "print(A,\"\\n\",B)\n",
        "\n",
        "\n",
        "suma = A + B\n",
        "resta = A - B\n",
        "Multiplicacion  = A * B\n",
        "Traspuesta = A.T\n",
        "\n",
        "print(suma, resta, Multiplicacion, \"\\n\",Traspuesta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d94ba2",
      "metadata": {
        "id": "b5d94ba2"
      },
      "source": [
        "\n",
        "## 3. Sistemas de ecuaciones lineales\n",
        "\n",
        "Un **sistema de ecuaciones lineales (SEL)** es un conjunto de dos o más ecuaciones que involucran varias incógnitas. Estos sistemas son omnipresentes en diversas disciplinas científicas e ingenieriles, donde se utilizan para modelar interacciones en redes bioquímicas, procesos económicos y muchos otros fenómenos.\n",
        "\n",
        "$\n",
        "\\begin{cases}\n",
        "2x + y = 8 \\\\\n",
        "x - y = 2\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "En este ejemplo, buscamos los valores de $x$ e $y$ que satisfacen simultáneamente ambas ecuaciones.\n",
        "\n",
        "***\n",
        "\n",
        "### Representación matricial\n",
        "\n",
        "Para facilitar la resolución y gestión de los sistemas de ecuaciones lineales, especialmente aquellos con un gran número de variables, podemos escribirlos de forma compacta utilizando matrices.\n",
        "\n",
        "El sistema de ecuaciones lineales del ejemplo anterior se puede expresar en su forma matricial como:\n",
        "\n",
        "$ \\begin{bmatrix}2 & 1 \\\\1 & -1\\end{bmatrix}\\begin{bmatrix}x \\\\y\\end{bmatrix}=\\begin{bmatrix}8 \\\\2\\end{bmatrix}$\n",
        "\n",
        "Esta representación consiste en tres componentes clave:\n",
        "\n",
        "* La matriz de la izquierda, denominada **matriz de coeficientes** ($A$), contiene los valores numéricos que acompañan a cada incógnita. En el ejemplo, $A = \\begin{bmatrix}2 & 1 \\\\1 & -1\\end{bmatrix}$.\n",
        "* El vector columna siguiente es el **vector de incógnitas** ($x$), que contiene las variables que deseamos resolver. En el ejemplo, $\\begin{bmatrix}x \\\\y\\end{bmatrix}$ .\n",
        "* El vector de la derecha es el **vector de términos independientes** ($b$), que agrupa los resultados o constantes de cada ecuación. En el ejemplo, $\\begin{bmatrix}8 \\\\2\\end{bmatrix}$ .\n",
        "\n",
        "De esta manera, un sistema de ecuaciones lineales se puede escribir de forma general como $A \\mathbf{x} = \\mathbf{b}$. Desde la perspectiva de las transformaciones lineales, esta notación nos pregunta: \"¿Qué vector $\\mathbf{x}$ es transformado en el vector $\\mathbf{b}$ por la transformación lineal representada por la matriz $A$?\".\n",
        "***\n",
        "\n",
        "### Resolver sistemas en Python con NumPy\n",
        "\n",
        "La resolución manual de sistemas de ecuaciones lineales puede ser tediosa y poco práctica para sistemas grandes. Afortunadamente, herramientas computacionales como la biblioteca **NumPy en Python** nos permiten encontrar la solución de manera eficiente.\n",
        "\n",
        "Podemos usar la función np.linalg.solve(A, b) para encontrar la solución del sistema [ref: user provided text]. Esta función toma la matriz de coeficientes $A$ y el vector de términos independientes $b$ como entradas y devuelve el vector de incógnitas $x$ que satisface el sistema.\n",
        "\n",
        "El resultado de ``np.linalg.solve`` muestra los valores de $x$ e $y$ que satisfacen ambas ecuaciones. Es importante destacar que detrás de ``np.linalg.solve`` se encuentran algoritmos numéricos altamente optimizados, como la **eliminación gaussiana** y la descomposición LU (Lower-Upper), que son los pilares del álgebra lineal computacional. Estos métodos permiten una resolución rápida y precisa, incluso para sistemas con miles de variables.\n",
        "\n",
        "En el caso de que la matriz de coeficientes $A$ sea **invertible** (es decir, no singular, con un determinante distinto de cero), la solución única del sistema se puede expresar como $\\mathbf{x} = A^{-1} \\mathbf{b}$. La computación de la inversa de una matriz, a su vez, también se basa en técnicas como la descomposición LU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2d51f2",
      "metadata": {
        "id": "bd2d51f2",
        "outputId": "e109f84c-edcb-4be9-e07a-73f5c9b9e618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Solución (x, y): [3.33333333 1.33333333]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2, 1], [1, -1]])\n",
        "b = np.array([8, 2])\n",
        "\n",
        "sol = np.linalg.solve(A, b)\n",
        "print(\"Solución (x, y):\", sol)  # [3.333..., 1.333...]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RaBJIUhTdja1",
      "metadata": {
        "id": "RaBJIUhTdja1"
      },
      "source": [
        "El resultado muestra los valores de $x$ y $y$ que satisfacen ambas ecuaciones.\n",
        "\n",
        "\n",
        "**ACTIVIDAD 5 – Resolver sistemas lineales**\n",
        "**Objetivo**: usar matrices para resolver ecuaciones.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Resuelve el sistema:\n",
        "\n",
        "     ```\n",
        "     2x + y = 8\n",
        "     x – y = 2\n",
        "     ```\n",
        "\n",
        "     usando `np.linalg.solve`.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Comprueba la solución sustituyendo los valores de `x` e `y` en las ecuaciones.\n",
        "\n",
        "* **Reto**\n",
        "  3\\. Escribe una función `resolver(A, b)` que reciba la matriz de coeficientes y el vector de términos independientes y devuelva la solución. Pruébala con otro sistema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1816ca06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = 3.3333333333333335, y = 1.3333333333333333\n",
            "Verificación:\n",
            "2x + y = 8.0 (esperado: 8)\n",
            "x - y = 2.0 (esperado: 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos las matrices del sistema\n",
        "A = np.array([[2, 1],\n",
        "              [1, -1]])\n",
        "B = np.array([8, 2])\n",
        "\n",
        "# Resolviendo el sistema\n",
        "sol = np.linalg.solve(A, B)\n",
        "\n",
        "#solución\n",
        "x, y = sol\n",
        "print(f\"x = {x}, y = {y}\")\n",
        "\n",
        "#Verificamos las ecuaciones\n",
        "eq1 = 2*x + y\n",
        "eq2 = x - y\n",
        "\n",
        "print(f\"Verificación:\")\n",
        "print(eq1)\n",
        "print(eq2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a5c37a0",
      "metadata": {
        "id": "9a5c37a0"
      },
      "source": [
        "\n",
        "***\n",
        "\n",
        "### ¿Por qué son importantes en Machine Learning?\n",
        "\n",
        "Los sistemas de ecuaciones lineales son de **importancia fundamental** en Machine Learning (ML) y la Inteligencia Artificial (IA), ya que subyacen a muchos algoritmos y procesos complejos :\n",
        "\n",
        "* **Regresión Lineal y Determinación de Parámetros**: Muchos problemas de Machine Learning, como la regresión lineal, se traducen directamente en resolver sistemas de ecuaciones lineales . Estos sistemas permiten encontrar los **parámetros (o coeficientes/pesos)** que mejor ajustan un modelo a los datos, minimizando el error de predicción. Por ejemplo, en la regresión lineal, la solución de mínimos cuadrados a menudo implica la inversión de una matriz .\n",
        "* **Optimización de Modelos**: En ML, la **optimización** es el proceso de encontrar los mejores parámetros para un modelo, minimizando una función de pérdida (error). La resolución de SELs (y operaciones de inversión de matrices relacionadas) es una tarea común al realizar **actualizaciones de parámetros** en algoritmos de optimización como el gradiente descendente . De hecho, el propio método del **gradiente descendente** puede verse como la resolución iterativa de una ecuación diferencial discreta que lleva a la solución óptima .\n",
        "* **Redes Neuronales**: La representación matricial es **el lenguaje intrínseco de las redes neuronales**.\n",
        "  * Cada capa de una red neuronal, especialmente en redes profundas, realiza una t**ransformación lineal** sobre los datos de entrada, que se implementa como una **multiplicación de matrices** (la matriz de entrada por una matriz de pesos aprendidos) .\n",
        "  * Los \"coeficientes\" o \"incógnitas\" de los SELs se corresponden con los** pesos y sesgos** que la red neuronal aprende durante su entrenamiento .\n",
        "  * La arquitectura completa de las redes neuronales se construye sobre estas ideas matemáticas, donde cada capa es una función que transforma los datos .\n",
        "* **Eficiencia Computacional y Manejo de Datos a Gran Escala**: La representación matricial y la resolución eficiente de sistemas con herramientas computacionales como NumPy **son fundamentales para entrenar modelos con muchos datos y variables**. Los problemas de IA a menudo involucran **datos de alta dimensión** y millones de parámetros (e.g., ResNet18 tiene 11 millones de parámetros) . Sin las operaciones matriciales optimizadas, sería imposible procesar tales volúmenes de información y realizar los cálculos necesarios para el aprendizaje.\n",
        "* **Análisis de Interacciones entre Variables**: Este método también ayuda a entender cómo las variables interactúan y contribuyen a las predicciones. La estructura de la matriz de coeficientes y la forma de la solución pueden ofrecer información sobre la independencia lineal de las características y su impacto en el modelo .\n",
        "\n",
        "En resumen, los sistemas de ecuaciones lineales, y el álgebra lineal en general, son el \"pan y mantequilla\" del Machine Learning computacional. Proporcionan el marco matemático indispensable que permite a las máquinas aprender, razonar y tomar decisiones, siendo la base para comprender a fondo el funcionamiento interno de los algoritmos de IA.\n",
        "\n",
        "***\n",
        "\n",
        "\n",
        "| Concepto                | Qué es                                           | Ejemplo concreto                  |\n",
        "|------------------------|-------------------------------------------------|---------------------------------|\n",
        "| Sistema de ecuaciones  | Conjunto de ecuaciones con varias incógnitas     | $2x + y = 8$, $x - y = 2$   |\n",
        "| Representación matricial| Forma compacta usando matrices y vectores        | $AX = B$                   |\n",
        "| Solución en Python     | Usar `np.linalg.solve` para encontrar incógnitas | $[3.333..., 1.333...]$        |\n",
        "| Uso en Machine Learning| Encontrar parámetros óptimos en modelos lineales | Regresión lineal                |\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5ebd14",
      "metadata": {
        "id": "1f5ebd14"
      },
      "source": [
        "## Actividades prácticas\n",
        "\n",
        "---\n",
        "\n",
        "### 📝 Actividad 3 – Sistemas de ecuaciones\n",
        "\n",
        "Resuelve con NumPy:\n",
        "\n",
        "$\n",
        "3x + 2y = 12 \\\\\n",
        "x -  y = 1\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cfb7b0c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = 2.7999999999999994, y = 1.8000000000000003\n",
            "Verificación:\n",
            "12.0\n",
            "0.9999999999999991\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos las matrices del sistema\n",
        "A = np.array([[3, 2],\n",
        "              [1, -1]])\n",
        "B = np.array([12, 1])\n",
        "\n",
        "# Resolviendo el sistema\n",
        "sol = np.linalg.solve(A, B)\n",
        "\n",
        "#solución\n",
        "x, y = sol\n",
        "print(f\"x = {x}, y = {y}\")\n",
        "\n",
        "#Verificamos las ecuaciones\n",
        "eq1 = 3*x + 2*y\n",
        "eq2 = x - y\n",
        "\n",
        "print(f\"Verificación:\")\n",
        "print(eq1)\n",
        "print(eq2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cTUnZMtGMrXt",
      "metadata": {
        "id": "cTUnZMtGMrXt"
      },
      "source": [
        "\n",
        "## 4 Uso de matrices en Machine Learning\n",
        "\n",
        "Un **dataset** (conjunto de datos) es la materia prima para los sistemas de IA, y puede representarse de forma natural y eficiente como una matriz. Esta estructura matricial permite organizar la información de manera que los algoritmos de ML puedan procesarla:\n",
        "\n",
        "* **Filas** → Representan los **ejemplos** o **muestras individuales** del dataset (por ejemplo, personas, casas, imágenes, etc.) .\n",
        "* **Columnas** → Representan las **características** o **atributos** de cada ejemplo (por ejemplo, edad, altura, precio, tipo de flor, etc.). A menudo, una \"feature\" es un tipo particular de medición.\n",
        "\n",
        "**Ejemplo: dataset Iris** El famoso **dataset Iris** es un ejemplo clásico de cómo un conjunto de datos se estructura como una matriz. Contiene mediciones de tres especies de Iris, con **150 data points (muestras) y cuatro características (features)** por cada muestra (longitud y anchura de sépalos y pétalos). Las etiquetas (species) asociadas a cada muestra también pueden ser representadas numéricamente.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x49KkbdHNt3H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x49KkbdHNt3H",
        "outputId": "5565fb75-3c95-450a-cfaa-f88d8753b012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma del dataset: (150, 4)\n",
            "Características: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Clases: ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "print(\"Forma del dataset:\", X.shape)   # (150, 4)\n",
        "print(\"Características:\", iris.feature_names)\n",
        "print(\"Clases:\", iris.target_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UwiFD7Z-t3H6",
      "metadata": {
        "id": "UwiFD7Z-t3H6"
      },
      "source": [
        "En ML, es común trabajar con **datos de alta dimensión**, que tienen muchas características . Las matrices son herramientas esenciales para representar y manipular estos datos. Por ejemplo, técnicas como la **normalización de datos** ajustan las características en una matriz para que estén en la misma escala, lo que mejora el rendimiento de los algoritmos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QcT7OlsUOAtK",
      "metadata": {
        "id": "QcT7OlsUOAtK"
      },
      "source": [
        "---\n",
        "\n",
        "### 4.2 Imágenes como matrices\n",
        "\n",
        "Una imagen digital es, en esencia, una tabla de números, lo que permite representarla de manera óptima como una matriz de píxeles\n",
        "\n",
        "* **Imágenes en blanco y negro**: Cada casilla de la matriz corresponde a un píxel, y su valor numérico representa la intensidad o el color (por ejemplo, 0 para negro, 255 para blanco).\n",
        "* **Imágenes en color**: Cada píxel tiene múltiples valores (por ejemplo, 3 valores para los canales Rojo, Verde y Azul - RGB). Esto no se representa con una simple matriz 2D, sino con un tensor (un arreglo multidimensional que generaliza escalares, vectores y matrices a dimensiones superiores). Por ejemplo, una imagen RGB podría ser un tensor de forma Altura x Anchura x 3 .\n",
        "\n",
        "**Ejemplo: imagen $28\\times28$ del dataset MNIST** Una imagen de $28\\times28$ píxeles, como las del famoso dataset MNIST, puede representarse como una matriz de ese tamaño. Para algunos modelos, esta matriz puede \"aplanarse\" en un vector de 784 números, que es la concatenación de todas las filas o columnas.\n",
        "\n",
        "👉 De esta forma, las redes neuronales pueden “leer” y procesar imágenes como si fueran tablas de números, lo que les permite identificar patrones, bordes, texturas y objetos mediante operaciones matemáticas como las convoluciones . Las **Redes Neuronales Convolucionales (CNNs)**, por ejemplo, dependen en gran medida de estas representaciones matriciales (y tensoriales) para identificar patrones en datos visuales.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JVbDi3vxOA1N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "JVbDi3vxOA1N",
        "outputId": "222b7421-0d32-4e0b-f158-a7bc2b1bef40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de X: (70000, 784)\n",
            "Forma de y: (70000,)\n",
            "Etiqueta real: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Descargar dataset MNIST (digitos escritos a mano)\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "\n",
        "X, y = mnist.data, mnist.target\n",
        "print(\"Forma de X:\", X.shape)  # (70000, 784) → 70k imágenes, cada una con 784 píxeles\n",
        "print(\"Forma de y:\", y.shape)  # etiquetas (dígitos 0–9)\n",
        "\n",
        "# 2. Seleccionamos una imagen (ejemplo: la nº 0)\n",
        "imagen_vector = X[0]          # vector de 784 elementos\n",
        "imagen_matriz = imagen_vector.reshape(28, 28)  # convertimos a matriz 28x28\n",
        "etiqueta = y[0]\n",
        "\n",
        "print(\"Etiqueta real:\", etiqueta)\n",
        "\n",
        "# 3. Mostrar la imagen\n",
        "plt.imshow(imagen_matriz, cmap=\"gray\")\n",
        "plt.title(f\"Dígito: {etiqueta}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DHOazYeYOA8d",
      "metadata": {
        "id": "DHOazYeYOA8d"
      },
      "source": [
        "### 4.3 Transformaciones lineales\n",
        "\n",
        "Una de las aplicaciones más profundas y fundamentales de las matrices en ML es su rol en las** transformaciones lineales**. Muchos modelos de ML son, en esencia, **multiplicaciones de matrices**. Las transformaciones lineales son funciones que mapean un vector de un espacio a otro, preservando la estructura del espacio vectorial, y son representadas por matrices.\n",
        "* **Regresión lineal**: La regresión lineal, uno de los modelos predictivos más simples pero potentes, se expresa matricialmente como: $$ y = Xw $$ Donde:\n",
        "  * $X$ = Matriz de datos de entrada (features), donde cada fila es una muestra y cada columna una característica .\n",
        "  * $w$ = Vector de **pesos del modelo (weights)** o coeficientes que el modelo aprende .\n",
        "  * $y$ = Vector de las predicciones de salida. En este contexto, la matriz $X$ describe una transformación que, al ser multiplicada por el vector de pesos $w$, produce las predicciones $y$. El objetivo de la regresión lineal es encontrar los pesos $w$ que mejor ajustan el modelo a los datos, lo que a menudo implica resolver un sistema de ecuaciones lineales, y en muchos casos, la inversión de matrices.\n",
        "\n",
        "\n",
        "Ejemplo en Python (regresión lineal simplificada):\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cxtkRRGGu1lK",
      "metadata": {
        "id": "cxtkRRGGu1lK"
      },
      "outputs": [],
      "source": [
        "# Dataset: horas de estudio y nota en prácticas\n",
        "X = np.array([[2, 7],\n",
        "              [4, 6],\n",
        "              [5, 9]])  # (3x2)\n",
        "\n",
        "# Pesos del modelo\n",
        "w = np.array([[0.4],\n",
        "              [0.6]])   # (2x1)\n",
        "\n",
        "y = X @ w   # Predicciones\n",
        "print(\"Predicciones:\\n\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZbShoJY6u1b6",
      "metadata": {
        "id": "ZbShoJY6u1b6"
      },
      "source": [
        "* **Redes neuronales**: Las redes neuronales, el motor de gran parte de la IA moderna, son composiciones de funciones y se construyen fundamentalmente sobre operaciones matriciales . Cada capa de una red neuronal aplica una transformación sobre sus datos de entrada. La operación básica de una capa (o un perceptrón) es: $$ h = XW + b $$ Donde :\n",
        "  * $X$ = Datos de entrada (o salida de la capa anterior).\n",
        "  * $W$ = Matriz de pesos o parámetros de la capa que el modelo aprende durante el entrenamiento.\n",
        "  * $b$ = Vector de sesgos (biases), un escalar que ajusta la salida de la neurona .\n",
        "  * $h$ = Salida lineal de la capa antes de la activación. Esta multiplicación de matrices ($XW$) es esencial para computar las salidas de cada capa, propagando la información a través de la red . Posteriormente, se aplica una función de activación no lineal (como Sigmoid, ReLU o Softmax) a $h$ para introducir la no-linealidad necesaria para modelar patrones complejos . El entrenamiento de estas redes implica ajustar estos pesos y sesgos, un proceso que se basa intensamente en el cálculo de gradientes y el algoritmo de retropropagación (backpropagation), el cual utiliza la regla de la cadena y operaciones matriciales.\n",
        "\n",
        "  Ejemplo sencillo en Python con NumPy de una capa de red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DPlzJxqlOBDH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPlzJxqlOBDH",
        "outputId": "8ce39d40-94c3-49b8-fc88-dcba82dfd8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrada X:\n",
            " [[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "Salida lineal h = XW + b:\n",
            " [[0.4 1.6]\n",
            " [1.6 4.9]]\n",
            "\n",
            "Salida tras ReLU:\n",
            " [[0.4 1.6]\n",
            " [1.6 4.9]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entrada (batch de 2 ejemplos, cada uno con 3 características)\n",
        "X = np.array([[1.0, 2.0, 3.0],\n",
        "              [4.0, 5.0, 6.0]])\n",
        "\n",
        "# Pesos (3 entradas -> 2 neuronas)\n",
        "W = np.array([[0.2, 0.8],\n",
        "              [0.5, -0.1],\n",
        "              [-0.3, 0.4]])\n",
        "\n",
        "# Sesgo (uno por neurona)\n",
        "b = np.array([0.1, -0.2])\n",
        "\n",
        "# Operación lineal: h = XW + b\n",
        "h = X @ W + b\n",
        "\n",
        "# Función de activación ReLU\n",
        "relu = np.maximum(0, h)\n",
        "\n",
        "print(\"Entrada X:\\n\", X)\n",
        "print(\"\\nSalida lineal h = XW + b:\\n\", h)\n",
        "print(\"\\nSalida tras ReLU:\\n\", relu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ejDAKYWWutGj",
      "metadata": {
        "id": "ejDAKYWWutGj"
      },
      "source": [
        "En resumen, las matrices son la representación fundamental de datos en ML, desde los conjuntos de datos crudos hasta las complejas interacciones dentro de las redes neuronales. Su uso no solo organiza la información, sino que también permite las transformaciones y cálculos eficientes que hacen posible el aprendizaje y la inteligencia artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QBszj10ROBKJ",
      "metadata": {
        "id": "QBszj10ROBKJ"
      },
      "source": [
        "### 4.4 Tensores como generalización\n",
        "\n",
        "En el ámbito del Deep Learning y la Inteligencia Artificial moderna, el concepto de tensor es fundamental. Los tensores son una **extensión o generalización de los escalares (números individuales), vectores (arreglos 1D) y matrices (arreglos 2D) a un número arbitrario de dimensiones** . Son las estructuras de datos fundamentales para almacenar y manipular información en frameworks de Deep Learning como TensorFlow y PyTorch .\n",
        "\n",
        "La \"dimensión\" de un tensor se refiere a su **rango (rank)** o el número de índices necesarios para acceder a un elemento individual.\n",
        "\n",
        "* **Escalar (Tensor 0D**): Un único número, como 5 . Representa magnitud sin dirección .\n",
        "* **Vector (Tensor 1D)**: Una lista ordenada de números, como  . Tiene magnitud y dirección .\n",
        "* **Matriz (Tensor 2D)**: Una tabla bidimensional de números . Es la forma estándar de almacenar datasets, donde las filas son ejemplos y las columnas son características .\n",
        "* **Tensor 3D**: Una colección de matrices o un arreglo tridimensional de números. Un ejemplo claro es una **imagen a color**, que puede representarse como alto × ancho × canales (por ejemplo, 3 canales para RGB) .\n",
        "* **Tensor 4D**: Una colección de tensores 3D. Un uso común es un** lote de imágenes** para el entrenamiento de una red neuronal: número de imágenes × alto × ancho × canales . Esto permite procesar múltiples imágenes simultáneamente, mejorando la eficiencia computacional.\n",
        "* **Tensores de dimensiones aún mayores**: Se utilizan para datos más complejos, como videos (que podrían ser 5D: lote × tiempo × alto × ancho × canales) o secuencias de datos en redes neuronales recurrentes (RNNs) .\n",
        "\n",
        "Ejemplo en PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "vxpRCxzJOBPm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxpRCxzJOBPm",
        "outputId": "6ce3800b-362b-4402-e32f-6d2bbe7759a1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 10 imágenes en blanco y negro de 28x28 píxeles\u001b[39;00m\n\u001b[1;32m      4\u001b[0m imagenes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 10 imágenes en blanco y negro de 28x28 píxeles\n",
        "imagenes = torch.zeros((10, 28, 28))\n",
        "print(\"Forma del tensor:\", imagenes.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3FGt3p5pwGUv",
      "metadata": {
        "id": "3FGt3p5pwGUv"
      },
      "source": [
        "En este ejemplo, ``torch.zeros((10, 28, 28))`` crea un tensor 3D donde la primera dimensión (10) representa el número de imágenes en el lote, y las otras dos dimensiones (28x28) representan el alto y ancho de cada imagen. Para imágenes en blanco y negro, no se necesita una dimensión explícita para los canales, ya que solo tienen un canal de intensidad."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7P-qAQOPnB",
      "metadata": {
        "id": "ca7P-qAQOPnB"
      },
      "source": [
        "👉 Los tensores son la **unidad básica en Deep Learning**, porque permiten representar datos complejos como imágenes, audio o texto.\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/TensorFaces16_%281%29.png\" alt=\"tensor\" width=\"600\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5xTInfhXOKw9",
      "metadata": {
        "id": "5xTInfhXOKw9"
      },
      "source": [
        "---\n",
        "\n",
        "## 📌 Idea clave\n",
        "\n",
        "* Los datasets en ML se representan como **matrices**.\n",
        "* Las imágenes y señales también son **matrices de números**.\n",
        "* Los algoritmos aplican **transformaciones lineales** (multiplicaciones matriciales) sobre los datos.\n",
        "* En Deep Learning trabajamos con **tensores**, que generalizan el concepto de matriz a más dimensiones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7oMsne16daRj",
      "metadata": {
        "id": "7oMsne16daRj"
      },
      "source": [
        "**ACTIVIDAD 6 – Tensores y dimensiones**\n",
        "**Objetivo**: identificar tensores y su uso en IA.\n",
        "\n",
        "* **Nivel básico**\n",
        "\n",
        "  1. Crea un tensor 3D con NumPy de tamaño `(3,4,2)` con números aleatorios.\n",
        "  2. Muestra su forma (`.shape`).\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Accede a la primera “matriz” del tensor y muéstrala.\n",
        "\n",
        "* **Reto**\n",
        "  4\\. Genera un lote de 10 imágenes en blanco y negro de 28×28 píxeles (`np.zeros((10,28,28))`). Explica qué representan las dimensiones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rJqi7Pe-dacP",
      "metadata": {
        "id": "rJqi7Pe-dacP"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m imagenes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma del tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m, imagenes\u001b[38;5;241m.\u001b[39mshape)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "imagenes = torch.zeros(3,4,2)\n",
        "print(\"Forma del tensor:\", imagenes.shape)\n",
        "print(imagenes.shape)\n",
        "print(imagenes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HPdzM2BHwpS1",
      "metadata": {
        "id": "HPdzM2BHwpS1"
      },
      "source": [
        "\n",
        "### Bibliografía\n",
        "\n",
        "*   **Danka, Tivadar.** *Mathematics of Machine Learning: Master linear algebra, calculus, and probability for machine learning*. Packt Publishing, 2025.\n",
        "*   **Gutierrez, Gilbert.** *Mathematics for AI: The Hidden Language of Machines*. Serie AI from Scratch, segunda entrega. No se especifica editorial ni fecha, pero es parte de una serie sobre IA.\n",
        "*   **Herraiz, Joaquín L., Benavent, María Teresa, Cordero, Paula, González, Raúl, Ibáñez, Paula, Infante, Juan Antonio, Porqueras, Fernando, Prieto, M. Ángeles, Rodríguez, Gema de Jesús.** *Las matemáticas de la inteligencia artificial*. Proyecto de Innovación de la Universidad Complutense de Madrid - Convocatoria 2020/2021. Este texto se difunde a través del Proyecto LibreTexts de Recursos Educativos Abiertos (REA).\n",
        "*   **Libro:** *Dive into Deep Learning*. Disponible en formato PDF.\n",
        "    *   **En línea:** https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/index.html.\n",
        "    *   **PDF:** https://d2l.ai/d2l-en.pdf.\n",
        "*   **Libro:** *Mathematics for Machine Learning*. Disponible en formato PDF.\n",
        "    *   **En línea:** https://mml-book.github.io/.\n",
        "    *   **PDF:** https://mml-book.github.io/book/mml-book.pdf.\n",
        "\n",
        "### Webgrafía (Recursos en Línea y Cursos)\n",
        "\n",
        "*   **Blogs:**\n",
        "    *   Aprendemachinelearning.com: http://www.aprendemachinelearning.com/.\n",
        "    *   Towards Data Science: https://towardsdatascience.com/three-month-plan-to-learn-mathematics-behind-machine-learning-74335a578740.\n",
        "*   **Coursera:** Curso \"Multivariate Calculus for Machine Learning\".\n",
        "    *   **En línea:** https://www.coursera.org/learn/multivariate-calculus-machine-learning.\n",
        "*   **Curso de Introducción a la Inteligencia Artificial:**\n",
        "    *   Elements of AI: https://www.elementsofai.com/.\n",
        "    *   Building AI: https://buildingai.elementsofai.com.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
