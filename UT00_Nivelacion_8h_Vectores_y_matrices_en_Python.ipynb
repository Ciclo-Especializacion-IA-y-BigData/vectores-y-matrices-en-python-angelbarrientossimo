{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "55f77e34",
      "metadata": {
        "id": "55f77e34"
      },
      "source": [
        "\n",
        "\n",
        "# Vectores y matrices en Python\n",
        "\n",
        "### Objetivos de aprendizaje\n",
        "\n",
        "* Comprender el concepto de vector y matriz como estructuras matem√°ticas y de datos.\n",
        "* Realizar operaciones b√°sicas: suma, resta, producto escalar y multiplicaci√≥n de matrices.\n",
        "* Resolver sistemas de ecuaciones lineales sencillos.\n",
        "* Aplicar todo esto con **NumPy**, la librer√≠a est√°ndar de Python para c√°lculo num√©rico.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rNzoNVhrVI_e",
      "metadata": {
        "id": "rNzoNVhrVI_e"
      },
      "source": [
        "# 1. Vectores\n",
        "\n",
        "### ¬øQu√© es un vector?\n",
        "\n",
        "Un **vector** es un objeto matem√°tico que nos da **dos informaciones a la vez**:\n",
        "\n",
        "1. **M√≥dulo (o longitud)** ‚Üí Cu√°nto mide. En el espacio euclidiano n-dimensional, el m√≥dulo (tambi√©n conocido como norma euclidiana o 2-norma) de un vector x = (x‚ÇÅ, ..., x‚Çô) se calcula como ‚àö(x‚ÇÅ¬≤ + ... + x‚Çô¬≤).\n",
        "2. **Direcci√≥n** ‚Üí hacia d√≥nde apunta.\n",
        "\n",
        "Aunque popularmente se define por tener magnitud y direcci√≥n, un vector es fundamentalmente una estructura matem√°tica que permite operaciones como la adici√≥n y la multiplicaci√≥n por escalares. Los conceptos de distancia y ortogonalidad tambi√©n son parte de su estructura geom√©trica\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Vector_00.svg/2560px-Vector_00.svg.png\" alt=\"Elementos de un vector\" width=\"300\"/>\n",
        "\n",
        "\n",
        "La forma m√°s sencilla de imaginar un vector es como una **flecha** dibujada desde un punto de partida (el **origen**) hasta un punto de llegada. En el contexto de un espacio vectorial (una estructura matem√°tica m√°s amplia), el origen es el vector nulo\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplos cotidianos\n",
        "\n",
        "* **Dar una patada a un bal√≥n**: no basta con la fuerza (magnitud), tambi√©n importa hacia d√≥nde lo lanzas (direcci√≥n).\n",
        "* **El viento**: decimos ‚Äú20 km/h al Este‚Äù. Esa es la magnitud (20) y la direcci√≥n (Este).\n",
        "* **Un mapa**: para ir de casa al instituto: ‚Äú3 manzanas al Norte y 2 al Este‚Äù ‚Üí vector $(3,2)$.\n",
        "\n",
        "---\n",
        "\n",
        "### Representaci√≥n matem√°tica\n",
        "\n",
        "Un vector se escribe como una colecci√≥n ordenada de n√∫meros, que pueden estar dispuestos en una fila o columna.\n",
        "\n",
        "$$\n",
        "\\vec{v} = (x_1, x_2, \\ldots, x_n)\n",
        "$$\n",
        "\n",
        "* Cada n√∫mero $x_i$ es un **componente** del vector.\n",
        "* En el ejemplo del mapa:\n",
        "  $\\vec{v}=(3,2)$ significa *3 pasos al Norte y 2 al Este*.\n",
        "* En un espacio tridimensional, podemos tener:\n",
        "  $\\vec{v}=(2,3,5)$.\n",
        "\n",
        "Para realizar operaciones matem√°ticas, es com√∫n representar los vectores como vectores columna. Un vector n-dimensional se puede ver como una funci√≥n que mapea un conjunto de √≠ndices {1, 2, ..., n} a n√∫meros reales, donde cada √≠ndice corresponde a un componente  \n",
        "\n",
        "---\n",
        "\n",
        "### Diferencia con un escalar\n",
        "\n",
        "Un escalar es la entidad matem√°tica m√°s simple: es un √∫nico valor num√©rico que representa magnitud, pero carece de direcci√≥n.\n",
        "\n",
        "Ejemplo de escalar:* La temperatura es de 25 ¬∫C.\n",
        "\n",
        "En IA, las tasas de aprendizaje o los t√©rminos de sesgo (bias) en una neurona son ejemplos de escalares\n",
        "\n",
        "A diferencia de los escalares, los vectores se usan para describir cantidades que existen en m√°s de una dimensi√≥n\n",
        "\n",
        "---\n",
        "\n",
        "### Vectores en la vida real‚Ä¶ y en la IA\n",
        "\n",
        "Los vectores y las matrices son fundamentales en la Inteligencia Artificial (IA) para la representaci√≥n y manipulaci√≥n de datos. En el aprendizaje autom√°tico, cada punto de datos se puede representar como un vector en un espacio de caracter√≠sticas, donde cada dimensi√≥n corresponde a una caracter√≠stica espec√≠fica.\n",
        "\n",
        "* **Im√°genes**: Una imagen puede representarse como una gran matriz de valores de p√≠xeles, donde cada p√≠xel corresponde a la intensidad de color. Por ejemplo, una imagen en blanco y negro de 100 p√≠xeles puede representarse como un vector con 100 componentes. Las redes neuronales convolucionales (CNNs) utilizan estas representaciones matriciales para procesar datos visuales.\n",
        "* **Datos de una casa**: Caracter√≠sticas de una casa como la superficie, el n√∫mero de habitaciones y el precio pueden agruparse en un vector de caracter√≠sticas, por ejemplo, (80, 3, 120000).\n",
        "* **NLP (Procesamiento de Lenguaje Natural)**: Las palabras o frases se transforman en vectores en un espacio de alta dimensi√≥n, conocidos como embeddings. Estos vectores permiten a los algoritmos de IA \"comprender\" el lenguaje de manera significativa, capturando relaciones sem√°nticas entre las palabras en lugar de solo coincidencias de cadenas. T√©cnicas como Word2Vec y GloVe utilizan estas representaciones vectoriales.\n",
        "* **Redes Neuronales**: Una red neuronal se describe como una funci√≥n multivariable que toma un vector como entrada (input) y produce otro vector como salida (output). La manipulaci√≥n de vectores y espacios vectoriales es clave para dise√±ar arquitecturas de redes neuronales eficientes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "k8oCQJFRVdlB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8oCQJFRVdlB",
        "outputId": "c27db847-0af7-437b-bed0-681ecd19a8f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector: [2, 3]\n",
            "Vector con NumPy: [2 3]\n"
          ]
        }
      ],
      "source": [
        "# Vector como lista\n",
        "v = [2, 3]\n",
        "print(\"Vector:\", v)\n",
        "\n",
        "# Con NumPy (mejor para matem√°ticas e IA)\n",
        "import numpy as np\n",
        "v = np.array([2, 3])\n",
        "print(\"Vector con NumPy:\", v)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OJiMSfzSV7cI",
      "metadata": {
        "id": "OJiMSfzSV7cI"
      },
      "source": [
        "Aqu√≠ el vector $(3,2)$ puede interpretarse como ‚Äú3 pasos al Norte y 2 al Este‚Äù.\n",
        "\n",
        "---\n",
        "\n",
        "### Visualizaci√≥n en el plano\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/5d/Position_vector.svg\"  alt=\"vector en el plano\" width=\"300\"/>\n",
        "\n",
        "Podemos dibujar el vector en python para que sea m√°s intuitivo:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DqV-Z3xBV9HM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "DqV-Z3xBV9HM",
        "outputId": "911c8f50-a480-4508-8cb2-f0ef6cef16a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "v = np.array([2,3])\n",
        "\n",
        "plt.axhline(0, color='black')\n",
        "plt.axvline(0, color='black')\n",
        "plt.quiver(0,0,v[0],v[1],angles='xy',scale_units='xy',scale=1,color='red')\n",
        "plt.xlim(-1,5); plt.ylim(-1,5)\n",
        "plt.gca().set_aspect('equal')\n",
        "plt.title(\"Vector (3,2)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "y-2jXdNDWDGU",
      "metadata": {
        "id": "y-2jXdNDWDGU"
      },
      "source": [
        "Esto muestra la flecha desde el origen $(0,0)$ hasta el punto $(3,2)$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dt7F_yw-WoCu",
      "metadata": {
        "id": "Dt7F_yw-WoCu"
      },
      "source": [
        "### 1.1 Caracter√≠sticas principales de los vectores\n",
        "\n",
        "Un vector se puede entender desde distintos puntos de vista:\n",
        "\n",
        "1. **Colecci√≥n ordenada de n√∫meros**\n",
        "   Un vector es una colecci√≥n ordenada de n√∫meros, es decir, una secuencia finita y ordenada de valores reales. Esta representaci√≥n es una forma clara y concisa de almacenar informaci√≥n, ya que el formato de tupla sugiere que los componentes pertenecen juntos en un orden preciso.\n",
        "\n",
        "   Ejemplo: $ (1.297, -2.35, 32.3, 29.874) $ Cada n√∫mero en la secuencia es un componente del vector. En el contexto de la inteligencia artificial (IA), estos valores podr√≠an representar un conjunto de caracter√≠sticas para un punto de datos individual en un conjunto de datos, donde cada elemento corresponde a una caracter√≠stica diferente (por ejemplo, altura, peso, edad, ingresos). Para datos de una casa, un vector podr√≠a ser (superficie, n¬∫ de habitaciones, precio)\n",
        "\n",
        "  \n",
        "   En programaci√≥n, puede representarse como:\n",
        "\n",
        "   ```python\n",
        "   v = [1.297, -2.35, 32.3, 29.874]   # lista en Python\n",
        "   ```\n",
        "\n",
        "   Aunque las listas de Python pueden representar vectores, los arrays de NumPy son una representaci√≥n m√°s eficiente para c√°lculos en √°lgebra linea\n",
        "  \n",
        "   ```python\n",
        "   import numpy as np\n",
        "\n",
        "    v = np.array([1.297, -2.35, 32.3, 29.874]) # lista en Numpy\n",
        "   ```\n",
        "---\n",
        "\n",
        "2. **Componentes**\n",
        "  Un vector $\\vec{v} = (v_1, v_2, \\ldots, v_n)$ est√° definido por sus **componentes** $v_i$. Estos componentes son los valores num√©ricos que conforman el vector. En un espacio de caracter√≠sticas, cada dimensi√≥n del vector corresponde a una caracter√≠stica espec√≠fica del dato que se representa. Los vectores se utilizan para describir cantidades que existen en m√°s de una dimensi√≥n, a diferencia de los escalares que solo tienen una magnitud.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Vector_09.svg/2560px-Vector_09.svg.png\"  alt=\"componentes vector\" width=\"300\"/>\n",
        "\n",
        "* Ejemplo en 2D: $\\vec{v} = (3, 4)$.\n",
        "\n",
        "  * El componente $v_x=3$ indica cu√°nto se mueve en el eje horizontal (x-axis).\n",
        "\n",
        "  * El componente $v_y=4$ indica cu√°nto se mueve en el eje vertical (y-axis). En matem√°ticas y IA, los vectores se suelen representar como vectores columna para una notaci√≥n m√°s compacta y para facilitar las operaciones matriciales.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "3. **Magnitud y direcci√≥n**\n",
        "\n",
        "Un vector es una cantidad que posee tanto magnitud (o m√≥dulo) como direcci√≥n. Esta dualidad es lo que los distingue de los escalares, que son un √∫nico valor num√©rico que solo representa magnitud, sin direcci√≥n asociada.\n",
        "\n",
        " <img src=\"https://soradavid.wordpress.com/wp-content/uploads/2014/08/imagen-1-muestra-las-principales-caracterc3adsticas-de-un-vector.png\"  alt=\"magnitud y direcci√≥n  vector\" width=\"300\"/>\n",
        "\n",
        "La **magnitud** (tambi√©n conocida como **norma** o **longitud**) es el \"tama√±o\" del vector. En el espacio euclidiano n-dimensional ($\\mathbb{R}^n$), la magnitud (o norma euclidiana, tambi√©n conocida como 2-norma) de un vector $\\vec{x} = (x_1, \\ldots, x_n)$ se calcula como: $$ |\\vec{x}| = \\sqrt{x_1^2 + x_2^2 + \\cdots + x_n^2} $$ Esta f√≥rmula proviene directamente del Teorema de Pit√°goras, extendido a dimensiones superiores. Las normas son funciones que miden el tama√±o de un vector y deben satisfacer tres propiedades clave: positividad definida (ser mayor o igual a cero y cero solo si el vector es nulo), homogeneidad positiva (escalar el vector escala su norma) y la desigualdad triangular. Esta es una de las \"p-normas\".\n",
        "\n",
        "  * Ejemplo: si $\\vec{x}=(3,4)$, entonces $|\\vec{x}| = \\sqrt{3^2+4^2} = 5$.\n",
        "\n",
        "La **direcci√≥n** indica hacia d√≥nde apunta el vector. En un espacio bidimensional (2D), puede calcularse con un √°ngulo: $$ \\theta = \\arctan\\left(\\frac{y}{x}\\right) $$ Para $(3,4)$, el √°ngulo es $\\arctan(4/3) \\approx 53^\\circ$. De manera m√°s general, la direcci√≥n de un vector est√° intr√≠nsecamente relacionada con el concepto de producto interno (o producto escalar). El **producto interno** permite definir el √°ngulo $\\alpha$ entre dos vectores $\\vec{x}$ e $\\vec{y}$ mediante la relaci√≥n $\\langle\\vec{x}, \\vec{y}\\rangle = |\\vec{x}||\\vec{y}| \\cos\\alpha$. Esta relaci√≥n es tan fundamental que, en espacios vectoriales abstractos donde la intuici√≥n geom√©trica del √°ngulo no es evidente, se utiliza para definir el √°ngulo entre vectores. En el aprendizaje autom√°tico, los **gradientes** de una funci√≥n son vectores que indican la direcci√≥n de m√°ximo crecimiento de la funci√≥n en un punto dado.\n",
        "\n",
        "\n",
        "   **Ejemplo en Python**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "krl_InUbWtI-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krl_InUbWtI-",
        "outputId": "5b2e8ea9-b8ef-4729-8aa0-a73d74aaaa6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Magnitud: 5.0\n",
            "Direcci√≥n: 53.13010235415598\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "v = np.array([3,4])\n",
        "magnitud = np.linalg.norm(v)\n",
        "direccion = np.degrees(np.arctan2(v[1], v[0]))\n",
        "print(\"Magnitud:\", magnitud)       # 5.0\n",
        "print(\"Direcci√≥n:\", direccion)     # 53.13 grados\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78Q_hB4Xa3w3",
      "metadata": {
        "id": "78Q_hB4Xa3w3"
      },
      "source": [
        "**ACTIVIDAD 1 ‚Äì Representar y calcular magnitud**\n",
        "**Objetivo**: comprender la representaci√≥n y longitud de un vector.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Define el vector `v = (3,4)` como lista en Python y como `np.array`.\n",
        "  2. Calcula su magnitud usando la f√≥rmula de Pit√°goras (`math.sqrt`).\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Repite el c√°lculo con `np.linalg.norm`.\n",
        "  4\\. Representa el vector en el plano con Matplotlib.\n",
        "\n",
        "* **Reto**\n",
        "  5\\. Crea una funci√≥n `magnitud(v)` que calcule la longitud de cualquier vector en 2D o 3D.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZJ8smOrTa3-f",
      "metadata": {
        "id": "ZJ8smOrTa3-f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5.0\n",
            "5.0\n",
            "[2, 2, 2]\n",
            "3.4641016151377544\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "#Nivel basico\n",
        "a = np.array([3,4])\n",
        "b = [3,4]\n",
        "magnitud = math.sqrt(b[0]** 2 + b[1]** 2)\n",
        "print(magnitud)\n",
        "#Nivel intermedio\n",
        "magnitud_2 = np.linalg.norm(a)\n",
        "print(magnitud_2)\n",
        "\n",
        "#Reto\n",
        "def magnitud1():\n",
        "    longitud = 0\n",
        "    if dimension == 2:\n",
        "        longitud += math.sqrt(vector[0] ** 2 + vector[1] ** 2)\n",
        "    else:\n",
        "        longitud += math.sqrt(vector[0] ** 2 + vector[1] ** 2 + vector[2] ** 2)\n",
        "    print(longitud)\n",
        "\n",
        "dimension = int(input(\"Dimension 2/3¬ø?\"))\n",
        "if dimension == 2:\n",
        "    x = int(input(\"Valor para vector[0]\"))\n",
        "    y = int(input(\"Valor para vector[1]\"))\n",
        "    vector  =[x,y]\n",
        "elif dimension == 3:\n",
        "    x = int(input(\"Valor para vector[0]\"))\n",
        "    y = int(input(\"Valor para vector[1]\"))\n",
        "    z = int(input(\"Valor para vector[2]\"))\n",
        "    vector  = [x,y,z]\n",
        "else:\n",
        "    print(\"Valor no valido\")\n",
        "print(vector)\n",
        "magnitud1()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-zQ6qWJfW4Rm",
      "metadata": {
        "id": "-zQ6qWJfW4Rm"
      },
      "source": [
        "\n",
        "4. **Interpretaci√≥n geom√©trica**\n",
        "\n",
        "Las operaciones b√°sicas con vectores tienen interpretaciones geom√©tricas claras que son fundamentales para entender c√≥mo los algoritmos de IA manipulan los datos. Un espacio vectorial es una estructura matem√°tica que define c√≥mo los vectores pueden ser sumados y multiplicados por escalares, y estas operaciones deben satisfacer ciertas propiedades para asegurar la coherencia del espacio\n",
        "\n",
        "* **Suma de vectores**: Equivale a **colocar una flecha tras otra**, con el resultado siendo una **traslaci√≥n**. La suma de dos vectores, **x + y**, produce un nuevo vector donde cada componente es la suma de los componentes correspondientes de **x** e **y**. Esta operaci√≥n debe cumplir propiedades como la conmutatividad y la asociatividad, y el resultado debe permanecer dentro del mismo espacio vectorial (propiedad de aditividad)\n",
        "\n",
        "  * **Ejemplo**: Si sumamos el vector $(2,1)$ con el vector $(1,3)$, obtenemos $(2+1, 1+3) = (3,4)$. Geom√©tricamente, esto es como mover el origen del segundo vector al final del primero y el resultado es el vector que va desde el origen del primero hasta el final del segundo.\n",
        "\n",
        "\n",
        "     <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Vector_addition.svg/2560px-Vector_addition.svg.png\"  alt=\"Suma de vectores\" width=\"300\"/>\n",
        "\n",
        "   \n",
        "* **Multiplicaci√≥n por un escalar**:  Esta operaci√≥n **estira o encoge el vector en la misma direcci√≥n**, o invierte su direcci√≥n si el escalar es negativo. Cuando un vector v se multiplica por un escalar c, el nuevo vector $c\\cdot\\vec{v}$ tiene una magnitud que es $|c|$ veces la magnitud de v, y su direcci√≥n es la misma si c > 0 o la opuesta si c < 0. Esta propiedad se conoce como homogeneidad positiva y es una de las caracter√≠sticas clave de las normas vectoriales\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Scalar_multiplication_by_r%3D3.svg/2560px-Scalar_multiplication_by_r%3D3.svg.png\"  alt=\"Multiplicaci√≥n por un escalar\" width=\"250\"/>\n",
        "   \n",
        "  * **Ejemplo**: Si multiplicamos el vector $(2,1)$ por el escalar $3$, obtenemos $(3 \\cdot 2, 3 \\cdot 1) = (6,3)$. El vector resultante es tres veces m√°s largo y apunta en la misma direcci√≥n que el original.\n",
        "\n",
        "---\n",
        "\n",
        "5. **Conexi√≥n con IA**\n",
        "\n",
        "Los vectores y las matrices son la **base fundamental para la representaci√≥n y manipulaci√≥n de datos en la Inteligencia Artificial (IA)**, especialmente en el aprendizaje autom√°tico y las redes neuronales.\n",
        "\n",
        "* **Componentes**: En IA, los componentes de un vector suelen representar las **caracter√≠sticas (features) de un dato**. Cada dimensi√≥n del vector corresponde a una caracter√≠stica espec√≠fica.\n",
        "    * **Ejemplo**: En un conjunto de datos de estudiantes, un vector podr√≠a contener la nota de un alumno en cada asignatura, donde cada componente es la calificaci√≥n de una materia diferente. De manera similar, para una casa, un vector podr√≠a ser (superficie, n¬∫ de habitaciones, precio).\n",
        "* **Magnitud**: La magnitud (o norma) de un vector en IA puede indicar el **‚Äúnivel general‚Äù o la intensidad de un dato**. Las normas son cruciales para determinar la similitud entre puntos de datos, as√≠ como para medir y controlar la complejidad de los modelos de redes neuronales.\n",
        "  * **Ejemplo**: En el contexto de un alumno, la magnitud del vector de sus notas podr√≠a representar su rendimiento global. En algoritmos de aprendizaje no supervisado, la distancia entre puntos (derivada de la magnitud) se utiliza para agrupar datos en clusters.\n",
        "* **Direcci√≥n**: La direcci√≥n de un vector es vital porque representa el **patr√≥n intr√≠nseco del dato**. Es particularmente importante al **comparar similitudes con otros datos**. El **producto interno (o producto escalar)** de dos vectores es una herramienta fundamental que permite cuantificar esta similitud y definir el √°ngulo entre ellos.\n",
        "  * La **similitud del coseno**, por ejemplo, mide cu√°nto se mueven las caracter√≠sticas de dos muestras de datos juntas, sin tener en cuenta su magnitud.\n",
        "* En el entrenamiento de modelos de IA, la direcci√≥n tambi√©n es fundamental en los algoritmos de optimizaci√≥n. Por ejemplo, los **gradientes** son vectores que indican la direcci√≥n de m√°ximo crecimiento de una funci√≥n. El **m√©todo del gradiente descendente** se basa en mover los par√°metros del modelo en la direcci√≥n opuesta al gradiente para minimizar una funci√≥n de p√©rdida, lo cual es esencial para el entrenamiento de redes neuronales."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TyJti_d7fPWj",
      "metadata": {
        "id": "TyJti_d7fPWj"
      },
      "source": [
        "### 1.2 Vectores en Machine Learning e Inteligencia Artificial\n",
        "\n",
        "Los **vectore** son la **forma est√°ndar y fundamental de representar la informaci√≥n en la Inteligencia Artificial (IA)**. Cada dato, por muy complejo que sea, acaba representado como una **colecci√≥n ordenada de n√∫meros**. Las matem√°ticas de la IA se basan en un marco matem√°tico que dicta c√≥mo se representan, procesan y analizan los datos. El √°lgebra lineal, en particular, se encarga de los espacios vectoriales y las transformaciones, siendo el n√∫cleo de las computaciones de la IA.\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.1 Representaci√≥n de datos simples\n",
        "\n",
        "Cada vector es un conjunto de **caracter√≠sticas** (o features) de un ejemplo. En el aprendizaje autom√°tico (Machine Learning), cada punto de datos se puede representar como un vector en un **espacio de caracter√≠sticas**, donde cada dimensi√≥n del vector corresponde a una caracter√≠stica espec√≠fica. La representaci√≥n de datos en espacios multi-dimensionales es fundamental para tareas como la clasificaci√≥n, el clustering y la regresi√≥n.\n",
        "Ejemplo: Las notas de un alumno en tres asignaturas, como (8.5, 7.0, 9.0), donde cada componente es la calificaci√≥n en una materia diferente.\n",
        "\n",
        "  * **Ejemplo**: Las notas de un alumno en tres asignaturas, como (8.5, 7.0, 9.0), donde cada componente es la calificaci√≥n en una materia diferente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F1f71U5sfTTf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1f71U5sfTTf",
        "outputId": "06f8bb35-e472-4374-c1d4-e4d0098f3e69"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[6 7 8]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "notas = np.array([8.5, 7.0, 9.0])\n",
        "print(notas)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gWiOgOvQflvK",
      "metadata": {
        "id": "gWiOgOvQflvK"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.2.2 Coordenadas en espacios geom√©tricos\n",
        "\n",
        "Un vector puede representar un punto en el plano (2D) o en el espacio (3D), y de manera m√°s general, en espacios multidimensionales. Los espacios vectoriales proporcionan la base para representar datos en **espacios de alta dimensi√≥n**.\n",
        "\n",
        "* **Ejemplo**: Un $ \\text{punto} = (10, 13, 5) $ Este tipo de representaci√≥n es muy √∫til para **visualizar** c√≥mo se agrupan los datos, utilizando t√©cnicas de reducci√≥n de dimensionalidad para proyectar datos de alta dimensi√≥n en 2D o 3D y observar patrones, clusters y outliers.\n",
        "\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/3D_Cartesian.svg/330px-3D_Cartesian.svg.png\"  alt=\"punto 3d\" width=\"300\"/>\n",
        "\n",
        "\n",
        "Este tipo de representaci√≥n es muy √∫til para **visualizar** c√≥mo se agrupan los datos.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.3 Caracter√≠sticas de objetos\n",
        "\n",
        "Un objeto real se describe mediante varias medidas, que se agrupan en un vector de caracter√≠sticas. Un ejemplo cl√°sico es el **conjunto de datos Iris**.\n",
        "\n",
        "* Ejemplo cl√°sico (dataset Iris): $ \\text{flor} = (5.1,\\ 3.5,\\ 1.4,\\ 0.2) $ Esta representaci√≥n describe una flor con medidas de longitud y ancho de s√©palos y p√©talos. Cada una de estas cuatro medidas es una caracter√≠stica, y juntas forman un vector en $\\mathbb{R}^4$. Para trabajar con estos vectores en programaci√≥n, se utilizan eficientemente arrays de NumPy.\n",
        "\n",
        "  <img src=\"https://miro.medium.com/1*H2UmG5L1I5bzFCW006N5Ag.png\"  alt=\"dataset Iris\" width=\"600\"/>\n",
        "\n",
        "\n",
        "```python\n",
        "flor = np.array([5.1, 3.5, 1.4, 0.2])\n",
        "print(flor)\n",
        "# Esto ser√≠a un array de NumPy que representa la flor, √∫til para c√°lculos eficientes.\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.4 Procesamiento del lenguaje natural (NLP)\n",
        "\n",
        "En NLP, las palabras o frases se transforman en **vectores en un espacio de alta dimensi√≥n**, conocidos como word embeddings.\n",
        "\n",
        "Palabras con significados parecidos tienen vectores cercanos en este espacio. Los word embeddings, como Word2Vec y GloVe, representan palabras en un espacio de menor dimensi√≥n mientras preservan las relaciones sem√°nticas entre ellas.\n",
        "\n",
        "* Ejemplo: ‚Äúrey‚Äù y ‚Äúreina‚Äù est√°n m√°s pr√≥ximos entre s√≠ que ‚Äúrey‚Äù y ‚Äúmesa‚Äù, debido a que los modelos matem√°ticos capturan las relaciones sem√°nticas entre palabras. Las t√©cnicas de reducci√≥n de dimensionalidad como PCA pueden aplicarse a estos embeddings para simplificar tareas como la similitud sem√°ntica o el agrupamiento de textos.\n",
        "\n",
        "   <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Word_embedding_illustration.svg/1920px-Word_embedding_illustration.svg.png\"  alt=\"word embeddings\" width=\"300\"/>\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.5 Im√°genes y se√±ales\n",
        "\n",
        "Una imagen o una se√±al se puede ver como un vector o una matriz, lo que permite su procesamiento mediante algoritmos de IA\n",
        "\n",
        "* **Im√°genes**: Una imagen puede representarse como una gran matriz de valores de p√≠xeles, donde cada p√≠xel corresponde a la intensidad de color. Por ejemplo, una imagen de 256x256 p√≠xeles puede representarse como una matriz de 256x256 (para escala de grises) o 256x256x3 (para im√°genes RGB). Las **Redes Neuronales Convolucionales (CNNs)**, por ejemplo, aplican operaciones matem√°ticas para identificar caracter√≠sticas clave como bordes y texturas en im√°genes, lo que es crucial para la clasificaci√≥n de objetos o el reconocimiento facial.\n",
        "\n",
        "* **Se√±ales** (audio o sensores): Las se√±ales, como las de audio o las captadas por sensores, se transforman en vectores para su an√°lisis y clasificaci√≥n [Fuente original del usuario]. Las **Transformadas de Fourier** y las **Transformadas Wavelet** son herramientas matem√°ticas utilizadas para procesar se√±ales y extraer caracter√≠sticas importantes, permitiendo a los modelos de IA operar en el dominio de la frecuencia para identificar patrones o reducir la dimensionalidad de los datos.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#### 1.2.6 Espacios de caracter√≠sticas\n",
        "\n",
        "En Machine Learning (ML), un vector es un punto en un espacio de caracter√≠sticas.\n",
        "\n",
        "* Cada dimensi√≥n corresponde a un atributo o caracter√≠stica.\n",
        "* Los algoritmos, como el K-Nearest Neighbors (KNN) o los m√©todos de clustering, trabajan **midiendo distancias** entre estos puntos para encontrar patrones, similitudes o agrupaciones en los datos. La elecci√≥n de una base para este espacio de caracter√≠sticas es crucial para transformar los datos de entrada en una representaci√≥n m√°s √∫til para el modelo. Las t√©cnicas de reducci√≥n de dimensionalidad como PCA tambi√©n operan en estos espacios, proyectando los datos en nuevas direcciones para capturar la mayor varianza y simplificar el an√°lisis\n",
        "\n",
        "üìå Ejemplo visual:\n",
        "\n",
        "* Alumnos representados por $(\\text{horas de estudio}, \\text{nota en examen})$.\n",
        "* Cada alumno es un **punto en 2D**.\n",
        "* El agrupamiento de puntos muestra **patrones de aprendizaje**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ww6UloWwo04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "7ww6UloWwo04",
        "outputId": "df255ed5-a454-471e-bbd2-f4d7f6395ce2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Datos ficticios: horas de estudio y notas\n",
        "horas = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "notas = [40, 45, 50, 60, 65, 70, 80, 85]\n",
        "\n",
        "plt.scatter(horas, notas, color='blue')\n",
        "plt.xlabel(\"Horas de estudio\")\n",
        "plt.ylabel(\"Nota en examen\")\n",
        "plt.title(\"Alumnos representados como vectores (horas, nota)\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2qX72Sijhj5C",
      "metadata": {
        "id": "2qX72Sijhj5C"
      },
      "source": [
        "### 1.3. Operaciones con vectores\n",
        "\n",
        "En Machine Learning, los vectores se manipulan con operaciones matem√°ticas fundamentales que son cruciales para **comparar datos, medir similitudes** y construir algoritmos. El √°lgebra lineal, que estudia los espacios vectoriales y sus transformaciones, constituye el n√∫cleo de los c√°lculos de la IA.\n",
        "\n",
        "\n",
        "---\n",
        "#### 1.3.1 Suma de vectores\n",
        "\n",
        "La suma de vectores se realiza elemento a elemento. Si tenemos dos vectores $\\mathbf{x} = (x_1, \\ldots, x_n)$ e $\\mathbf{y} = (y_1, \\ldots, y_n)$, su suma es $\\mathbf{x} + \\mathbf{y} = (x_1+y_1, \\ldots, x_n+y_n)$.\n",
        "\n",
        "$$\n",
        "(2,3)+(1,4)=(3,7)\n",
        "$$\n",
        "\n",
        "üëâ **Interpretaci√≥n**: Geom√©tricamente, la suma de vectores es una traslaci√≥n, donde se coloca un vector a continuaci√≥n del otro.\n",
        "\n",
        "üìå En geometr√≠a, esta operaci√≥n se representa com√∫nmente con la **regla del paralelogramo**. La propiedad de aditividad de un espacio vectorial establece que la suma de dos vectores cualesquiera sigue siendo un vector dentro del mismo espacio.\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Vector_addition.svg/2560px-Vector_addition.svg.png\"  alt=\"Suma de vectores\" width=\"300\"/>\n",
        "\n",
        "En el aprendizaje autom√°tico, la suma de vectores es √∫til en muchos algoritmos, especialmente en la optimizaci√≥n, donde los pesos de un modelo se ajustan sumando o restando valores de gradiente. En Python, las arrays de NumPy soportan esta operaci√≥n de forma predeterminada con el operador +.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YwUm_uxqbr3d",
      "metadata": {
        "id": "YwUm_uxqbr3d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "x = np.array([2, 3])\n",
        "y = np.array([1, 4])\n",
        "\n",
        "# Suma de vectores\n",
        "suma = x + y\n",
        "\n",
        "print(\"x + y =\", suma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yZ2pDNJtbsHF",
      "metadata": {
        "id": "yZ2pDNJtbsHF"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.12 Multiplicaci√≥n por un escalar\n",
        "\n",
        "En esta operaci√≥n, cada componente del vector se multiplica por un n√∫mero real (escalar). Si un vector $\\mathbf{x} = (x_1, \\ldots, x_n)$ se multiplica por un escalar $c \\in \\mathbb{R}$, el resultado es $c\\mathbf{x} = (cx_1, \\ldots, cx_n)$.\n",
        "\n",
        "$$\n",
        "2\\cdot(2,3)=(4,6)\n",
        "$$\n",
        "\n",
        "üëâ Interpretaci√≥n: Geom√©tricamente, la multiplicaci√≥n por un escalar **estira o encoge el vector**, manteniendo la misma direcci√≥n si el escalar es positivo, o invirtiendo su direcci√≥n si es negativo. Esta es la propiedad de homogeneidad positiva de una norma.\n",
        "\n",
        "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Scalar_multiplication_by_r%3D3.svg/2560px-Scalar_multiplication_by_r%3D3.svg.png\"  alt=\"Multiplicaci√≥n por un escalar\" width=\"250\"/>\n",
        "\n",
        "En Machine Learning, la multiplicaci√≥n por un escalar se utiliza al ajustar los pesos y par√°metros de un modelo, por ejemplo, escalando el gradiente durante procesos de optimizaci√≥n como el descenso de gradiente. La tasa de aprendizaje en el descenso de gradiente es un escalar que determina el tama√±o del paso para actualizar los par√°metros del modelo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qrR0uH57bv_c",
      "metadata": {
        "id": "qrR0uH57bv_c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos el vector\n",
        "x = np.array([2, 3])\n",
        "\n",
        "# Definimos el escalar\n",
        "c = 2\n",
        "\n",
        "# Multiplicaci√≥n por escalar\n",
        "resultado = c * x\n",
        "\n",
        "print(f\"{c} * {x} = {resultado}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yNsk-SaobQGk",
      "metadata": {
        "id": "yNsk-SaobQGk"
      },
      "source": [
        "**ACTIVIDAD 2 ‚Äì Suma, resta y producto escalar**\n",
        "**Objetivo**: practicar operaciones b√°sicas con vectores.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Declara `a = (2,1)` y `b = (1,3)`. Calcula su suma y resta con NumPy.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Calcula el producto escalar con un bucle `for`.\n",
        "  3\\. Calcula el producto escalar con `np.dot(a, b)`.\n",
        "\n",
        "* **Reto**\n",
        "  4\\. Implementa una funci√≥n `similitud_coseno(a, b)` que devuelva el coseno del √°ngulo entre dos vectores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "ugNblW1ZbQTQ",
      "metadata": {
        "id": "ugNblW1ZbQTQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3 4]\n",
            "[ 1 -2]\n",
            "5\n",
            "5\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "np.float64(0.7071067811865475)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "#Nivel basico\n",
        "a = np.array([2,1])\n",
        "b = np.array([1,3])\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "#Nivel intermedio\n",
        "for i in a:\n",
        "    if i ==  a[0]:\n",
        "        resultado1 = a[0] * b[0]\n",
        "    else:\n",
        "        resultado2 = a[1] * b[1]\n",
        "print(resultado1 + resultado2)\n",
        "\n",
        "f = np.dot(a,b)\n",
        "print(f)\n",
        "#Reto\n",
        "def similitud_coseno(a, b):\n",
        "    producto_punto = np.dot(a, b)\n",
        "    norma_a = np.linalg.norm(a)\n",
        "    norma_b = np.linalg.norm(b)\n",
        "    \n",
        "    if norma_a == 0 or norma_b == 0:\n",
        "        return 0 \n",
        "    \n",
        "    return producto_punto / (norma_a * norma_b)\n",
        "similitud_coseno(a,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0yuMre9qbwI1",
      "metadata": {
        "id": "0yuMre9qbwI1"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.3 Norma (longitud del vector)\n",
        "\n",
        "La norma de un vector, a menudo referida como su magnitud o longitud, mide el \"tama√±o\" del vector.\n",
        "La norma euclidiana (tambi√©n conocida como 2-norma) de un vector $\\vec{v}=(x_1,x_2,\\ldots,x_n)$ se calcula como: $$ |\\vec{v}|=\\sqrt{x_1^2+x_2^2+\\cdots+x_n^2} $$\n",
        "\n",
        "\n",
        "* Ejemplo: $$ |(2,3,5)|=\\sqrt{2^2+3^2+5^2}=\\sqrt{4+9+25}=\\sqrt{38}\\approx6.16 $$ Esta f√≥rmula se deriva directamente del Teorema de Pit√°goras, generalizado a dimensiones superiores. Una funci√≥n para medir la magnitud de un vector se define como norma si satisface tres propiedades clave: positividad definida, homogeneidad positiva y la desigualdad triangular\n",
        "\n",
        "Existen otras p-normas, como la 1-norma (distancia de Manhattan), que es la suma de los valores absolutos de los componentes, y la $\\infty$-norma, que es el valor absoluto m√°ximo de los componentes.\n",
        "\n",
        "En Machine Learning, las nociones de magnitud y distancia son cr√≠ticas para determinar la similitud entre puntos de datos, as√≠ como para medir y controlar la complejidad de los modelos de redes neuronales. Por ejemplo, el error cuadr√°tico medio (MSE) es esencialmente la distancia euclidiana escalada entre la predicci√≥n y la verdad fundamental. Las normas se utilizan para controlar la complejidad de los modelos durante el entrenamiento, penalizando coeficientes grandes para fomentar la simplicidad y mejorar la generalizaci√≥n.\n",
        "\n",
        "En Python, la magnitud euclidiana de un vector puede calcularse eficientemente usando ``np.linalg.norm``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xSvzdzA0asUo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSvzdzA0asUo",
        "outputId": "b3c415a3-af4f-4467-b65c-da0b3e9c525e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norma Euclidiana (2-norma): 6.164414002968976\n",
            "Norma 1: 10.0\n",
            "Norma infinito: 5.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos el vector\n",
        "v = np.array([2, 3, 5])\n",
        "\n",
        "# Norma Euclidiana (2-norma)\n",
        "norm_2 = np.linalg.norm(v)\n",
        "\n",
        "# Norma 1 (suma de valores absolutos)\n",
        "norm_1 = np.linalg.norm(v, ord=1)\n",
        "\n",
        "# Norma infinito (m√°ximo valor absoluto)\n",
        "norm_inf = np.linalg.norm(v, ord=np.inf)\n",
        "\n",
        "print(\"Norma Euclidiana (2-norma):\", norm_2)\n",
        "print(\"Norma 1:\", norm_1)\n",
        "print(\"Norma infinito:\", norm_inf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ucKhg7bashE",
      "metadata": {
        "id": "3ucKhg7bashE"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.4 Normalizaci√≥n\n",
        "\n",
        "La **normalizaci√≥n** de un vector consiste en **dividir el vector por su norma**, de forma que el vector resultante tenga una longitud de 1. $$ \\hat{v}=\\frac{\\vec{v}}{|\\vec{v}|} $$\n",
        "\n",
        "\n",
        "\n",
        "üëâ **Muy √∫til para comparar vectores en la misma escala**. Esta t√©cnica es fundamental en IA, ya que permite estandarizar conjuntos de datos para asegurar que las diferentes caracter√≠sticas tengan el mismo rango e influencia en el modelo, mejorando la precisi√≥n de las predicciones. En el entrenamiento de modelos de redes neuronales, a menudo se estandarizan los datos restando la media y dividiendo por la desviaci√≥n est√°ndar, lo que asegura que todas las caracter√≠sticas tengan una media de 0 y una varianza de 1\n",
        "\n",
        " <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Vector_normalization.svg/800px-Vector_normalization.svg.png\" width=\"100\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rpezHClicAvY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpezHClicAvY",
        "outputId": "7e7dcec4-ef0e-4ccf-95bd-0317baf40d98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Producto escalar SIN normalizar: 30\n",
            "Producto escalar CON normalizaci√≥n: 0.6\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos dos vectores\n",
        "a = np.array([10, 0])\n",
        "b = np.array([3, 4])\n",
        "\n",
        "# Producto escalar sin normalizar\n",
        "dot_no_norm = np.dot(a, b)\n",
        "\n",
        "# Normalizamos los vectores\n",
        "a_norm = a / np.linalg.norm(a)\n",
        "b_norm = b / np.linalg.norm(b)\n",
        "\n",
        "# Producto escalar con vectores normalizados (similitud coseno)\n",
        "dot_norm = np.dot(a_norm, b_norm)\n",
        "\n",
        "print(\"Producto escalar SIN normalizar:\", dot_no_norm)\n",
        "print(\"Producto escalar CON normalizaci√≥n:\", dot_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MZD-y8vFcA64",
      "metadata": {
        "id": "MZD-y8vFcA64"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.5 Producto escalar (dot product)\n",
        "\n",
        "El **producto escalar** (o producto interno) de dos vectores $\\vec{u}=(u_1, u_2, \\ldots, u_n)$ y $\\vec{v}=(v_1, v_2, \\ldots, v_n)$ se calcula multiplicando cada componente correspondiente y luego sumando los resultados. $$ \\vec{u}\\cdot\\vec{v}=\\sum_i u_i v_i $$\n",
        "Ejemplo: $$ (2,3,5)\\cdot(1,0,4)=2\\cdot1+3\\cdot0+5\\cdot4=2+0+20=22 $$\n",
        "\n",
        "üëâ**Interpretaci√≥n**: El producto escalar **mide qu√© tan alineados est√°n los vectores**. Es una forma de cuantificar la similitud entre dos vectores\n",
        "\n",
        "* Si el resultado es grande y positivo (cuando los vectores se normalizan), significa que los vectores apuntan en direcciones parecidas o tienen una alta similitud. La similitud coseno es precisamente el producto interno de dos vectores normalizados y se usa para medir cu√°n similares son las caracter√≠sticas de dos muestras de datos sin considerar su magnitud.\n",
        "\n",
        "* Si el resultado es cero, los vectores son perpendiculares (ortogonales), lo que significa que no tienen una relaci√≥n lineal o \"no contienen informaci√≥n\" el uno del otro.\n",
        "\n",
        "En Machine Learning, los productos escalares son una herramienta fundamental para definir la ortogonalidad y el √°ngulo entre vectores, lo que es esencial para algoritmos que miden la similitud o la distancia. En Python, se puede calcular con la funci√≥n ```np.dot```.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_u-9gS4CaoOV",
      "metadata": {
        "id": "_u-9gS4CaoOV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "\n",
        "# Producto escalar\n",
        "dot_product = np.dot(u, v)\n",
        "\n",
        "print(\"Producto escalar:\", dot_product)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BNXlCYZ_aok0",
      "metadata": {
        "id": "BNXlCYZ_aok0"
      },
      "source": [
        "---\n",
        "\n",
        "#### 1.3.6 Distancia entre vectores\n",
        "\n",
        "La **distancia euclidiana** entre dos vectores $\\vec{u}$ y $\\vec{v}$ mide lo distintos que son. Se calcula como la norma euclidiana de la diferencia entre los vectores: $$ d(\\vec{u},\\vec{v})=|\\vec{u}-\\vec{v}| = \\sqrt{(u_1-v_1)^2 + (u_2-v_2)^2 + \\cdots + (u_n-v_n)^2} $$\n",
        "\n",
        "* Ejemplo: $$ d((2,3,5),(1,0,4))=|(2-1, 3-0, 5-4)|=|(1,3,1)|=\\sqrt{(1)^2+(3)^2+(1)^2}=\\sqrt{1+9+1}=\\sqrt{11}\\approx3.316 $$\n",
        "\n",
        "üëâ En Machine Learning, las nociones de distancia son **cr√≠ticas para determinar la similitud entre puntos de datos**. Se usa ampliamente en algoritmos de **clustering** (agrupamiento de datos en funci√≥n de su cercan√≠a), **K-Nearest Neighbors (KNN)** (para clasificar puntos de datos bas√°ndose en la mayor√≠a de votos de sus vecinos m√°s cercanos) y **detecci√≥n de anomal√≠as** (identificando puntos de datos que se desv√≠an significativamente de los patrones esperados).\n",
        "\n",
        "En Python, la distancia euclidiana se puede calcular usando ``np.linalg.norm(x - y, ord=2)``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xkZ-0cpxbPC3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkZ-0cpxbPC3",
        "outputId": "df6fe00e-cfdb-4a02-a60b-3b562fe5de9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 3.3166247903554\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos los vectores\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "\n",
        "# Distancia euclidiana\n",
        "dist_euclidiana = np.linalg.norm(u - v)\n",
        "\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XcCIvMFqblZN",
      "metadata": {
        "id": "XcCIvMFqblZN"
      },
      "source": [
        "**ACTIVIDAD 3 ‚Äì Comparar vectores**\n",
        "**Objetivo**: entender diferencias entre magnitud y distancia.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Calcula la norma de `u = (2,3,5)` y `v = (1,0,4)` con `np.linalg.norm`.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Calcula la distancia euclidiana entre `u` y `v` con la f√≥rmula y con `np.linalg.norm(u-v)`.\n",
        "\n",
        "* **Reto**\n",
        "  3\\. Genera 5 vectores aleatorios en 3D con `np.random.randint` y calcula cu√°l es el par m√°s cercano entre ellos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "21ssutz8blk3",
      "metadata": {
        "id": "21ssutz8blk3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 3.3166247903554\n",
            "[[5 8 7]\n",
            " [4 4 4]\n",
            " [1 9 7]\n",
            " [9 6 5]\n",
            " [9 3 8]]\n",
            "\n",
            "El par m√°s cercano de vectores es:\n",
            "[5 8 7] y [1 9 7] con una distancia de 4.123105625617661\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "u = np.array([2, 3, 5])\n",
        "v = np.array([1, 0, 4])\n",
        "dist_euclidiana = np.linalg.norm(u - v)\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n",
        "\n",
        "#Reto\n",
        "vectores = 5\n",
        "array_aux = []\n",
        "\n",
        "for i in range(vectores):\n",
        "    x = np.random.randint(1, 10)\n",
        "    y = np.random.randint(1, 10)\n",
        "    z = np.random.randint(1, 10)\n",
        "    array_aux.append([x, y, z])\n",
        "\n",
        "array_aux = np.array(array_aux)\n",
        "print(array_aux) \n",
        "\n",
        "distancias = np.linalg.norm(array_aux[:, np.newaxis] - array_aux, axis=2)\n",
        "\n",
        "np.fill_diagonal(distancias, np.inf)\n",
        "indice_min = np.unravel_index(np.argmin(distancias), distancias.shape)\n",
        "\n",
        "vector1 = array_aux[indice_min[0]]\n",
        "vector2 = array_aux[indice_min[1]]\n",
        "distancia_min = distancias[indice_min]\n",
        "\n",
        "print(f\"\\nEl par m√°s cercano de vectores es:\\n{vector1} y {vector2} con una distancia de {distancia_min}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lMUIHuttbPQG",
      "metadata": {
        "id": "lMUIHuttbPQG"
      },
      "source": [
        "---\n",
        "#### 1.3.7 Distancia vs. Similitud coseno\n",
        "\n",
        "La elecci√≥n entre usar la **distancia** o la **similitud coseno** para comparar vectores en Machine Learning depende fundamentalmente de si la magnitud absoluta o la direcci√≥n (patr√≥n) de los vectores es m√°s relevante para el problema en cuesti√≥n. Ambas son medidas de la relaci√≥n entre vectores y son cr√≠ticas en la IA para determinar la similitud entre puntos de datos.\n",
        "\n",
        "* **Distancia (generalmente Distancia Euclidiana)**:\n",
        "\n",
        "  * La distancia euclidiana mide el \"tama√±o\" de la diferencia entre dos vectores. Es una medida de cu√°n \"lejos\" est√°n dos puntos en el espacio.\n",
        "  * **Importa la magnitud absoluta**: La distancia es sensible a la longitud o magnitud de los vectores. Un vector m√°s largo tendr√° una mayor distancia de otro vector si su magnitud es muy diferente, incluso si apuntan en la misma direcci√≥n. Esto se ilustra con la f√≥rmula de la norma euclidiana, que considera la suma de los cuadrados de los componentes.\n",
        "  * **Ejemplo**: Si un vector de datos de una casa (superficie, precio) es (80, 100000) y otro es (160, 200000), la distancia entre ellos ser√° grande, reflejando las grandes diferencias en sus valores absolutos.\n",
        "\n",
        "**En Machine Learning**: Las nociones de magnitud y distancia son cr√≠ticas para determinar la similitud entre puntos de datos. Algoritmos de aprendizaje no supervisado, como el clustering, separan los puntos de datos en grupos bas√°ndose en sus distancias mutuas. Sin embargo, en espacios de alta dimensi√≥n, las m√©tricas de distancia tradicionales pueden perder su efectividad, un fen√≥meno conocido como la \"maldici√≥n de la dimensionalidad\".\n",
        "\n",
        "* **Similitud Coseno**:\n",
        "  * El producto interno (o escalar) de dos vectores normalizados es una medida de similitud frecuentemente utilizada.\n",
        "  * **Importa solo la direcci√≥n (patr√≥n)**: La similitud coseno mide el coseno del √°ngulo entre dos vectores. Al normalizar los vectores (dividi√©ndolos por su norma para que tengan longitud 1), esta m√©trica se vuelve **independiente de su magnitud**, enfoc√°ndose exclusivamente en su orientaci√≥n relativa.\n",
        "  * **Ejemplo**: Volviendo al ejemplo de la casa, si la casa (160, 200000) se normaliza a (0.64, 0.77) y la (80, 100000) a (0.64, 0.77), su similitud coseno ser√≠a m√°xima (1), indicando el mismo \"patr√≥n\" o proporci√≥n, a pesar de que sus valores absolutos son muy diferentes.\n",
        "\n",
        "**En Machine Learning**: La similitud coseno es una herramienta fundamental en IA, especialmente cuando la direcci√≥n (el \"patr√≥n\") es m√°s informativa que la magnitud. Se utiliza para saber \"cu√°nto se mueven las caracter√≠sticas de dos muestras de datos juntas\".\n",
        "\n",
        "* **Muy relevante en embeddings de texto e im√°genes**:\n",
        "  * **Procesamiento de Lenguaje Natural (NLP)**: Las palabras se transforman en vectores de alta dimensi√≥n llamados word embeddings. En estos espacios, palabras con significados parecidos tienen vectores cercanos, y la similitud coseno permite cuantificar esta cercan√≠a sem√°ntica, ya que las longitudes de los vectores de palabras individuales no suelen ser tan importantes como su orientaci√≥n mutua.\n",
        "  * **Im√°genes**: En computer vision y reconocimiento de im√°genes, los vectores representan patrones visuales. La similitud coseno ayuda a comparar estos patrones sin que el brillo general o el tama√±o de un objeto dominen la comparaci√≥n.\n",
        "  * **Redes Neuronales**: Se describe una red neuronal como una funci√≥n multivariable que toma un vector como entrada y produce otro vector como salida. La manipulaci√≥n de vectores y espacios vectoriales es clave para dise√±ar arquitecturas de redes neuronales eficientes. La similitud coseno puede usarse para evaluar la relaci√≥n entre estas representaciones vectoriales internas.\n",
        "\n",
        "En resumen, mientras que la **distancia** proporciona una medida del espacio absoluto que separa dos puntos, la **similitud coseno** ofrece una perspectiva de su alineaci√≥n direccional. Comprender cu√°ndo aplicar cada una es vital para el desarrollo efectivo de modelos de IA, ya que permite a los algoritmos interpretar mejor las relaciones subyacentes en los datos.\n",
        "\n",
        "---\n",
        "### C√≥digo ejemplo en Python (NumPy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dRrfUvNFhzn9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRrfUvNFhzn9",
        "outputId": "43b63b9f-dc76-41f5-a22d-b10aefb3609e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distancia euclidiana: 100000.03199999488\n",
            "Similitud coseno: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dos vectores: mismo patr√≥n pero distinta magnitud\n",
        "a = np.array([80, 100000])\n",
        "b = np.array([160, 200000])\n",
        "\n",
        "# --- Distancia Euclidiana ---\n",
        "dist_euclidiana = np.linalg.norm(a - b)\n",
        "\n",
        "# --- Similitud Coseno ---\n",
        "# Normalizamos ambos vectores\n",
        "a_norm = a / np.linalg.norm(a)\n",
        "b_norm = b / np.linalg.norm(b)\n",
        "\n",
        "# Producto escalar entre los vectores normalizados\n",
        "sim_coseno = np.dot(a_norm, b_norm)\n",
        "\n",
        "# La distancia euclidiana es enorme porque los valores absolutos de los vectores son muy distintos.\n",
        "print(\"Distancia euclidiana:\", dist_euclidiana)\n",
        "\n",
        "# La similitud coseno es 1.0, lo que indica que los vectores est√°n perfectamente alineados (mismo patr√≥n de proporciones).\n",
        "print(\"Similitud coseno:\", sim_coseno)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wRKGc6RBhYbL",
      "metadata": {
        "id": "wRKGc6RBhYbL"
      },
      "source": [
        "### Ejercicio resuleto en Python con NumPy\n",
        "\n",
        "Imagina que tienes los resultados de dos estudiantes en tres asignaturas:\n",
        "\n",
        "* Alumno A: Matem√°ticas = 7, Lengua = 8, Ingl√©s = 6\n",
        "\n",
        "* Alumno B: Matem√°ticas = 5, Lengua = 9, Ingl√©s = 7\n",
        "\n",
        "Representa las notas de cada alumno como vectores en Python.\n",
        "\n",
        "Calcula:\n",
        "\n",
        "* La suma de los vectores (notas combinadas de ambos alumnos).\n",
        "\n",
        "* La diferencia de los vectores (comparaci√≥n alumno A ‚Äì alumno B).\n",
        "\n",
        "* La norma de cada vector (magnitud de las notas de cada alumno).\n",
        "\n",
        "* El producto escalar entre ambos vectores (medida de similitud en su rendimiento).\n",
        "\n",
        "* La distancia entre los vectores (qu√© tan diferentes son en sus resultados).\n",
        "\n",
        "* Normaliza los vectores de cada alumno para que la comparaci√≥n sea independiente de la escala.\n",
        "\n",
        "Interpreta los resultados:\n",
        "* ¬øqu√© alumno es m√°s regular?\n",
        "* ¬øqu√© tan parecidos son en sus notas?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "z5bmFsXShbbO",
      "metadata": {
        "id": "z5bmFsXShbbO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Representaci√≥n de los vectores (notas de alumnos)\n",
        "alumno_A = np.array([7, 8, 6])\n",
        "alumno_B = np.array([5, 9, 7])\n",
        "\n",
        "print(\"Alumno A:\", alumno_A)\n",
        "print(\"Alumno B:\", alumno_B)\n",
        "\n",
        "# 2. Operaciones con vectores\n",
        "suma = alumno_A + alumno_B\n",
        "resta = alumno_A - alumno_B\n",
        "norma_A = np.linalg.norm(alumno_A)\n",
        "norma_B = np.linalg.norm(alumno_B)\n",
        "producto_escalar = np.dot(alumno_A, alumno_B)\n",
        "distancia = np.linalg.norm(alumno_A - alumno_B)\n",
        "\n",
        "# 3. Normalizaci√≥n\n",
        "alumno_A_norm = alumno_A / norma_A\n",
        "alumno_B_norm = alumno_B / norma_B\n",
        "\n",
        "# 4. Resultados\n",
        "print(\"\\nSuma de notas:\", suma)\n",
        "print(\"Diferencia de notas (A - B):\", resta)\n",
        "\n",
        "# Comparamos las normas para comparar su rendimiento en las tres asignaturas\n",
        "print(\"Norma de A:\", norma_A)\n",
        "print(\"Norma de B:\", norma_B)\n",
        "# Cuanto m√°s alto el producto escalar, m√°s siguen un patr√≥n similar\n",
        "print(\"Producto escalar (similitud):\", producto_escalar)\n",
        "# Cuanto menor la distancia, rendimientros m√°s cercanos\n",
        "print(\"Distancia entre A y B:\", distancia)\n",
        "print(\"Alumno A normalizado:\", alumno_A_norm)\n",
        "print(\"Alumno B normalizado:\", alumno_B_norm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00606f85",
      "metadata": {
        "id": "00606f85"
      },
      "source": [
        "### Resumen r√°pido\n",
        "\n",
        "| Operaci√≥n              | Descripci√≥n                              | F√≥rmula                                          | Uso en Machine Learning                          |\n",
        "|------------------------|------------------------------------------|-------------------------------------------------|-------------------------------------------------|\n",
        "| **Suma**               | Suma elemento a elemento                 | $$ (v_1 + v_2)_i = v_{1,i} + v_{2,i} $$         | Combinar caracter√≠sticas o vectores             |\n",
        "| **Resta**              | Resta elemento a elemento                | $$ (v_1 - v_2)_i = v_{1,i} - v_{2,i} $$         | Calcular errores o diferencias (pred vs real)   |\n",
        "| **Multiplicaci√≥n escalar** | Escalar cada componente del vector     | $$ (c \\cdot v)_i = c \\cdot v_i $$               | Ajustar magnitud de datos o pesos               |\n",
        "| **Producto escalar**   | Multiplicaci√≥n elemento a elemento y suma | $$ \\sum_i v_{1,i} \\cdot v_{2,i} $$              | Medir similitud o correlaci√≥n                   |\n",
        "| **Similitud coseno**   | Medida de √°ngulo entre vectores          | $$ \\cos(\\theta)=\\tfrac{v_1\\cdot v_2}{||v_1||\\,||v_2||} $$ | Comparar embeddings en NLP e im√°genes |\n",
        "| **Producto vectorial** | Vector perpendicular en 3D               | $$ v_1 \\times v_2 $$                            | Geometr√≠a 3D, visi√≥n por ordenador avanzada     |\n",
        "| **Norma (longitud)**   | Tama√±o o magnitud del vector              | $$ \\sqrt{\\sum_i v_i^2} $$                       | Medir magnitud o energ√≠a de un dato             |\n",
        "| **Normalizaci√≥n (L2)** | Vector con longitud 1                     | $$ \\hat{v} = \\tfrac{v}{||v||} $$                | Comparar vectores en la misma escala            |\n",
        "| **Distancia eucl√≠dea** | Separaci√≥n entre dos vectores             | $$ d(v_1, v_2) = || v_1 - v_2 || $$             | KNN, clustering, detecci√≥n de anomal√≠as         |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xOdTftgIRgS_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOdTftgIRgS_",
        "outputId": "3ec918c1-5495-4b8e-bf22-4b098e861602"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector v1: [2 3 5]\n",
            "Vector v2: [1 4 2]\n",
            "\n",
            "1) Suma: [3 7 7]\n",
            "2) Resta: [ 1 -1  3]\n",
            "3) Multiplicaci√≥n escalar (2 * v1): [ 4  6 10]\n",
            "4) Producto escalar: 24\n",
            "5) Producto vectorial: [-14   1   5]\n",
            "6) Norma de v1: 6.164414002968976\n",
            "7) v1 normalizado: [0.32444284 0.48666426 0.81110711]\n",
            "8) Distancia entre v1 y v2: 3.3166247903554\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos dos vectores en R^3 (tres dimensiones)\n",
        "v1 = np.array([2, 3, 5])\n",
        "v2 = np.array([1, 4, 2])\n",
        "c = 2  # escalar\n",
        "\n",
        "print(\"Vector v1:\", v1)\n",
        "print(\"Vector v2:\", v2)\n",
        "\n",
        "# 1. Suma de vectores -> juntar datos\n",
        "# Ejemplo: sumar las notas de dos alumnos en cada asignatura\n",
        "suma = v1 + v2\n",
        "print(\"\\n1) Suma:\", suma)  # [3 7 7]\n",
        "\n",
        "# 2. Resta de vectores -> diferencia entre datos\n",
        "# Ejemplo: ver en qu√© asignaturas un alumno saca m√°s puntos que otro\n",
        "resta = v1 - v2\n",
        "print(\"2) Resta:\", resta)  # [1 -1 3]\n",
        "\n",
        "# 3. Multiplicaci√≥n por un escalar -> estirar o encoger un vector\n",
        "# Ejemplo: duplicar todas las caracter√≠sticas de un objeto\n",
        "mult_escalar = c * v1\n",
        "print(\"3) Multiplicaci√≥n escalar (2 * v1):\", mult_escalar)  # [4 6 10]\n",
        "\n",
        "# 4. Producto escalar (dot product) -> mide qu√© tan parecidos son dos vectores\n",
        "# Ejemplo: comparar si dos alumnos tienen notas similares\n",
        "producto_escalar = np.dot(v1, v2)\n",
        "print(\"4) Producto escalar:\", producto_escalar)  # 24\n",
        "\n",
        "# 5. Producto vectorial -> genera un vector perpendicular en 3D\n",
        "# Ejemplo: se usa en geometr√≠a, gr√°ficos y visi√≥n por ordenador\n",
        "producto_vectorial = np.cross(v1, v2)\n",
        "print(\"5) Producto vectorial:\", producto_vectorial)  # [-14  1  5]\n",
        "\n",
        "# 6. Norma (longitud del vector) -> mide el tama√±o del vector\n",
        "# Ejemplo: mide el ‚Äúnivel‚Äù o magnitud de un dato\n",
        "norma_v1 = np.linalg.norm(v1)\n",
        "print(\"6) Norma de v1:\", norma_v1)  # 6.164...\n",
        "\n",
        "# 7. Normalizaci√≥n -> vector con tama√±o 1\n",
        "# Ejemplo: permite comparar datos aunque est√©n en escalas distintas\n",
        "v1_normalizado = v1 / norma_v1\n",
        "print(\"7) v1 normalizado:\", v1_normalizado)\n",
        "\n",
        "# 8. Distancia entre dos vectores -> mide lo diferentes que son\n",
        "# Ejemplo: se usa en Machine Learning (KNN, clustering, detecci√≥n de anomal√≠as)\n",
        "distancia = np.linalg.norm(v1 - v2)\n",
        "print(\"8) Distancia entre v1 y v2:\", distancia)  # 3.162...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kCt0qEYsn7Mr",
      "metadata": {
        "id": "kCt0qEYsn7Mr"
      },
      "source": [
        "### üìù Actividad 1 ‚Äì Vectores\n",
        "\n",
        "1. Definir dos vectores a=(3,4) y b=(1,2): En la Inteligencia Artificial y el Machine Learning, los vectores se representan de forma est√°ndar como una colecci√≥n ordenada de n√∫meros. La manera m√°s eficiente y com√∫n de trabajar con ellos en Python es a trav√©s de NumPy arrays.\n",
        "\n",
        "2. Calcular: Las operaciones con vectores son fundamentales para comparar datos, medir similitudes y construir algoritmos en Machine Learning\n",
        "\n",
        "  * Su suma y resta: La suma y resta de vectores se realiza elemento a elemento. NumPy soporta estas operaciones directamente con los operadores + y -.\n",
        "  * Su producto escalar (dot product): El producto escalar de dos vectores se calcula multiplicando cada componente correspondiente y luego sumando los resultados. Este valor mide qu√© tan alineados est√°n los vectores [conversaci√≥n anterior]. En NumPy, se utiliza la funci√≥n np.dot() o el operador @.\n",
        "  * Sus normas (longitudes): La norma euclidiana (tambi√©n conocida como 2-norma) mide la longitud o magnitud del vector. Se calcula como la ra√≠z cuadrada de la suma de los cuadrados de sus componentes. En NumPy, se utiliza np.linalg.norm().\n",
        "  \n",
        "3. Representar ambos en el plano con Matplotlib: La visualizaci√≥n de vectores en el plano ayuda a comprender su interpretaci√≥n geom√©trica. Matplotlib es una herramienta com√∫n para esta tarea, utilizando funciones como plt.arrow() para dibujar las flechas de los vectores.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "187fcae1",
      "metadata": {
        "id": "187fcae1"
      },
      "source": [
        "# 2. Matrices\n",
        "\n",
        "En matem√°ticas, una **matriz** es una **tabla rectangular u ordenada de n√∫meros organizada en filas y columnas**. Es como una hoja de c√°lculo o una tabla de Excel, donde cada casilla contiene un n√∫mero. Las matrices son una de las estructuras de datos m√°s importantes que pueden representar sistemas de ecuaciones, gr√°ficos, mapeos entre espacios vectoriales y mucho m√°s. Son los bloques de construcci√≥n fundamentales del *Machine Learning*.\n",
        "\n",
        "Las matrices son una generalizaci√≥n bidimensional de los vectores y, a su vez, son un caso especial de los tensores de orden superior, que son las estructuras de datos fundamentales en el *deep learning*.\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo sencillo\n",
        "\n",
        "Una matriz con 2 filas y 3 columnas puede escribirse as√≠:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Tiene **2 filas** (horizontal).\n",
        "* Tiene **3 columnas** (vertical).\n",
        "* El **elemento** en la primera fila y segunda columna es $a_{1,2} = 2$.\n",
        "\n",
        "üëâ Notaci√≥n general: Una matriz $A$ de tama√±o $m \\times n$ tiene $m$ filas y $n$ columnas. Se denota como $A = (a_{i,j})_{i=1,j=1}^{n,m} \\in \\mathbb{R}^{n \\times m}$, donde $\\mathbb{R}^{n \\times m}$ es el conjunto de todas las matrices reales con $n$ filas y $m$ columnas.\n",
        "\n",
        "---\n",
        "\n",
        "### Diferencia con un vector\n",
        "\n",
        "* Un **vector** es una colecci√≥n ordenada de n√∫meros dispuestos en una fila o columna, y representa una cantidad que tiene tanto magnitud como direcci√≥n. En esencia, un vector puede considerarse un caso especial de matriz con **una sola fila o una sola columna**. Por ejemplo, un vector columna de 3 elementos: $$ \\vec{v} = \\begin{bmatrix} 3 \\ 7 \\ 5 \\end{bmatrix} $$\n",
        "\n",
        "* Una **matriz** puede tener muchas filas y muchas columnas. Los vectores son fundamentales para comprender muchos aspectos de la IA, especialmente al tratar con conjuntos de datos, transformaciones y espacios multidimensionales. En contraste, las matrices son esenciales para la representaci√≥n y manipulaci√≥n eficiente de datos, especialmente con conjuntos de datos de alta dimensi√≥n\n",
        "\n",
        "---\n",
        "\n",
        "### Intuici√≥n\n",
        "\n",
        "Piensa en una matriz como en un **almac√©n de informaci√≥n estructurada**:\n",
        "\n",
        "* Cada **fila** = un ejemplo (un alumno, una flor, una imagen).\n",
        "* Cada **columna** = una caracter√≠stica (nota, tama√±o, color).\n",
        "\n",
        "üëâ  Esta visi√≥n es la que usaremos en **Machine Learning**, donde un dataset entero se guarda en forma de matriz. En el machine learning, los conjuntos de datos a menudo se almacenan en matrices, con cada fila representando un punto de datos individual y cada columna representando una caracter√≠stica espec√≠fica del dato. Los modelos de IA, especialmente las redes neuronales profundas, dependen en gran medida de las operaciones matriciales para realizar c√°lculos en grandes conjuntos de datos. Las matrices son cruciales para el c√≥mo muchos modelos de IA aprenden y hacen predicciones.\n",
        "\n",
        "---\n",
        "\n",
        "### Ejemplo cotidiano\n",
        "\n",
        "Supongamos que guardamos las notas de 3 alumnos en 3 asignaturas:\n",
        "\n",
        "$$\n",
        "\\text{Notas} =\n",
        "\\begin{bmatrix}\n",
        "6 & 7 & 8 \\\\\n",
        "5 & 9 & 7 \\\\\n",
        "8 & 6 & 9\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Fila 1 ‚Üí Alumno A con notas (6,7,8).\n",
        "* Fila 2 ‚Üí Alumno B con notas (5,9,7).\n",
        "* Fila 3 ‚Üí Alumno C con notas (8,6,9).\n",
        "* Columnas ‚Üí Asignaturas (Matem√°ticas, Lengua, Ingl√©s).\n",
        "\n",
        "Este ejemplo ilustra c√≥mo una matriz puede representar un sistema de puntos de datos, donde las filas corresponden a diferentes muestras (alumnos) y las columnas a diferentes caracter√≠sticas (asignaturas/notas). Esta representaci√≥n es fundamental en el Machine Learning, donde, por ejemplo, los datos de entrada de un dataset para regresi√≥n lineal pueden representarse como una matriz, y las etiquetas objetivo correspondientes como otro vector o matriz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kfQuZOy7S6-P",
      "metadata": {
        "id": "kfQuZOy7S6-P"
      },
      "source": [
        "\n",
        "## 2.1 Caracter√≠sticas de una matriz\n",
        "\n",
        "Ahora que ya sabemos qu√© es una matriz y su papel fundamental en la inteligencia artificial (IA) como el lenguaje de los datos, veamos sus **caracter√≠sticas principales**. Las matrices son estructuras matem√°ticas esenciales que permiten la representaci√≥n y manipulaci√≥n eficiente de grandes conjuntos de datos\n",
        "\n",
        "---\n",
        "\n",
        "### Tama√±o o forma de una matriz\n",
        "\n",
        "El **tama√±o o la forma** de una matriz es una de sus caracter√≠sticas m√°s importantes y se define por el n√∫mero de **filas** (disposici√≥n horizontal) y **columnas** (disposici√≥n vertical) que posee. Una matriz es, en esencia, una tabla de n√∫meros.\n",
        "\n",
        "üëâ Si una matriz tiene $m$ filas y $n$ columnas, decimos que es de **tama√±o $m \\times n$ (‚Äúm por n‚Äù)**. El conjunto de todas las matrices reales con $m$ filas y $n$ columnas se denota como $\\mathbb{R}^{m \\times n}$.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "* Tiene **2 filas** (horizontales).\n",
        "* Tiene **3 columnas** (verticales).\n",
        "* Es una matriz de **2 √ó 3**.\n",
        "\n",
        "üìå **Idea clave**: Si una matriz tiene $m$ filas y $n$ columnas, decimos que es de tama√±o $m \\times n$ (‚Äúm por n‚Äù). El conjunto de todas las matrices reales con $m$ filas y $n$ columnas se denota como $\\mathbb{R}^{m \\times n}$.\n",
        "\n",
        "\n",
        "**Importancia del tama√±o en las operaciones y la representaci√≥n de datos en IA**:\n",
        "\n",
        "* **Representaci√≥n de datos**: En machine learning, los conjuntos de datos se suelen almacenar en matrices, donde cada fila puede representar un punto de datos individual y cada columna una caracter√≠stica espec√≠fica de esos datos. Por ejemplo, una imagen de 256x256 p√≠xeles puede representarse como una matriz de ese tama√±o (para escala de grises) o como un tensor de 256x256x3 (para im√°genes RGB), donde las dimensiones definen la estructura de la imagen. En Procesamiento de Lenguaje Natural (PLN), palabras o frases se representan como vectores de alta dimensi√≥n, que luego se procesan como matrices.\n",
        "\n",
        "* **Suma y resta de matrices**: Para poder sumar o restar dos matrices, estas deben tener **exactamente las mismas dimensiones** (el mismo n√∫mero de filas y columnas).\n",
        "\n",
        "* **Multiplicaci√≥n de matrices**: Esta es una operaci√≥n fundamental en IA. Para multiplicar dos matrices $A$ y $B$, **el n√∫mero de columnas de la primera matriz ($A$) debe ser igual al n√∫mero de filas de la segunda matriz ($B$)**. Si $A$ es de tama√±o $n \\times m$ y $B$ es de tama√±o $m \\times l$, su producto $AB$ resultar√° en una matriz de tama√±o $n \\times l$. Esta compatibilidad dimensional es vital en algoritmos como la regresi√≥n lineal y en las capas de las redes neuronales para propagar la informaci√≥n.\n",
        "\n",
        "* **Transposici√≥n de una matriz**: La transposici√≥n de una matriz implica intercambiar sus filas por sus columnas. Si una matriz original tiene un tama√±o de $m \\times n$, su transpuesta tendr√° un tama√±o de $n \\times m$.\n",
        "* **Inversa de una matriz**: No todas las matrices tienen inversa. Solo las matrices cuadradas (aquellas con el mismo n√∫mero de filas y columnas, es decir, de tama√±o $n \\times n$) y no singulares (con determinante distinto de cero) pueden tener una inversa.\n",
        "\n",
        "* **Redimensionamiento (Reshaping)**: Es posible cambiar la forma de una matriz sin alterar el n√∫mero total de sus elementos, lo que implica reorganizar c√≥mo se distribuyen las filas y columnas. Por ejemplo, una matriz de $3 \\times 4$ puede ser redimensionada a $6 \\times 2$ o $4 \\times 3$, entre otras, manteniendo los 12 elementos.\n",
        "\n",
        "* **Errores de forma (Shape Mismatches)**: En la pr√°ctica de machine learning, los errores debidos a la falta de coincidencia en las formas o dimensiones de las matrices son muy comunes y pueden causar problemas significativos en el desarrollo de modelos.\n",
        "\n",
        "Comprender el tama√±o y la forma de las matrices es un pilar fundamental para trabajar eficazmente con los algoritmos y modelos de IA\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "roTfgV6I428p",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roTfgV6I428p",
        "outputId": "68fc4e92-7edd-49f7-d3d0-755fbd80bde6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz A:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n",
            "Forma: (2, 3)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "\n",
        "print(\"Matriz A:\\n\", A)\n",
        "print(\"Forma:\", A.shape)  # (2, 3) ‚Üí 2 filas, 3 columnas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eqrw2uez43aN",
      "metadata": {
        "id": "Eqrw2uez43aN"
      },
      "source": [
        "## 2.2. Elementos de una matriz\n",
        "\n",
        "Cada n√∫mero dentro de la matriz se llama **elemento**.\n",
        "Se identifica por la **fila** y la **columna** en la que se encuentra.\n",
        "\n",
        "Ejemplo: en la matriz anterior, el n√∫mero que est√° en la **fila 2, columna 3** es:\n",
        "\n",
        "$$\n",
        "a_{2,3} = 6\n",
        "$$\n",
        "\n",
        "üëâ Se suele escribir con la letra de la matriz en min√∫scula y los sub√≠ndices de fila y columna.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YtCaqYrn5Bt9",
      "metadata": {
        "id": "YtCaqYrn5Bt9"
      },
      "outputs": [],
      "source": [
        "print(\"Elemento fila 2, columna 3:\", A[1, 2])  # √≠ndice empieza en 0 ‚Üí a_{2,3} = 6\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2dMCupk35Est",
      "metadata": {
        "id": "2dMCupk35Est"
      },
      "source": [
        "\n",
        "### 2.3 Tipos de matrices\n",
        "\n",
        "En el estudio de las matem√°ticas aplicadas a la Inteligencia Artificial, las matrices son estructuras fundamentales para representar y procesar datos. Dentro de este contexto, existen algunas matrices especiales que, debido a sus propiedades √∫nicas, son de particular importancia para la optimizaci√≥n de c√°lculos, la resoluci√≥n de sistemas de ecuaciones lineales y el dise√±o de modelos eficientes. Conocer sus caracter√≠sticas nos permite comprender mejor c√≥mo funcionan los algoritmos y modelos de IA.\n",
        "\n",
        "\n",
        "* **Matriz cuadrada**:  Una matriz es cuadrada si tiene el mismo n√∫mero de filas ($n$) y columnas ($n$) [ref: user provided definition, 84]. Se denota su tama√±o como $n \\times n$.\n",
        "\n",
        "  Ejemplo: Una matriz de $2 \\times 2$ o $3 \\times 3$\n",
        "\n",
        "  * **Relevancia en IA**: Las matrices cuadradas son esenciales en muchos algoritmos, ya que solo ellas pueden tener una **inversa** (siempre que sean no singulares, es decir, con determinante distinto de cero). Adem√°s, los conceptos de **autovalores y autovectores**, fundamentales para entender el comportamiento de transformaciones lineales y la reducci√≥n de dimensionalidad (como en PCA), est√°n definidos para matrices cuadradas. La **descomposici√≥n espectral** y la **descomposici√≥n de autovalores (EVD)** son t√©cnicas que se aplican a matrices cuadradas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sW8bvrcGicAu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sW8bvrcGicAu",
        "outputId": "43d7c141-19c5-4ddf-f95b-8c15075da0cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz Cuadrada\n",
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "\n",
        "print(\"Matriz Cuadrada\")\n",
        "print(A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zBV52y1ricLV",
      "metadata": {
        "id": "zBV52y1ricLV"
      },
      "source": [
        "\n",
        "\n",
        "* **Matriz identidad**: La matriz identidad, denotada por $I$, es una matriz cuadrada que posee unos en la diagonal principal (desde la esquina superior izquierda hasta la inferior derecha) y ceros en todas las dem√°s posiciones.\n",
        "\n",
        "  $$\n",
        "  I =\n",
        "  \\begin{bmatrix}\n",
        "  1 & 0 & 0 \\\\\n",
        "  0 & 1 & 0 \\\\\n",
        "  0 & 0 & 1\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  *   **Propiedad**: Se comporta como el n√∫mero 1 en la multiplicaci√≥n escalar o matricial; es decir, multiplicar cualquier matriz por la matriz identidad deja la matriz original sin cambios ($A \\times I = A$ y $I \\times A = A$)  Esto la convierte en el \"elemento neutro\" de la multiplicaci√≥n matricial.\n",
        "\n",
        "  * **Relevancia en IA**:\n",
        "      *  **Inicializaci√≥n**: Se utiliza frecuentemente para inicializar ciertos algoritmos, como las matrices de pesos iniciales en modelos de aprendizaje profundo, garantizando que los pesos no est√©n sesgados al principio.\n",
        "\n",
        "      *  **Sistemas de ecuaciones lineales**: Es clave para resolver sistemas de ecuaciones lineales, particularmente en la eliminaci√≥n gaussiana y la inversi√≥n de matrices, ya que la inversa de una matriz $A$ es aquella que, al multiplicarse por $A$, da como resultado la matriz identidad ($A \\times A^{-1} = I$).\n",
        "\n",
        "      *  **Matrices ortogonales**: Define la condici√≥n para que una matriz sea ortogonal: $Q^T \\times Q = I$, donde $Q^T$ es la transpuesta de $Q$.\n",
        "\n",
        "      *  **Autovalores**: Juega un papel en el c√°lculo de autovalores, donde se busca $\\lambda$ tal que $\\det(A - \\lambda I) = 0$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qel-no8rijG5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qel-no8rijG5",
        "outputId": "658412d1-3058-4ead-a1e8-813dc7e18c46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "# Matriz identidad de 3x3\n",
        "I = np.eye(3)\n",
        "print(\"Identidad:\\n\", I)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RmaU4YZcijTl",
      "metadata": {
        "id": "RmaU4YZcijTl"
      },
      "source": [
        "* **Matriz nula**: Una matriz nula es aquella en la que todos sus elementos son 0.\n",
        "\n",
        "  $$\n",
        "  0 =\n",
        "  \\begin{bmatrix}\n",
        "  0 & 0 \\\\\n",
        "  0 & 0\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  * **Relevancia en IA**: El concepto de elementos cero es fundamental. Por ejemplo, en el contexto de los espacios vectoriales, existe un \"vector nulo\" (todos sus elementos son cero) que act√∫a como identidad aditiva. Una transformaci√≥n lineal que mapea todos los vectores al vector cero no puede tener una inversa. Una matriz con una columna o fila de ceros tiene un determinante de cero, lo que implica que no es invertible. En la pr√°ctica, se utilizan funciones como ``np.zeros`` en NumPy para crear matrices con todos sus elementos inicializados a cero.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jj_BZitFin-t",
      "metadata": {
        "id": "jj_BZitFin-t"
      },
      "outputs": [],
      "source": [
        "# Matriz nula de 2x2\n",
        "Z = np.zeros((2, 2))\n",
        "print(\"Nula:\\n\", Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oC6vjZ3zioKE",
      "metadata": {
        "id": "oC6vjZ3zioKE"
      },
      "source": [
        "* **Matriz diagonal**: Una matriz diagonal es una matriz cuadrada que tiene n√∫meros √∫nicamente en su diagonal principal, y ceros en todos los elementos fuera de ella.\n",
        "\n",
        "  $$\n",
        "  D =\n",
        "  \\begin{bmatrix}\n",
        "  3 & 0 & 0 \\\\\n",
        "  0 & 5 & 0 \\\\\n",
        "  0 & 0 & 7\n",
        "  \\end{bmatrix}\n",
        "  $$\n",
        "\n",
        "  * **Relevancia en IA**:\n",
        "      *  **Eficiencia computacional**: Las matrices diagonales son altamente valoradas en la pr√°ctica de la IA debido a su **eficiencia computacional**. Multiplicar por una matriz diagonal es significativamente m√°s r√°pido, requiriendo $O(n)$ operaciones en lugar de $O(n^2)$. El determinante de una matriz triangular (y por ende, de una diagonal) se calcula simplemente multiplicando sus elementos de la diagonal.\n",
        "      *  **Simplificaci√≥n de transformaciones lineales (Diagonalizaci√≥n)**: El objetivo de muchos algoritmos en IA es diagonalizar matrices. Esto implica encontrar una base (compuesta por autovectores) en la que la matriz de una transformaci√≥n lineal se convierte en diagonal. Esta diagonalizaci√≥n simplifica enormemente el an√°lisis y la aplicaci√≥n de la transformaci√≥n, revelando la \"estructura interna\" de la misma.\n",
        "      *  **Descomposiciones matriciales:** Son componentes clave en descomposiciones importantes como la **descomposici√≥n espectral** (donde la matriz diagonal contiene los autovalores) y la **descomposici√≥n en valores singulares (SVD)** (donde una matriz diagonal contiene los valores singulares, que representan los factores de estiramiento de la transformaci√≥n).\n",
        "\n",
        "  Estas matrices especiales no solo son conceptos te√≥ricos, sino herramientas poderosas que subyacen a la eficacia y eficiencia de muchos de los algoritmos y modelos complejos utilizados en el campo de la Inteligencia Artificial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2MXdj-Sc5WA4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MXdj-Sc5WA4",
        "outputId": "08485a88-b139-4619-e9a8-eb5eb772600a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "Nula:\n",
            " [[0. 0.]\n",
            " [0. 0.]]\n",
            "Diagonal:\n",
            " [[3 0 0]\n",
            " [0 5 0]\n",
            " [0 0 7]]\n"
          ]
        }
      ],
      "source": [
        "# Matriz diagonal con 3, 5, 7 en la diagonal\n",
        "D = np.diag([3, 5, 7])\n",
        "print(\"Diagonal:\\n\", D)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Zgs1kDiuGxGe",
      "metadata": {
        "id": "Zgs1kDiuGxGe"
      },
      "source": [
        "### 2.4 Operaciones con matrices\n",
        "\n",
        "En √°lgebra lineal, las **operaciones con matrices** son la piedra angular para la manipulaci√≥n y el procesamiento de datos. En el √°mbito del Machine Learning (ML) y la Inteligencia Artificial (IA), estas operaciones son realizadas con **frecuencia** y de manera intensiva, constituyendo el coraz√≥n de los c√°lculos y algoritmos. Herramientas como **NumPy** en Python facilitan enormemente su implementaci√≥n, permitiendo realizar estas operaciones de forma eficiente en grandes conjuntos de datos.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2.4.1 Suma y resta de matrices\n",
        "\n",
        "La **suma y resta de matrices** son operaciones fundamentales que permiten combinar o comparar matrices\n",
        "\n",
        "üëâ  La regla principal es que solo se pueden sumar o restar matrices si tienen **exactamente el mismo tama√±o** (es decir, el mismo n√∫mero de filas y columnas). La operaci√≥n se realiza **elemento a elemento** (element-wise), lo que significa que los elementos correspondientes de cada matriz se suman o se restan\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "+\n",
        "\\begin{bmatrix}\n",
        "5 & 6 \\\\\n",
        "7 & 8\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "6 & 8 \\\\\n",
        "10 & 12\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "**Relevancia en IA/ML**: Estas operaciones son √∫tiles en muchos algoritmos de machine learning, particularmente en la **optimizaci√≥n**, donde los **pesos (weights)** de un modelo se ajustan al a√±adir o restar valores de gradiente durante el proceso de entrenamiento. Por ejemplo, en el m√©todo del **gradiente descendente**, los par√°metros del modelo se actualizan en cada iteraci√≥n sumando o restando un valor proporcional al gradiente de la funci√≥n de p√©rdida. Adem√°s, la **adici√≥n de matrices es conmutativa** ($A + B = B + A$) y **asociativa** ($A + (B + C) = (A + B) + C$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SngTC8afGztu",
      "metadata": {
        "id": "SngTC8afGztu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "A = np.array([[1, 2],\n",
        "              [3, 4]])\n",
        "B = np.array([[5, 6],\n",
        "              [7, 8]])\n",
        "print(\"Suma:\\n\", A + B)\n",
        "print(\"Resta:\\n\", A - B)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T6sMFQZOG4HO",
      "metadata": {
        "id": "T6sMFQZOG4HO"
      },
      "source": [
        "#### 2.4.2 Multiplicaci√≥n por un escalar\n",
        "\n",
        "üëâ Cada elemento de la matriz se multiplica por un n√∫mero real.\n",
        "\n",
        "$$\n",
        "2 \\cdot\n",
        "\\begin{bmatrix}\n",
        "1 & 2 \\\\\n",
        "3 & 4\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "2 & 4 \\\\\n",
        "6 & 8\n",
        "\\end{bmatrix}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ucNoylHzHAYt",
      "metadata": {
        "id": "ucNoylHzHAYt"
      },
      "outputs": [],
      "source": [
        "print(\"A * 2:\\n\", 2 * A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PkMt4t2yHDU-",
      "metadata": {
        "id": "PkMt4t2yHDU-"
      },
      "source": [
        "#### 2.4.3 Multiplicaci√≥n de matrices\n",
        "\n",
        "La **multiplicaci√≥n de matrices** es una operaci√≥n central y una de las m√°s cruciales en IA, ya que permite la **transformaci√≥n de datos**. A diferencia de la suma y resta, la multiplicaci√≥n de matrices no se realiza elemento a elemento.\n",
        "\n",
        "\n",
        "üëâ La regla fundamental en √°lgebra lineal es que para multiplicar dos matrices $A$ y $B$ ($C = A \\cdot B$), **el n√∫mero de columnas de la primera matriz ($A$) debe ser igual al n√∫mero de filas de la segunda matriz ($B$)**. Si $A$ tiene dimensiones $n \\times m$ y $B$ tiene dimensiones $m \\times l$, la matriz resultante $C$ tendr√° dimensiones $n \\times l$\n",
        "\n",
        "La multiplicaci√≥n combina las filas de la primera matriz con las columnas de la segunda a trav√©s de un proceso de producto escalar (dot product). El elemento en la $i$-√©sima fila y $j$-√©sima columna de la matriz resultante $C$ se calcula como el producto escalar de la $i$-√©sima fila de $A$ y la $j$-√©sima columna de $B$.\n",
        "\n",
        "F√≥rmula:  \n",
        "$$\n",
        "C = A \\cdot B \\quad \\Rightarrow \\quad c_{ij} = \\sum_{k=1}^{m} a_{ik} \\cdot b_{kj}\n",
        "$$\n",
        "\n",
        "Ejemplo:  \n",
        "Si $A$ es una matriz de $2 \\times 3$ y $B$ es una matriz de $3 \\times 2$, el resultado $C$ ser√° una matriz de $2 \\times 2$:  \n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\quad\n",
        "B =\n",
        "\\begin{bmatrix}\n",
        "7 & 8 \\\\\n",
        "9 & 10 \\\\\n",
        "11 & 12\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "El producto $C = A \\times B$ ser√≠a:  \n",
        "\n",
        "$$\n",
        "C =\n",
        "\\begin{bmatrix}\n",
        "(1\\cdot7 + 2\\cdot9 + 3\\cdot11) & (1\\cdot8 + 2\\cdot10 + 3\\cdot12) \\\\\n",
        "(4\\cdot7 + 5\\cdot9 + 6\\cdot11) & (4\\cdot8 + 5\\cdot10 + 6\\cdot12)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "(7+18+33) & (8+20+36) \\\\\n",
        "(28+45+66) & (32+50+72)\n",
        "\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}\n",
        "58 & 64 \\\\\n",
        "139 & 154\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "üìå **Relevancia en IA/ML**: La multiplicaci√≥n de matrices es una operaci√≥n fundamental en la mayor√≠a de los algoritmos de IA.\n",
        "\n",
        "  * **Redes neuronales**: En las redes neuronales profundas, la multiplicaci√≥n de matrices se utiliza para **computar las salidas de cada capa** multiplicando los datos de entrada por las** matrices de peso**s aprendidos. Este proceso es crucial para propagar la informaci√≥n a trav√©s de la red.\n",
        "  * **Regresi√≥n lineal**: Es un componente clave en la **regresi√≥n lineal**, donde los vectores de caracter√≠sticas de entrada se multiplican por una matriz de pesos para generar predicciones.\n",
        "  * **Optimizaci√≥n**: Se usa en muchos **algoritmos de optimizaci√≥n**.\n",
        "  * Eficiencia computacional: Las bibliotecas como NumPy est√°n altamente optimizadas para realizar multiplicaciones de matrices de manera muy r√°pida, a menudo aprovechando hardware especializado (como GPUs) y bibliotecas de bajo nivel (como BLAS y LAPACK) para operaciones paralelas.\n",
        "  * **Composici√≥n de transformaciones**: Desde la perspectiva de las transformaciones lineales, la multiplicaci√≥n de matrices representa la **composici√≥n de dos transformaciones lineales**.\n",
        "  * **Notaci√≥n en Python**: NumPy permite usar el operador ``@`` para la multiplicaci√≥n de matrices, lo que simplifica el c√≥digo.\n",
        "  * Propiedades: Es importante notar que, a diferencia de la suma, **la multiplicaci√≥n de matrices generalmente no es conmutativa** ($A \\times B \\neq B \\times A$). Sin embargo, s√≠ es asociativa ($A \\times (B \\times C) = (A \\times B) \\times C$) y distributiva sobre la suma.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GXdh8UCiHGmZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXdh8UCiHGmZ",
        "outputId": "c2e6a6e0-400f-4630-85f1-1ed8bf465b0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Multiplicaci√≥n C @ D:\n",
            " [[ 58  64]\n",
            " [139 154]]\n"
          ]
        }
      ],
      "source": [
        "C = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])   # (2x3)\n",
        "D = np.array([[7, 8],\n",
        "              [9, 10],\n",
        "              [11, 12]])    # (3x2)\n",
        "\n",
        "print(\"Multiplicaci√≥n C @ D:\\n\", C @ D)  # producto matricial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xS-nNmaA5cQM",
      "metadata": {
        "id": "xS-nNmaA5cQM"
      },
      "source": [
        "---\n",
        "\n",
        "#### 2.4.4 Transposici√≥n\n",
        "\n",
        "La transpuesta de una matriz, denotada por $A^T$ (o $A'$), es una nueva matriz que se obtiene al intercambiar sus filas por sus columnas [ref: user provided text, 100, 316]. Si una matriz original tiene $m$ filas y $n$ columnas (tama√±o $m \\times n$), su transpuesta tendr√° $n$ filas y $m$ columnas (tama√±o $n \\times m$)\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 3 \\\\\n",
        "4 & 5 & 6\n",
        "\\end{bmatrix}\n",
        "\\quad \\longrightarrow \\quad\n",
        "A^T =\n",
        "\\begin{bmatrix}\n",
        "1 & 4 \\\\\n",
        "2 & 5 \\\\\n",
        "3 & 6\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "üëâ Es como ‚Äúvoltear‚Äù la matriz sobre su diagonal principal\n",
        "\n",
        "üìå **Relevancia en IA/ML**:  La transposici√≥n es una operaci√≥n fundamental y cr√≠tica para que las dimensiones coincidan en los c√°lculos de Machine Learning  Se utiliza en diversos contextos:\n",
        "  * **Productos escalares (similitud)**: Se emplea en operaciones que involucran productos escalares, por ejemplo, para calcular la **similitud entre vectores** (como la similitud del coseno).\n",
        "\n",
        "  * **C√°lculo de gradientes**: Es esencial en el **c√°lculo de gradientes** en algoritmos de optimizaci√≥n, como el de **retropropagaci√≥n (backpropagation)** en redes neuronales. La transpuesta juega un papel clave en la regla de la cadena para propagar los errores hacia atr√°s a trav√©s de las capas de la red.\n",
        "\n",
        "  * **Ecuaciones de modelos lineales**: Aparece en la formulaci√≥n y resoluci√≥n de ecuaciones de modelos lineales, por ejemplo, en la soluci√≥n de m√≠nimos cuadrados.\n",
        "\n",
        "  * **Redes neuronales**: Se usa en diversas **operaciones dentro de las redes neuronales**.\n",
        "\n",
        "  * **Matrices ortogonales**: Una matriz $Q$ es ortogonal si su transpuesta es igual a su inversa ($Q^T = Q^{-1}$), lo que significa que $Q^T \\times Q = I$ (la matriz identidad). Las matrices ortogonales son importantes porque preservan la longitud y los √°ngulos de los vectores, siendo √∫tiles en transformaciones geom√©tricas y en t√©cnicas como el **An√°lisis de Componentes Principales (PCA)**.\n",
        "\n",
        "  * **Propiedades**: La transposici√≥n de una suma de matrices es la suma de sus transpuestas ($(A+B)^T = A^T + B^T$) y la transpuesta de un producto es el producto de las transpuestas en orden inverso ($(AB)^T = B^T A^T$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t841XV615cew",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t841XV615cew",
        "outputId": "2288f837-d3a0-4721-9330-421276bbadc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de datos_alumnos: (3, 2)\n",
            "Forma de pesos: (1, 2)\n",
            "Error: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 1 is different from 2)\n",
            "Forma de pesos.T: (2, 1)\n",
            "Predicciones (3 alumnos):\n",
            " [[5. ]\n",
            " [5.2]\n",
            " [7.4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset: 3 alumnos (filas), con 2 caracter√≠sticas cada uno (columnas)\n",
        "# Caracter√≠sticas: [horas de estudio, nota en pr√°cticas]\n",
        "datos_alumnos = np.array([[2, 7],   # Alumno 1\n",
        "                          [4, 6],   # Alumno 2\n",
        "                          [5, 9]])  # Alumno 3\n",
        "print(\"Forma de datos_alumnos:\", datos_alumnos.shape)  # (3, 2)\n",
        "\n",
        "# Pesos del modelo: importancia que damos a cada caracter√≠stica\n",
        "# [peso_horas, peso_practicas]\n",
        "pesos = np.array([[0.4, 0.6]])  # (1, 2) ‚Üí vector fila\n",
        "print(\"Forma de pesos:\", pesos.shape)\n",
        "\n",
        "# -----------------------------\n",
        "# Intento de multiplicaci√≥n\n",
        "# -----------------------------\n",
        "# Regla: columnas de la primera (2) = filas de la segunda (¬ø?)\n",
        "# Aqu√≠ tenemos (3x2) @ (1x2) ‚Üí ERROR, porque 2 ‚â† 1\n",
        "try:\n",
        "    print(datos_alumnos @ pesos)\n",
        "except ValueError as e:\n",
        "    print(\"Error:\", e)\n",
        "\n",
        "# -----------------------------\n",
        "# Soluci√≥n: usar la transpuesta\n",
        "# -----------------------------\n",
        "# pesos.T convierte (1,2) ‚Üí (2,1)\n",
        "print(\"Forma de pesos.T:\", pesos.T.shape)\n",
        "\n",
        "# Ahora s√≠: (3x2) @ (2x1) ‚Üí (3x1)\n",
        "predicciones = datos_alumnos @ pesos.T\n",
        "print(\"Predicciones (3 alumnos):\\n\", predicciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KHNq6BnSHQpR",
      "metadata": {
        "id": "KHNq6BnSHQpR"
      },
      "source": [
        "\n",
        "#### 2.4.5 Inversa de una matriz\n",
        "\n",
        "La inversa de una matriz $A$, denotada como $A^{-1}$, es otra matriz que, al multiplicarse por $A$, produce la matriz identidad ($I$). Es decir, la inversa \"deshace\" el efecto de la matriz original.\n",
        "La inversa $A^{-1}$ cumple la siguiente propiedad fundamental:\n",
        "\n",
        "$$\n",
        "A \\cdot A^{-1} = I\n",
        "$$\n",
        "\n",
        "Solo existe para matrices cuadradas (aquellas con el mismo n√∫mero de filas y columnas) y que sean no singulares (es decir, su determinante es distinto de 0). Las matrices con un determinante de cero se denominan matrices singulares y no tienen inversa. Si una matriz no es cuadrada, no es invertible en el sentido cl√°sico.\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}2&1\\\\5&3\\end{bmatrix}\n",
        "\\begin{bmatrix}3&-1\\\\-5&2\\end{bmatrix}\n",
        "=\n",
        "\\begin{bmatrix}1&0\\\\0&1\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "üìå **Relevancia en IA/ML**: La inversi√≥n de matrices es una operaci√≥n crucial en muchas √°reas de la IA y el Machine Learning:\n",
        "\n",
        "* **Resoluci√≥n de sistemas de ecuaciones lineales**: La inversa de una matriz es indispensable para resolver sistemas de ecuaciones lineales, que son frecuentes en ML al calcular las **actualizaciones de par√°metros** en algoritmos o en problemas de optimizaci√≥n. Por ejemplo, en la **regresi√≥n linea**l, la soluci√≥n a los m√≠nimos cuadrados a menudo implica encontrar la inversa de una matriz.\n",
        "* **Optimizaci√≥n**: En algoritmos de optimizaci√≥n como el **gradiente descendente**, la inversi√≥n de matrices se utiliza para ajustar los pesos y minimizar la funci√≥n de error en los modelos de aprendizaje autom√°tico.\n",
        "* **Transformaciones invertibles**: En el contexto de las transformaciones lineales, una transformaci√≥n es invertible si existe otra transformaci√≥n que la \"deshace\". Esto es cr√≠tico en algoritmos como los **autoencoders y modelos generativos**, donde los datos se codifican y luego se decodifican a su forma original.\n",
        "* **Matrices ortogonales**: La inversa de una matriz ortogonal es igual a su transpuesta ($Q^{-1} = Q^T$), lo que es fundamental en transformaciones que preservan la geometr√≠a de los datos, como rotaciones y reducciones de dimensionalidad en PCA.\n",
        "* **Algoritmos computacionales**: M√©todos como la **eliminaci√≥n gaussiana** y la **descomposici√≥n LU** proporcionan formas computacionales para obtener la inversa de una matriz, siendo pasos clave en la implementaci√≥n de algoritmos esenciales.\n",
        "* **Propiedades**: La transpuesta de una inversa es la inversa de la transpuesta ($(A^{-1})^T = (A^T)^{-1}$), y el determinante de la inversa es el rec√≠proco del determinante original ($\\det(A^{-1}) = (\\det A)^{-1}$).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "UPCJybtPHRS-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPCJybtPHRS-",
        "outputId": "b94daaaf-7296-4a96-d3ab-b0cd3283d864"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sympy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msympy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Definimos la matriz en SymPy\u001b[39;00m\n\u001b[1;32m      4\u001b[0m E \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mMatrix([[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      5\u001b[0m                [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m]])\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sympy'"
          ]
        }
      ],
      "source": [
        "import sympy as sp\n",
        "\n",
        "# Definimos la matriz en SymPy\n",
        "E = sp.Matrix([[2, 1],\n",
        "               [5, 3]])\n",
        "\n",
        "E_inv = E.inv()  # inversa exacta\n",
        "print(\"Inversa simb√≥lica:\\n\", E_inv)\n",
        "\n",
        "# Comprobaci√≥n\n",
        "print(\"Comprobaci√≥n E * E_inv:\\n\", E * E_inv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mAndXJQl5e8w",
      "metadata": {
        "id": "mAndXJQl5e8w"
      },
      "source": [
        "\n",
        "#### 2.4.6 Determinante\n",
        "\n",
        "El **determinante** es un **n√∫mero escalar √∫nico asociado a una matriz cuadrada**. En √°lgebra lineal, su valor nos ofrece informaci√≥n crucial sobre las propiedades de la matriz y la transformaci√≥n lineal que representa. Geom√©tricamente, el determinante describe cu√°nto distorsiona el volumen una transformaci√≥n lineal y c√≥mo cambia la orientaci√≥n del espacio.\n",
        "\n",
        "En **√°lgebra lineal**, **el determinante nos dice si una matriz tiene inversa** (y si se puede \"deshacer\" una transformaci√≥n) o no\n",
        "\n",
        "**En Machine Learning, esto se interpreta de manera muy pr√°ctica**:\n",
        "\n",
        "  * Si **determinante ‚â† 0**:\n",
        "    * La matriz contiene **informaci√≥n independiente** .\n",
        "    * Las columnas de la matriz son **linealmente independientes**. Esto significa que **cada caracter√≠stica (columna) aporta informaci√≥n distinta y no redundante** al conjunto de datos o al modelo .\n",
        "    * La transformaci√≥n lineal que representa la matriz no \"colapsa\" el espacio, es decir, preserva la dimensionalidad y no reduce el volumen a cero.\n",
        "  * Si d**eterminante = 0** :\n",
        "    * Indica que hay **columnas o filas redundantes**. Esto significa que una columna (o fila) es una copia o una combinaci√≥n lineal de otras columnas (o filas).\n",
        "    * En el contexto de los datos, esto significa que **los datos no aportan informaci√≥n nueva y el modelo no puede aprender correctamente** si necesita invertir la matriz. La presencia de columnas linealmente dependientes puede causar problemas de **multicolinealidad**, afectando la estabilidad y la interpretabilidad de los modelos.\n",
        "    * La transformaci√≥n lineal asociada a la matriz colapsa el espacio, reduciendo su dimensionalidad a cero o a una dimensi√≥n menor. Por ejemplo, en un espacio 2D, un determinante de 0 significa que los vectores columna son colineales (est√°n sobre la misma l√≠nea), \"aplastando\" el √°rea a cero.\n",
        "    * **Los modelos que necesitan invertir matrices** (por ejemplo, la regresi√≥n lineal utilizando la f√≥rmula de m√≠nimos cuadrados en forma normal) no pueden entrenar bien en este caso, ya que la inversa no existe .\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo 1:** Determinante distinto de 0\n",
        "\n",
        "$$\n",
        "A =\n",
        "\\begin{bmatrix}\n",
        "2 & 1 \\\\\n",
        "5 & 3\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "C√°lculo en matriz de 2X2:\n",
        "\n",
        "$$\n",
        "\\det(A) = 2\\cdot 3 - 1\\cdot 5 = 6 - 5 = 1\n",
        "$$\n",
        "\n",
        "‚úÖ Como $\\det(A) = 1 \\neq 0$, las columnas son **independientes**.\n",
        "üëâ Cada caracter√≠stica (representada por una columna) aporta informaci√≥n distinta. En un modelo, esto es deseable para un aprendizaje robusto.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Ejemplo 2:** Determinante igual a 0 (redundancia)\n",
        "\n",
        "$$\n",
        "B =\n",
        "\\begin{bmatrix}\n",
        "2 & 4 \\\\\n",
        "1 & 2\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "C√°lculo:\n",
        "\n",
        "$$\n",
        "\\det(B) = 2\\cdot 2 - 4\\cdot 1 = 4 - 4 = 0\n",
        "$$\n",
        "\n",
        "‚ùå Aqu√≠ $\\det(B) = 0$.\n",
        "üëâ La segunda columna es el **doble de la primera**. No aporta informaci√≥n nueva, lo que indica redundancia en los datos\n",
        "\n",
        "**Consideraciones adicionales en IA/ML sobre el determinante**:\n",
        "\n",
        "* **Valores singulares y Autovalores**: El determinante est√° relacionado con los autovalores y valores singulares de una matriz. Por ejemplo, para una matriz cuadrada, el determinante es el producto de sus autovalores.\n",
        "* **Matrices triangulares**: El determinante de una matriz triangular (superior o inferior) es simplemente el producto de los elementos de su diagonal principal. Esta propiedad es clave para algoritmos de descomposici√≥n.\n",
        "* **Costo computacional**: El c√°lculo directo del determinante mediante la f√≥rmula de permutaciones es computacionalmente muy costoso (complejidad factorial $O(n!)$). Sin embargo, existen m√©todos mucho m√°s eficientes, como el uso de la descomposici√≥n LU, que reducen la complejidad a $O(n^3)$. Las bibliotecas como NumPy utilizan estas implementaciones optimizadas.\n",
        "* **Estabilidad num√©rica**: En la pr√°ctica, con matrices grandes y n√∫meros de punto flotante, calcular el determinante puede ser sensible a errores num√©ricos.\n",
        "Comprender el determinante no es solo una cuesti√≥n te√≥rica, sino una herramienta diagn√≥stica fundamental para la calidad y la manejabilidad de los datos en el desarrollo de algoritmos de Machine Learning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OnK8AdcQ5fFc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnK8AdcQ5fFc",
        "outputId": "77073063-5388-4175-a002-cb5b3c30ba08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Determinante ventas: 0.0\n",
            "Rango ventas: 1\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Columnas: [precio_base, IVA, total_con_IVA]\n",
        "# Aqu√≠ IVA = 0.21 * base y total = base + IVA  ‚Üí col3 = col1 + col2 (lineal)\n",
        "ventas = np.array([\n",
        "    [100, 21, 121],\n",
        "    [200, 42, 242],\n",
        "    [300, 63, 363]\n",
        "], dtype=float)\n",
        "\n",
        "print(\"Determinante ventas:\", np.linalg.det(ventas))        # ‚Üí 0.0 exacto (o ~0 por redondeo)\n",
        "print(\"Rango ventas:\", np.linalg.matrix_rank(ventas))       # ‚Üí 2 < 3  (hay redundancia)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DLOOPbVM5i4v",
      "metadata": {
        "id": "DLOOPbVM5i4v"
      },
      "source": [
        "\n",
        "## Recuerda\n",
        "\n",
        "Las operaciones con matrices son el **fundamento matem√°tico** para manejar datos y algoritmos en IA y ML:\n",
        "* La **suma y resta** de matrices se realizan **elemento a elemento **y solo son posibles si las matrices tienen el **mismo tama√±o**. Son esenciales en la optimizaci√≥n, como en el ajuste de pesos durante el **gradiente descendente**.\n",
        "* La **multiplicaci√≥n por escalar** ajusta la magnitud de todos los elementos de una matriz (la \"estira o encoge\"), sin alterar sus dimensiones. Se usa para modificar par√°metros y pesos de un modelo.\n",
        "* La **multiplicaci√≥n de matrices** es una operaci√≥n central que **combina informaci√≥n y transforma datos**. Es **clave en redes neuronales** para calcular las salidas de las capas, requiriendo que el n√∫mero de columnas de la primera matriz sea igual al n√∫mero de filas de la segunda.\n",
        "* La **transpuesta** de una matriz ($A^T$) **intercambia filas por columnas**. Es vital para **ajustar dimensiones** en c√°lculos de ML, utiliz√°ndose en productos escalares, c√°lculo de gradientes y modelos lineales.\n",
        "* La **inversa** de una matriz ($A^{-1}$) \"deshace\" su efecto, y se cumple que $A \\cdot A^{-1} = I$ (la matriz identidad). Solo existe para **matrices cuadradas y no singulares** (con determinante distinto de 0). Es crucial para la resoluci√≥n de sistemas de** ecuaciones lineales** y en algoritmos de **optimizaci√≥n**.\n",
        "* El **determinante** es un n√∫mero asociado a una **matriz cuadrada** que indica si esta tiene inversa. Un **determinante distinto de 0** significa que la matriz contiene informaci√≥n independiente (datos no redundantes); **un determinante igual a 0** se√±ala **redundancia** en las columnas, lo que puede impedir el correcto aprendizaje de un modelo que necesite invertir la matriz."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HizVdvTVFBLi",
      "metadata": {
        "id": "HizVdvTVFBLi"
      },
      "source": [
        "## 2.5 Matrices en Python con NumPy\n",
        "\n",
        "En Python, las matrices no existen como tipo de dato b√°sico. Para trabajar con ellas usamos **NumPy**, una librer√≠a fundamental en c√°lculo num√©rico y Machine Learning.\n",
        "\n",
        "üëâ En NumPy, una **matriz** se representa con un objeto llamado `ndarray`.\n",
        "\n",
        "* Un **vector** es un array 1D (una lista de n√∫meros).\n",
        "* Una **matriz** es un array 2D (tabla de n√∫meros con filas y columnas).\n",
        "* Un **tensor** es un array con m√°s dimensiones (3D, 4D, ‚Ä¶).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.1 Crear matrices\n",
        "\n",
        "Con NumPy podemos crear matrices de varias formas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0QKY6UqMFZHx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QKY6UqMFZHx",
        "outputId": "cb62bcd6-3088-4311-fd18-2b8a439e62b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matriz A:\n",
            " [[1 2 3]\n",
            " [4 5 6]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Crear una matriz a partir de una lista de listas\n",
        "A = np.array([[1, 2, 3],\n",
        "              [4, 5, 6]])\n",
        "print(\"Matriz A:\\n\", A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MiJIuMXOFb4d",
      "metadata": {
        "id": "MiJIuMXOFb4d"
      },
      "source": [
        "üëâ Aqu√≠ creamos una matriz **2x3** (2 filas, 3 columnas) con n√∫meros que nosotros mismos escribimos.\n",
        "\n",
        "---\n",
        "\n",
        "Tambi√©n podemos crear matrices especiales autom√°ticamente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J5AtOsmnFdrx",
      "metadata": {
        "id": "J5AtOsmnFdrx"
      },
      "outputs": [],
      "source": [
        "# Crear una matriz de ceros\n",
        "Z = np.zeros((3, 3))\n",
        "print(\"\\nMatriz de ceros:\\n\", Z)\n",
        "\n",
        "# Crear una matriz de unos\n",
        "U = np.ones((2, 4))\n",
        "print(\"\\nMatriz de unos:\\n\", U)\n",
        "\n",
        "# Crear la matriz identidad (I)\n",
        "I = np.eye(3)\n",
        "print(\"\\nMatriz identidad:\\n\", I)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3uuqNZ5Fh21",
      "metadata": {
        "id": "b3uuqNZ5Fh21"
      },
      "source": [
        "üëâ Muy √∫til en ML:\n",
        "\n",
        "* Las de ceros o unos se usan para **inicializar** datos.\n",
        "* La identidad juega el papel del ‚Äú1‚Äù en las matrices: $A \\cdot I = A$.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.2 Acceso a elementos\n",
        "\n",
        "Una vez creada la matriz, podemos consultar sus elementos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4MRKFTQqFicB",
      "metadata": {
        "id": "4MRKFTQqFicB"
      },
      "outputs": [],
      "source": [
        "print(\"Elemento fila 1, col 2:\", A[0, 1])   # fila 1, columna 2 (recuerda que Python empieza en 0)\n",
        "print(\"Primera fila:\", A[0, :])             # todos los elementos de la fila 1\n",
        "print(\"Segunda columna:\", A[:, 1])          # todos los elementos de la columna 2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nEYKIE8QFmD1",
      "metadata": {
        "id": "nEYKIE8QFmD1"
      },
      "source": [
        "\n",
        "üëâ Aqu√≠ aprendemos:\n",
        "\n",
        "* `A[i, j]` ‚Üí un elemento concreto.\n",
        "* `A[i, :]` ‚Üí toda la fila *i*.\n",
        "* `A[:, j]` ‚Üí toda la columna *j*.\n",
        "\n",
        "Esto se usa much√≠simo para trabajar con datos: por ejemplo, seleccionar todas las notas de Matem√°ticas (columna) o todas las caracter√≠sticas de un alumno (fila).\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.3 Operaciones b√°sicas con matrices\n",
        "\n",
        "Las matrices permiten operaciones como suma, resta o multiplicaci√≥n.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eX-pxalrFn1B",
      "metadata": {
        "id": "eX-pxalrFn1B"
      },
      "outputs": [],
      "source": [
        "B = np.array([[7, 8, 9],\n",
        "              [10, 11, 12]])\n",
        "\n",
        "print(\"Suma A + B:\\n\", A + B)     # suma elemento a elemento\n",
        "print(\"Resta A - B:\\n\", A - B)\n",
        "print(\"Multiplicaci√≥n escalar (2*A):\\n\", 2 * A)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GlvEN7dPFqmx",
      "metadata": {
        "id": "GlvEN7dPFqmx"
      },
      "source": [
        "\n",
        "üëâ Estas operaciones son **elemento a elemento** (cada casilla se suma, resta o multiplica con su correspondiente).\n",
        "\n",
        "Para hacer el **producto matricial cl√°sico del √°lgebra lineal** usamos `@`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EPG0R80lFsSN",
      "metadata": {
        "id": "EPG0R80lFsSN"
      },
      "outputs": [],
      "source": [
        "print(\"Producto A @ B.T:\\n\", A @ B.T)  # trasponemos B para que encajen dimensiones\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fNuUwt8NFuJQ",
      "metadata": {
        "id": "fNuUwt8NFuJQ"
      },
      "source": [
        "\n",
        "üëâ Aqu√≠, `A` es de tama√±o (2x3) y `B.T` de (3x2), por lo que el resultado es (2x2).\n",
        "Esto se usa en ML para combinar datos con pesos o aplicar transformaciones.\n",
        "\n",
        "---\n",
        "\n",
        "### 2.5.4 Propiedades de matrices\n",
        "\n",
        "NumPy nos permite calcular propiedades muy √∫tiles:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vj5rMYMaFv7I",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj5rMYMaFv7I",
        "outputId": "7a3f5704-675c-43ec-e1db-02af31fbb8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transpuesta de A:\n",
            " [[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n",
            "Determinante de A.T @ A: 0.0\n",
            "Inversa de la identidad:\n",
            " [[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Transpuesta de A:\\n\", A.T)                  # Cambia filas por columnas\n",
        "print(\"Determinante de A.T @ A:\", np.linalg.det(A.T @ A))  # Determinante\n",
        "print(\"Inversa de la identidad:\\n\", np.linalg.inv(I))      # Matriz inversa"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VNtc5INvFyok",
      "metadata": {
        "id": "VNtc5INvFyok"
      },
      "source": [
        "\n",
        "üëâ Estas operaciones aparecen mucho en Machine Learning:\n",
        "\n",
        "* La **transpuesta** alinea las dimensiones para c√°lculos.\n",
        "* El **determinante** indica si hay redundancia en los datos.\n",
        "* La **inversa** se usa en f√≥rmulas como la regresi√≥n lineal.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hTHlTmhldth8",
      "metadata": {
        "id": "hTHlTmhldth8"
      },
      "source": [
        "**ACTIVIDAD 4 ‚Äì Operaciones b√°sicas con matrices**\n",
        "**Objetivo**: aplicar suma, resta y multiplicaci√≥n.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Declara dos matrices `A` y `B` de tama√±o 2√ó2.\n",
        "  2. Calcula su suma, resta y multiplicaci√≥n por un escalar.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Calcula el producto matricial `A @ B`.\n",
        "  4\\. Obt√©n la transpuesta de `A`.\n",
        "\n",
        "* **Reto**\n",
        "  5\\. Calcula el determinante y la inversa de una matriz cuadrada 2√ó2. Comprueba que `A @ A‚Åª¬π = I`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "srT82c3ldtuT",
      "metadata": {
        "id": "srT82c3ldtuT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 7  8]\n",
            " [10 11]]\n",
            "[[1 2]\n",
            " [2 4]]\n",
            "[[14 16]\n",
            " [20 22]]\n",
            "[[2 4]\n",
            " [4 8]]\n",
            "[[ 8 10]\n",
            " [12 15]]\n",
            "[[6 6]\n",
            " [8 7]]\n",
            "[[23 46]\n",
            " [32 64]]\n",
            "[[ 7 10]\n",
            " [ 8 11]]\n",
            "-2.9999999999999902 0.0\n",
            "[[-3.66666667  2.66666667]\n",
            " [ 3.33333333 -2.33333333]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.array([[7, 8],\n",
        "              [10, 11]])\n",
        "print(a)\n",
        "b = np.array([[1, 2],\n",
        "              [2, 4]])\n",
        "print(b)\n",
        "#Multiplicacion por un escalar\n",
        "c = 2\n",
        "print(c * a)\n",
        "print(c * b)\n",
        "print(a + b)\n",
        "print(a - b)\n",
        "print(a @ b)\n",
        "print(a.T)\n",
        "determinante = np.linalg.det(a)\n",
        "determinanteb = np.linalg.det(b)\n",
        "print(determinante, determinanteb)\n",
        "#Si el determinante es cero no tiene inversa, como no es cero tiene inversa\n",
        "a_inv = np.linalg.inv(a)\n",
        "print(a_inv)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3JtCZ5uWdxFl",
      "metadata": {
        "id": "3JtCZ5uWdxFl"
      },
      "source": [
        "### 2.5.5 Ejemplo aplicado a Machine Learning\n",
        "\n",
        "Supongamos que tenemos un dataset con alumnos:\n",
        "\n",
        "* Caracter√≠sticas ‚Üí \\[horas de estudio, nota en pr√°cticas].\n",
        "* Queremos calcular una predicci√≥n de su nota final a partir de unos pesos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kBFyMFebF0-J",
      "metadata": {
        "id": "kBFyMFebF0-J"
      },
      "outputs": [],
      "source": [
        "# Matriz de datos: filas = alumnos, columnas = caracter√≠sticas\n",
        "datos = np.array([[2, 7],   # Alumno 1\n",
        "                  [4, 6],   # Alumno 2\n",
        "                  [5, 9]])  # Alumno 3\n",
        "\n",
        "# Pesos del modelo: importancia de cada caracter√≠stica\n",
        "pesos = np.array([[0.4],\n",
        "                  [0.6]])\n",
        "\n",
        "# Predicciones: datos (3x2) @ pesos (2x1) = (3x1)\n",
        "predicciones = datos @ pesos\n",
        "print(\"Predicciones:\\n\", predicciones)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BSblOZk1F3WU",
      "metadata": {
        "id": "BSblOZk1F3WU"
      },
      "source": [
        "üëâ Esto es exactamente lo que ocurre en un modelo lineal:\n",
        "\n",
        "* `datos` = matriz con las caracter√≠sticas de cada ejemplo.\n",
        "* `pesos` = par√°metros que aprende el modelo.\n",
        "* `predicciones` = resultado para cada alumno."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0sOc8DUDF5kU",
      "metadata": {
        "id": "0sOc8DUDF5kU"
      },
      "source": [
        "## Resumen\n",
        "\n",
        "* NumPy hace que trabajar con **matrices sea muy sencillo**.\n",
        "* Todo lo que aprendemos en matem√°ticas (sumar, multiplicar, trasponer‚Ä¶) lo podemos probar en Python con pocas l√≠neas.\n",
        "* En Machine Learning, las **matrices son la forma est√°ndar de guardar y manipular datos**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LnwzKdOeL9Ee",
      "metadata": {
        "id": "LnwzKdOeL9Ee"
      },
      "source": [
        "## Actividades pr√°cticas\n",
        "\n",
        "### üìù Actividad 2 ‚Äì Matrices\n",
        "\n",
        "1. Crea dos matrices 2x2:\n",
        "\n",
        "   $\n",
        "   A = \\begin{bmatrix}1 & 3 \\\\ 2 & 4\\end{bmatrix}, \\quad\n",
        "   B = \\begin{bmatrix}2 & 0 \\\\ 1 & 2\\end{bmatrix}\n",
        "   $\n",
        "2. Calcula: suma, resta, transpuesta y producto $A \\times B$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "20fe841a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 3]\n",
            " [2 4]] \n",
            " [[2 0]\n",
            " [1 2]]\n",
            "[[3 3]\n",
            " [3 6]] [[-1  3]\n",
            " [ 1  2]] [[2 0]\n",
            " [2 8]] \n",
            " [[1 2]\n",
            " [3 4]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "A = np.array([[1,3],\n",
        "             [2,4]])\n",
        "B = np.array([[2,0],\n",
        "             [1,2]])\n",
        "print(A,\"\\n\",B)\n",
        "\n",
        "\n",
        "suma = A + B\n",
        "resta = A - B\n",
        "Multiplicacion  = A * B\n",
        "Traspuesta = A.T\n",
        "\n",
        "print(suma, resta, Multiplicacion, \"\\n\",Traspuesta)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5d94ba2",
      "metadata": {
        "id": "b5d94ba2"
      },
      "source": [
        "\n",
        "## 3. Sistemas de ecuaciones lineales\n",
        "\n",
        "Un **sistema de ecuaciones lineales (SEL)** es un conjunto de dos o m√°s ecuaciones que involucran varias inc√≥gnitas. Estos sistemas son omnipresentes en diversas disciplinas cient√≠ficas e ingenieriles, donde se utilizan para modelar interacciones en redes bioqu√≠micas, procesos econ√≥micos y muchos otros fen√≥menos.\n",
        "\n",
        "$\n",
        "\\begin{cases}\n",
        "2x + y = 8 \\\\\n",
        "x - y = 2\n",
        "\\end{cases}\n",
        "$\n",
        "\n",
        "En este ejemplo, buscamos los valores de $x$ e $y$ que satisfacen simult√°neamente ambas ecuaciones.\n",
        "\n",
        "***\n",
        "\n",
        "### Representaci√≥n matricial\n",
        "\n",
        "Para facilitar la resoluci√≥n y gesti√≥n de los sistemas de ecuaciones lineales, especialmente aquellos con un gran n√∫mero de variables, podemos escribirlos de forma compacta utilizando matrices.\n",
        "\n",
        "El sistema de ecuaciones lineales del ejemplo anterior se puede expresar en su forma matricial como:\n",
        "\n",
        "$ \\begin{bmatrix}2 & 1 \\\\1 & -1\\end{bmatrix}\\begin{bmatrix}x \\\\y\\end{bmatrix}=\\begin{bmatrix}8 \\\\2\\end{bmatrix}$\n",
        "\n",
        "Esta representaci√≥n consiste en tres componentes clave:\n",
        "\n",
        "* La matriz de la izquierda, denominada **matriz de coeficientes** ($A$), contiene los valores num√©ricos que acompa√±an a cada inc√≥gnita. En el ejemplo, $A = \\begin{bmatrix}2 & 1 \\\\1 & -1\\end{bmatrix}$.\n",
        "* El vector columna siguiente es el **vector de inc√≥gnitas** ($x$), que contiene las variables que deseamos resolver. En el ejemplo, $\\begin{bmatrix}x \\\\y\\end{bmatrix}$ .\n",
        "* El vector de la derecha es el **vector de t√©rminos independientes** ($b$), que agrupa los resultados o constantes de cada ecuaci√≥n. En el ejemplo, $\\begin{bmatrix}8 \\\\2\\end{bmatrix}$ .\n",
        "\n",
        "De esta manera, un sistema de ecuaciones lineales se puede escribir de forma general como $A \\mathbf{x} = \\mathbf{b}$. Desde la perspectiva de las transformaciones lineales, esta notaci√≥n nos pregunta: \"¬øQu√© vector $\\mathbf{x}$ es transformado en el vector $\\mathbf{b}$ por la transformaci√≥n lineal representada por la matriz $A$?\".\n",
        "***\n",
        "\n",
        "### Resolver sistemas en Python con NumPy\n",
        "\n",
        "La resoluci√≥n manual de sistemas de ecuaciones lineales puede ser tediosa y poco pr√°ctica para sistemas grandes. Afortunadamente, herramientas computacionales como la biblioteca **NumPy en Python** nos permiten encontrar la soluci√≥n de manera eficiente.\n",
        "\n",
        "Podemos usar la funci√≥n np.linalg.solve(A, b) para encontrar la soluci√≥n del sistema [ref: user provided text]. Esta funci√≥n toma la matriz de coeficientes $A$ y el vector de t√©rminos independientes $b$ como entradas y devuelve el vector de inc√≥gnitas $x$ que satisface el sistema.\n",
        "\n",
        "El resultado de ``np.linalg.solve`` muestra los valores de $x$ e $y$ que satisfacen ambas ecuaciones. Es importante destacar que detr√°s de ``np.linalg.solve`` se encuentran algoritmos num√©ricos altamente optimizados, como la **eliminaci√≥n gaussiana** y la descomposici√≥n LU (Lower-Upper), que son los pilares del √°lgebra lineal computacional. Estos m√©todos permiten una resoluci√≥n r√°pida y precisa, incluso para sistemas con miles de variables.\n",
        "\n",
        "En el caso de que la matriz de coeficientes $A$ sea **invertible** (es decir, no singular, con un determinante distinto de cero), la soluci√≥n √∫nica del sistema se puede expresar como $\\mathbf{x} = A^{-1} \\mathbf{b}$. La computaci√≥n de la inversa de una matriz, a su vez, tambi√©n se basa en t√©cnicas como la descomposici√≥n LU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd2d51f2",
      "metadata": {
        "id": "bd2d51f2",
        "outputId": "e109f84c-edcb-4be9-e07a-73f5c9b9e618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Soluci√≥n (x, y): [3.33333333 1.33333333]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "A = np.array([[2, 1], [1, -1]])\n",
        "b = np.array([8, 2])\n",
        "\n",
        "sol = np.linalg.solve(A, b)\n",
        "print(\"Soluci√≥n (x, y):\", sol)  # [3.333..., 1.333...]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RaBJIUhTdja1",
      "metadata": {
        "id": "RaBJIUhTdja1"
      },
      "source": [
        "El resultado muestra los valores de $x$ y $y$ que satisfacen ambas ecuaciones.\n",
        "\n",
        "\n",
        "**ACTIVIDAD 5 ‚Äì Resolver sistemas lineales**\n",
        "**Objetivo**: usar matrices para resolver ecuaciones.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Resuelve el sistema:\n",
        "\n",
        "     ```\n",
        "     2x + y = 8\n",
        "     x ‚Äì y = 2\n",
        "     ```\n",
        "\n",
        "     usando `np.linalg.solve`.\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  2\\. Comprueba la soluci√≥n sustituyendo los valores de `x` e `y` en las ecuaciones.\n",
        "\n",
        "* **Reto**\n",
        "  3\\. Escribe una funci√≥n `resolver(A, b)` que reciba la matriz de coeficientes y el vector de t√©rminos independientes y devuelva la soluci√≥n. Pru√©bala con otro sistema.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1816ca06",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = 3.3333333333333335, y = 1.3333333333333333\n",
            "Verificaci√≥n:\n",
            "2x + y = 8.0 (esperado: 8)\n",
            "x - y = 2.0 (esperado: 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos las matrices del sistema\n",
        "A = np.array([[2, 1],\n",
        "              [1, -1]])\n",
        "B = np.array([8, 2])\n",
        "\n",
        "# Resolviendo el sistema\n",
        "sol = np.linalg.solve(A, B)\n",
        "\n",
        "#soluci√≥n\n",
        "x, y = sol\n",
        "print(f\"x = {x}, y = {y}\")\n",
        "\n",
        "#Verificamos las ecuaciones\n",
        "eq1 = 2*x + y\n",
        "eq2 = x - y\n",
        "\n",
        "print(f\"Verificaci√≥n:\")\n",
        "print(eq1)\n",
        "print(eq2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a5c37a0",
      "metadata": {
        "id": "9a5c37a0"
      },
      "source": [
        "\n",
        "***\n",
        "\n",
        "### ¬øPor qu√© son importantes en Machine Learning?\n",
        "\n",
        "Los sistemas de ecuaciones lineales son de **importancia fundamental** en Machine Learning (ML) y la Inteligencia Artificial (IA), ya que subyacen a muchos algoritmos y procesos complejos :\n",
        "\n",
        "* **Regresi√≥n Lineal y Determinaci√≥n de Par√°metros**: Muchos problemas de Machine Learning, como la regresi√≥n lineal, se traducen directamente en resolver sistemas de ecuaciones lineales . Estos sistemas permiten encontrar los **par√°metros (o coeficientes/pesos)** que mejor ajustan un modelo a los datos, minimizando el error de predicci√≥n. Por ejemplo, en la regresi√≥n lineal, la soluci√≥n de m√≠nimos cuadrados a menudo implica la inversi√≥n de una matriz .\n",
        "* **Optimizaci√≥n de Modelos**: En ML, la **optimizaci√≥n** es el proceso de encontrar los mejores par√°metros para un modelo, minimizando una funci√≥n de p√©rdida (error). La resoluci√≥n de SELs (y operaciones de inversi√≥n de matrices relacionadas) es una tarea com√∫n al realizar **actualizaciones de par√°metros** en algoritmos de optimizaci√≥n como el gradiente descendente . De hecho, el propio m√©todo del **gradiente descendente** puede verse como la resoluci√≥n iterativa de una ecuaci√≥n diferencial discreta que lleva a la soluci√≥n √≥ptima .\n",
        "* **Redes Neuronales**: La representaci√≥n matricial es **el lenguaje intr√≠nseco de las redes neuronales**.\n",
        "  * Cada capa de una red neuronal, especialmente en redes profundas, realiza una t**ransformaci√≥n lineal** sobre los datos de entrada, que se implementa como una **multiplicaci√≥n de matrices** (la matriz de entrada por una matriz de pesos aprendidos) .\n",
        "  * Los \"coeficientes\" o \"inc√≥gnitas\" de los SELs se corresponden con los** pesos y sesgos** que la red neuronal aprende durante su entrenamiento .\n",
        "  * La arquitectura completa de las redes neuronales se construye sobre estas ideas matem√°ticas, donde cada capa es una funci√≥n que transforma los datos .\n",
        "* **Eficiencia Computacional y Manejo de Datos a Gran Escala**: La representaci√≥n matricial y la resoluci√≥n eficiente de sistemas con herramientas computacionales como NumPy **son fundamentales para entrenar modelos con muchos datos y variables**. Los problemas de IA a menudo involucran **datos de alta dimensi√≥n** y millones de par√°metros (e.g., ResNet18 tiene 11 millones de par√°metros) . Sin las operaciones matriciales optimizadas, ser√≠a imposible procesar tales vol√∫menes de informaci√≥n y realizar los c√°lculos necesarios para el aprendizaje.\n",
        "* **An√°lisis de Interacciones entre Variables**: Este m√©todo tambi√©n ayuda a entender c√≥mo las variables interact√∫an y contribuyen a las predicciones. La estructura de la matriz de coeficientes y la forma de la soluci√≥n pueden ofrecer informaci√≥n sobre la independencia lineal de las caracter√≠sticas y su impacto en el modelo .\n",
        "\n",
        "En resumen, los sistemas de ecuaciones lineales, y el √°lgebra lineal en general, son el \"pan y mantequilla\" del Machine Learning computacional. Proporcionan el marco matem√°tico indispensable que permite a las m√°quinas aprender, razonar y tomar decisiones, siendo la base para comprender a fondo el funcionamiento interno de los algoritmos de IA.\n",
        "\n",
        "***\n",
        "\n",
        "\n",
        "| Concepto                | Qu√© es                                           | Ejemplo concreto                  |\n",
        "|------------------------|-------------------------------------------------|---------------------------------|\n",
        "| Sistema de ecuaciones  | Conjunto de ecuaciones con varias inc√≥gnitas     | $2x + y = 8$, $x - y = 2$   |\n",
        "| Representaci√≥n matricial| Forma compacta usando matrices y vectores        | $AX = B$                   |\n",
        "| Soluci√≥n en Python     | Usar `np.linalg.solve` para encontrar inc√≥gnitas | $[3.333..., 1.333...]$        |\n",
        "| Uso en Machine Learning| Encontrar par√°metros √≥ptimos en modelos lineales | Regresi√≥n lineal                |\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f5ebd14",
      "metadata": {
        "id": "1f5ebd14"
      },
      "source": [
        "## Actividades pr√°cticas\n",
        "\n",
        "---\n",
        "\n",
        "### üìù Actividad 3 ‚Äì Sistemas de ecuaciones\n",
        "\n",
        "Resuelve con NumPy:\n",
        "\n",
        "$\n",
        "3x + 2y = 12 \\\\\n",
        "x -  y = 1\n",
        "$\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5cfb7b0c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x = 2.7999999999999994, y = 1.8000000000000003\n",
            "Verificaci√≥n:\n",
            "12.0\n",
            "0.9999999999999991\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definimos las matrices del sistema\n",
        "A = np.array([[3, 2],\n",
        "              [1, -1]])\n",
        "B = np.array([12, 1])\n",
        "\n",
        "# Resolviendo el sistema\n",
        "sol = np.linalg.solve(A, B)\n",
        "\n",
        "#soluci√≥n\n",
        "x, y = sol\n",
        "print(f\"x = {x}, y = {y}\")\n",
        "\n",
        "#Verificamos las ecuaciones\n",
        "eq1 = 3*x + 2*y\n",
        "eq2 = x - y\n",
        "\n",
        "print(f\"Verificaci√≥n:\")\n",
        "print(eq1)\n",
        "print(eq2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cTUnZMtGMrXt",
      "metadata": {
        "id": "cTUnZMtGMrXt"
      },
      "source": [
        "\n",
        "## 4 Uso de matrices en Machine Learning\n",
        "\n",
        "Un **dataset** (conjunto de datos) es la materia prima para los sistemas de IA, y puede representarse de forma natural y eficiente como una matriz. Esta estructura matricial permite organizar la informaci√≥n de manera que los algoritmos de ML puedan procesarla:\n",
        "\n",
        "* **Filas** ‚Üí Representan los **ejemplos** o **muestras individuales** del dataset (por ejemplo, personas, casas, im√°genes, etc.) .\n",
        "* **Columnas** ‚Üí Representan las **caracter√≠sticas** o **atributos** de cada ejemplo (por ejemplo, edad, altura, precio, tipo de flor, etc.). A menudo, una \"feature\" es un tipo particular de medici√≥n.\n",
        "\n",
        "**Ejemplo: dataset Iris** El famoso **dataset Iris** es un ejemplo cl√°sico de c√≥mo un conjunto de datos se estructura como una matriz. Contiene mediciones de tres especies de Iris, con **150 data points (muestras) y cuatro caracter√≠sticas (features)** por cada muestra (longitud y anchura de s√©palos y p√©talos). Las etiquetas (species) asociadas a cada muestra tambi√©n pueden ser representadas num√©ricamente.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x49KkbdHNt3H",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x49KkbdHNt3H",
        "outputId": "5565fb75-3c95-450a-cfaa-f88d8753b012"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma del dataset: (150, 4)\n",
            "Caracter√≠sticas: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Clases: ['setosa' 'versicolor' 'virginica']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "print(\"Forma del dataset:\", X.shape)   # (150, 4)\n",
        "print(\"Caracter√≠sticas:\", iris.feature_names)\n",
        "print(\"Clases:\", iris.target_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UwiFD7Z-t3H6",
      "metadata": {
        "id": "UwiFD7Z-t3H6"
      },
      "source": [
        "En ML, es com√∫n trabajar con **datos de alta dimensi√≥n**, que tienen muchas caracter√≠sticas . Las matrices son herramientas esenciales para representar y manipular estos datos. Por ejemplo, t√©cnicas como la **normalizaci√≥n de datos** ajustan las caracter√≠sticas en una matriz para que est√©n en la misma escala, lo que mejora el rendimiento de los algoritmos."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QcT7OlsUOAtK",
      "metadata": {
        "id": "QcT7OlsUOAtK"
      },
      "source": [
        "---\n",
        "\n",
        "### 4.2 Im√°genes como matrices\n",
        "\n",
        "Una imagen digital es, en esencia, una tabla de n√∫meros, lo que permite representarla de manera √≥ptima como una matriz de p√≠xeles\n",
        "\n",
        "* **Im√°genes en blanco y negro**: Cada casilla de la matriz corresponde a un p√≠xel, y su valor num√©rico representa la intensidad o el color (por ejemplo, 0 para negro, 255 para blanco).\n",
        "* **Im√°genes en color**: Cada p√≠xel tiene m√∫ltiples valores (por ejemplo, 3 valores para los canales Rojo, Verde y Azul - RGB). Esto no se representa con una simple matriz 2D, sino con un tensor (un arreglo multidimensional que generaliza escalares, vectores y matrices a dimensiones superiores). Por ejemplo, una imagen RGB podr√≠a ser un tensor de forma Altura x Anchura x 3 .\n",
        "\n",
        "**Ejemplo: imagen $28\\times28$ del dataset MNIST** Una imagen de $28\\times28$ p√≠xeles, como las del famoso dataset MNIST, puede representarse como una matriz de ese tama√±o. Para algunos modelos, esta matriz puede \"aplanarse\" en un vector de 784 n√∫meros, que es la concatenaci√≥n de todas las filas o columnas.\n",
        "\n",
        "üëâ De esta forma, las redes neuronales pueden ‚Äúleer‚Äù y procesar im√°genes como si fueran tablas de n√∫meros, lo que les permite identificar patrones, bordes, texturas y objetos mediante operaciones matem√°ticas como las convoluciones . Las **Redes Neuronales Convolucionales (CNNs)**, por ejemplo, dependen en gran medida de estas representaciones matriciales (y tensoriales) para identificar patrones en datos visuales.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JVbDi3vxOA1N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "JVbDi3vxOA1N",
        "outputId": "222b7421-0d32-4e0b-f158-a7bc2b1bef40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Forma de X: (70000, 784)\n",
            "Forma de y: (70000,)\n",
            "Etiqueta real: 5\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 1. Descargar dataset MNIST (digitos escritos a mano)\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "\n",
        "X, y = mnist.data, mnist.target\n",
        "print(\"Forma de X:\", X.shape)  # (70000, 784) ‚Üí 70k im√°genes, cada una con 784 p√≠xeles\n",
        "print(\"Forma de y:\", y.shape)  # etiquetas (d√≠gitos 0‚Äì9)\n",
        "\n",
        "# 2. Seleccionamos una imagen (ejemplo: la n¬∫ 0)\n",
        "imagen_vector = X[0]          # vector de 784 elementos\n",
        "imagen_matriz = imagen_vector.reshape(28, 28)  # convertimos a matriz 28x28\n",
        "etiqueta = y[0]\n",
        "\n",
        "print(\"Etiqueta real:\", etiqueta)\n",
        "\n",
        "# 3. Mostrar la imagen\n",
        "plt.imshow(imagen_matriz, cmap=\"gray\")\n",
        "plt.title(f\"D√≠gito: {etiqueta}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DHOazYeYOA8d",
      "metadata": {
        "id": "DHOazYeYOA8d"
      },
      "source": [
        "### 4.3 Transformaciones lineales\n",
        "\n",
        "Una de las aplicaciones m√°s profundas y fundamentales de las matrices en ML es su rol en las** transformaciones lineales**. Muchos modelos de ML son, en esencia, **multiplicaciones de matrices**. Las transformaciones lineales son funciones que mapean un vector de un espacio a otro, preservando la estructura del espacio vectorial, y son representadas por matrices.\n",
        "* **Regresi√≥n lineal**: La regresi√≥n lineal, uno de los modelos predictivos m√°s simples pero potentes, se expresa matricialmente como: $$ y = Xw $$ Donde:\n",
        "  * $X$ = Matriz de datos de entrada (features), donde cada fila es una muestra y cada columna una caracter√≠stica .\n",
        "  * $w$ = Vector de **pesos del modelo (weights)** o coeficientes que el modelo aprende .\n",
        "  * $y$ = Vector de las predicciones de salida. En este contexto, la matriz $X$ describe una transformaci√≥n que, al ser multiplicada por el vector de pesos $w$, produce las predicciones $y$. El objetivo de la regresi√≥n lineal es encontrar los pesos $w$ que mejor ajustan el modelo a los datos, lo que a menudo implica resolver un sistema de ecuaciones lineales, y en muchos casos, la inversi√≥n de matrices.\n",
        "\n",
        "\n",
        "Ejemplo en Python (regresi√≥n lineal simplificada):\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cxtkRRGGu1lK",
      "metadata": {
        "id": "cxtkRRGGu1lK"
      },
      "outputs": [],
      "source": [
        "# Dataset: horas de estudio y nota en pr√°cticas\n",
        "X = np.array([[2, 7],\n",
        "              [4, 6],\n",
        "              [5, 9]])  # (3x2)\n",
        "\n",
        "# Pesos del modelo\n",
        "w = np.array([[0.4],\n",
        "              [0.6]])   # (2x1)\n",
        "\n",
        "y = X @ w   # Predicciones\n",
        "print(\"Predicciones:\\n\", y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZbShoJY6u1b6",
      "metadata": {
        "id": "ZbShoJY6u1b6"
      },
      "source": [
        "* **Redes neuronales**: Las redes neuronales, el motor de gran parte de la IA moderna, son composiciones de funciones y se construyen fundamentalmente sobre operaciones matriciales . Cada capa de una red neuronal aplica una transformaci√≥n sobre sus datos de entrada. La operaci√≥n b√°sica de una capa (o un perceptr√≥n) es: $$ h = XW + b $$ Donde :\n",
        "  * $X$ = Datos de entrada (o salida de la capa anterior).\n",
        "  * $W$ = Matriz de pesos o par√°metros de la capa que el modelo aprende durante el entrenamiento.\n",
        "  * $b$ = Vector de sesgos (biases), un escalar que ajusta la salida de la neurona .\n",
        "  * $h$ = Salida lineal de la capa antes de la activaci√≥n. Esta multiplicaci√≥n de matrices ($XW$) es esencial para computar las salidas de cada capa, propagando la informaci√≥n a trav√©s de la red . Posteriormente, se aplica una funci√≥n de activaci√≥n no lineal (como Sigmoid, ReLU o Softmax) a $h$ para introducir la no-linealidad necesaria para modelar patrones complejos . El entrenamiento de estas redes implica ajustar estos pesos y sesgos, un proceso que se basa intensamente en el c√°lculo de gradientes y el algoritmo de retropropagaci√≥n (backpropagation), el cual utiliza la regla de la cadena y operaciones matriciales.\n",
        "\n",
        "  Ejemplo sencillo en Python con NumPy de una capa de red neuronal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DPlzJxqlOBDH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPlzJxqlOBDH",
        "outputId": "8ce39d40-94c3-49b8-fc88-dcba82dfd8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Entrada X:\n",
            " [[1. 2. 3.]\n",
            " [4. 5. 6.]]\n",
            "\n",
            "Salida lineal h = XW + b:\n",
            " [[0.4 1.6]\n",
            " [1.6 4.9]]\n",
            "\n",
            "Salida tras ReLU:\n",
            " [[0.4 1.6]\n",
            " [1.6 4.9]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Entrada (batch de 2 ejemplos, cada uno con 3 caracter√≠sticas)\n",
        "X = np.array([[1.0, 2.0, 3.0],\n",
        "              [4.0, 5.0, 6.0]])\n",
        "\n",
        "# Pesos (3 entradas -> 2 neuronas)\n",
        "W = np.array([[0.2, 0.8],\n",
        "              [0.5, -0.1],\n",
        "              [-0.3, 0.4]])\n",
        "\n",
        "# Sesgo (uno por neurona)\n",
        "b = np.array([0.1, -0.2])\n",
        "\n",
        "# Operaci√≥n lineal: h = XW + b\n",
        "h = X @ W + b\n",
        "\n",
        "# Funci√≥n de activaci√≥n ReLU\n",
        "relu = np.maximum(0, h)\n",
        "\n",
        "print(\"Entrada X:\\n\", X)\n",
        "print(\"\\nSalida lineal h = XW + b:\\n\", h)\n",
        "print(\"\\nSalida tras ReLU:\\n\", relu)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ejDAKYWWutGj",
      "metadata": {
        "id": "ejDAKYWWutGj"
      },
      "source": [
        "En resumen, las matrices son la representaci√≥n fundamental de datos en ML, desde los conjuntos de datos crudos hasta las complejas interacciones dentro de las redes neuronales. Su uso no solo organiza la informaci√≥n, sino que tambi√©n permite las transformaciones y c√°lculos eficientes que hacen posible el aprendizaje y la inteligencia artificial."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "QBszj10ROBKJ",
      "metadata": {
        "id": "QBszj10ROBKJ"
      },
      "source": [
        "### 4.4 Tensores como generalizaci√≥n\n",
        "\n",
        "En el √°mbito del Deep Learning y la Inteligencia Artificial moderna, el concepto de tensor es fundamental. Los tensores son una **extensi√≥n o generalizaci√≥n de los escalares (n√∫meros individuales), vectores (arreglos 1D) y matrices (arreglos 2D) a un n√∫mero arbitrario de dimensiones** . Son las estructuras de datos fundamentales para almacenar y manipular informaci√≥n en frameworks de Deep Learning como TensorFlow y PyTorch .\n",
        "\n",
        "La \"dimensi√≥n\" de un tensor se refiere a su **rango (rank)** o el n√∫mero de √≠ndices necesarios para acceder a un elemento individual.\n",
        "\n",
        "* **Escalar (Tensor 0D**): Un √∫nico n√∫mero, como 5 . Representa magnitud sin direcci√≥n .\n",
        "* **Vector (Tensor 1D)**: Una lista ordenada de n√∫meros, como  . Tiene magnitud y direcci√≥n .\n",
        "* **Matriz (Tensor 2D)**: Una tabla bidimensional de n√∫meros . Es la forma est√°ndar de almacenar datasets, donde las filas son ejemplos y las columnas son caracter√≠sticas .\n",
        "* **Tensor 3D**: Una colecci√≥n de matrices o un arreglo tridimensional de n√∫meros. Un ejemplo claro es una **imagen a color**, que puede representarse como alto √ó ancho √ó canales (por ejemplo, 3 canales para RGB) .\n",
        "* **Tensor 4D**: Una colecci√≥n de tensores 3D. Un uso com√∫n es un** lote de im√°genes** para el entrenamiento de una red neuronal: n√∫mero de im√°genes √ó alto √ó ancho √ó canales . Esto permite procesar m√∫ltiples im√°genes simult√°neamente, mejorando la eficiencia computacional.\n",
        "* **Tensores de dimensiones a√∫n mayores**: Se utilizan para datos m√°s complejos, como videos (que podr√≠an ser 5D: lote √ó tiempo √ó alto √ó ancho √ó canales) o secuencias de datos en redes neuronales recurrentes (RNNs) .\n",
        "\n",
        "Ejemplo en PyTorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "vxpRCxzJOBPm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxpRCxzJOBPm",
        "outputId": "6ce3800b-362b-4402-e32f-6d2bbe7759a1"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 10 im√°genes en blanco y negro de 28x28 p√≠xeles\u001b[39;00m\n\u001b[1;32m      4\u001b[0m imagenes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 10 im√°genes en blanco y negro de 28x28 p√≠xeles\n",
        "imagenes = torch.zeros((10, 28, 28))\n",
        "print(\"Forma del tensor:\", imagenes.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3FGt3p5pwGUv",
      "metadata": {
        "id": "3FGt3p5pwGUv"
      },
      "source": [
        "En este ejemplo, ``torch.zeros((10, 28, 28))`` crea un tensor 3D donde la primera dimensi√≥n (10) representa el n√∫mero de im√°genes en el lote, y las otras dos dimensiones (28x28) representan el alto y ancho de cada imagen. Para im√°genes en blanco y negro, no se necesita una dimensi√≥n expl√≠cita para los canales, ya que solo tienen un canal de intensidad."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca7P-qAQOPnB",
      "metadata": {
        "id": "ca7P-qAQOPnB"
      },
      "source": [
        "üëâ Los tensores son la **unidad b√°sica en Deep Learning**, porque permiten representar datos complejos como im√°genes, audio o texto.\n",
        "\n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/TensorFaces16_%281%29.png\" alt=\"tensor\" width=\"600\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5xTInfhXOKw9",
      "metadata": {
        "id": "5xTInfhXOKw9"
      },
      "source": [
        "---\n",
        "\n",
        "## üìå Idea clave\n",
        "\n",
        "* Los datasets en ML se representan como **matrices**.\n",
        "* Las im√°genes y se√±ales tambi√©n son **matrices de n√∫meros**.\n",
        "* Los algoritmos aplican **transformaciones lineales** (multiplicaciones matriciales) sobre los datos.\n",
        "* En Deep Learning trabajamos con **tensores**, que generalizan el concepto de matriz a m√°s dimensiones."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7oMsne16daRj",
      "metadata": {
        "id": "7oMsne16daRj"
      },
      "source": [
        "**ACTIVIDAD 6 ‚Äì Tensores y dimensiones**\n",
        "**Objetivo**: identificar tensores y su uso en IA.\n",
        "\n",
        "* **Nivel b√°sico**\n",
        "\n",
        "  1. Crea un tensor 3D con NumPy de tama√±o `(3,4,2)` con n√∫meros aleatorios.\n",
        "  2. Muestra su forma (`.shape`).\n",
        "\n",
        "* **Nivel intermedio**\n",
        "  3\\. Accede a la primera ‚Äúmatriz‚Äù del tensor y mu√©strala.\n",
        "\n",
        "* **Reto**\n",
        "  4\\. Genera un lote de 10 im√°genes en blanco y negro de 28√ó28 p√≠xeles (`np.zeros((10,28,28))`). Explica qu√© representan las dimensiones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rJqi7Pe-dacP",
      "metadata": {
        "id": "rJqi7Pe-dacP"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m imagenes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mForma del tensor:\u001b[39m\u001b[38;5;124m\"\u001b[39m, imagenes\u001b[38;5;241m.\u001b[39mshape)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "imagenes = torch.zeros(3,4,2)\n",
        "print(\"Forma del tensor:\", imagenes.shape)\n",
        "print(imagenes.shape)\n",
        "print(imagenes[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HPdzM2BHwpS1",
      "metadata": {
        "id": "HPdzM2BHwpS1"
      },
      "source": [
        "\n",
        "### Bibliograf√≠a\n",
        "\n",
        "*   **Danka, Tivadar.** *Mathematics of Machine Learning: Master linear algebra, calculus, and probability for machine learning*. Packt Publishing, 2025.\n",
        "*   **Gutierrez, Gilbert.** *Mathematics for AI: The Hidden Language of Machines*. Serie AI from Scratch, segunda entrega. No se especifica editorial ni fecha, pero es parte de una serie sobre IA.\n",
        "*   **Herraiz, Joaqu√≠n L., Benavent, Mar√≠a Teresa, Cordero, Paula, Gonz√°lez, Ra√∫l, Ib√°√±ez, Paula, Infante, Juan Antonio, Porqueras, Fernando, Prieto, M. √Ångeles, Rodr√≠guez, Gema de Jes√∫s.** *Las matem√°ticas de la inteligencia artificial*. Proyecto de Innovaci√≥n de la Universidad Complutense de Madrid - Convocatoria 2020/2021. Este texto se difunde a trav√©s del Proyecto LibreTexts de Recursos Educativos Abiertos (REA).\n",
        "*   **Libro:** *Dive into Deep Learning*. Disponible en formato PDF.\n",
        "    *   **En l√≠nea:** https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/index.html.\n",
        "    *   **PDF:** https://d2l.ai/d2l-en.pdf.\n",
        "*   **Libro:** *Mathematics for Machine Learning*. Disponible en formato PDF.\n",
        "    *   **En l√≠nea:** https://mml-book.github.io/.\n",
        "    *   **PDF:** https://mml-book.github.io/book/mml-book.pdf.\n",
        "\n",
        "### Webgraf√≠a (Recursos en L√≠nea y Cursos)\n",
        "\n",
        "*   **Blogs:**\n",
        "    *   Aprendemachinelearning.com: http://www.aprendemachinelearning.com/.\n",
        "    *   Towards Data Science: https://towardsdatascience.com/three-month-plan-to-learn-mathematics-behind-machine-learning-74335a578740.\n",
        "*   **Coursera:** Curso \"Multivariate Calculus for Machine Learning\".\n",
        "    *   **En l√≠nea:** https://www.coursera.org/learn/multivariate-calculus-machine-learning.\n",
        "*   **Curso de Introducci√≥n a la Inteligencia Artificial:**\n",
        "    *   Elements of AI: https://www.elementsofai.com/.\n",
        "    *   Building AI: https://buildingai.elementsofai.com.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
